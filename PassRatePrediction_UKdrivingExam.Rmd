---
title: "ST447TestProjectCode"
author: "Andrin Gehrig"
date: "2023-11-24"
output: html_document
---

Comparing two UK driving test centers and analyzing which location is more favorable for a person XYZ of the profile:
- 19, female
The two driving centers in question are Wood Green in London or the center in Worthing.

Methods:
Linear Regression / prediction
Wald Test (z-test and t-test)
(RandomForest)

Plots:
Some plots to illustrate the results

```{r data}

library(readxl) # for reading xlsx data
library(dplyr) 
library(zoo)# common package for data processing 
library(randomForest)
# path to the raw data
path <- "dvsa1203.xls"
# define which sheets to read from the original file
sheet_names <- excel_sheets(path = path)[-1]
# create an empty data frame to store the data in
uk_df_wide <- data.frame()
# loop over all the tables in the original file
for (i in 1:length(sheet_names)) {
  # read and store table i in sheet i.
  # cleaning by skipping empty rows and headers and defining NA strings
  df1 <- read_xls(path, sheet = sheet_names[i], skip = 7, 
    col_names = F, na = c("",".."))
  # only select non-empty columns 
  df1_relevant_cols <- df1 %>% 
    select_if(~sum(!is.na(.)) > 0)
  # assign appropriate column names
  colnames(df1_relevant_cols) <- c("Location", "Age",
                     "M_conducted","M_passes","M_pass_rate",
                     "F_conducted","F_passes","F_pass_rate",
                     "T_conducted","T_passes","T_pass_rate")
  # fill in some empty cells and remove unnecessary rows
  # set the correct data format for columns
  df1_clean <- df1_relevant_cols %>%
    mutate(Location = na.locf(Location) ) %>%
    filter(!is.na(Age) & Age != "Total") %>%
    mutate(Date = sheet_names[i]) %>%
    mutate(Date = as.factor(Date)) %>%
    mutate(Location = as.factor(Location)) %>%
    mutate(Age = as.factor(Age)) %>%
    select(Date, everything())  
  # append the data for sheet i to the data frame
  uk_df_wide <- rbind(uk_df_wide, df1_clean)}
# reformat df for data analysis by creating a column for gender
# select only results relevant for male test takers
uk_m_df <- uk_df_wide %>%
  rename(Passrate = M_pass_rate, Conducted = M_conducted) %>%
  select( -F_conducted, -F_passes, -F_pass_rate,
          -T_conducted, -T_passes, -T_pass_rate, -M_passes) %>%
  mutate(Gender = "M")
# select only results relevant for female test takers
uk_f_df <- uk_df_wide %>%
  rename(Passrate = F_pass_rate, Conducted = F_conducted) %>%
  select( -F_passes, -T_conducted, -T_passes, -T_pass_rate,
          -M_conducted, -M_passes, -M_pass_rate) %>%
  mutate(Gender = "F")
# stack the df for male and female to get the full data again
uk_df <- rbind(uk_m_df, uk_f_df)
uk_df <- arrange(uk_df, Location, Date, Age)
# count distinct rows to check correctness
uk_df %>% distinct() %>% nrow()

```


```{r linear model}
# Create a new data frames for the locations of interest
# Create a numeric "Year" variable from the "Date"
# Select only variables needed for the model estimation
relevant_locations <- uk_df %>%
  filter(Location=="Wood Green (London)" | Location=="Worthing" | Location=="Wood Green" ) %>%
  mutate(Location = ifelse(Location == "Wood Green", "Wood Green (London)", as.character(Location)) ) %>%
  mutate(Year = as.numeric(substr(Date, 1,4))) %>%
  select(Year, Age, Passrate, Gender, Location) %>%
  arrange(Year, Location, Age )
lin_mod <- lm(Passrate~.,data=relevant_locations)# Fit the linear model
summary(lin_mod) # show the model output


coefs <- as.data.frame(lin_mod$coefficients)
coefs$names <- rownames(coefs)


```


```{r pass rate prediction}

# Create new df with the profile of XYZ for Worthing
XYZ_worthing <- data.frame(Year = 2023, Age = as.factor(19), 
                        Gender = "F", Location = "Worthing")
# Create new df with the profile of XYZ for Wood Green
XYZ_wood <- data.frame(Year = 2023, Age = as.factor(19), 
                        Gender = "F",Location = "Wood Green (London)")
# Predict the expected pass rate for Worthing
pred_worthing <- predict(lin_mod, newdata = XYZ_worthing, 
                         interval = "confidence")
# Predict the expected pass rate for Wood Green
pred_wood <- predict(lin_mod, newdata = XYZ_wood, 
                     interval = "confidence")

```




```{r rf prediction}

uk_worthing_df <- filter(uk_df, Location == "Worthing")

uk_worthing <- select(uk_worthing_df, Date, Age, Passrate, Gender)

rf_uk_worthing <- with(uk_worthing, randomForest(Passrate ~ ., data = uk_worthing) )
summary(rf_uk_worthing)

uk_worthing$rf_prediction <- rf_uk_worthing$predicted



uk_green_df <- filter(uk_df, Location == "Wood Green (London)" | Location == "Wood Green (London)") %>%
  mutate(Location = ifelse(Location == "Wood Green", "Wood Green (London)", as.character(Location)) )

uk_green <- select(uk_green_df, Date, Age, Passrate, Gender)

rf_uk_green <- with(uk_green, randomForest(Passrate ~ ., data = uk_green) )
summary(rf_uk_green)

uk_green$rf_prediction <- rf_uk_green$predicted

```




```{r mean comparison}

# Select data for XYZ's profile and compute mean for each location
mean_data <- relevant_locations %>%
  filter(Age=="19", Gender == "F") %>%
  group_by(Location) %>%
  summarise(MeanPR = mean(na.omit(Passrate)), 
            SDev = sd(na.omit(Passrate)), N = n())
mean_data

```

```{r wald test}

# z-test manually

nh_dif <- 0 # Null hypothesis difference
# Wald statistic:
w_sta <- with(mean_data, (MeanPR[1] - MeanPR[2] - nh_dif) / 
                 (sqrt((SDev[1]^2 / N[1]) + (SDev[2]^2 / N[2]))) ) 
alpha <- 0.05 # Test at a significance level of 5%
# Calculate critical value from the standard normal distribution
critical_value <- qnorm(1 - alpha/2)
# Compare the calculated Wald statistic with critical value
abs(w_sta) > critical_value
w_sta # Output the calculated Wald statistic

#### t test built in

mean_observations <- relevant_locations %>%
  filter(Age=="19", Gender == "F")

t.test(filter(mean_observations, Location == "Worthing")$Passrate, 
       filter(mean_observations, Location == "Wood Green (London)")$Passrate,
       alternative = c("two.sided"),
       mu = 0, paired = FALSE, var.equal = FALSE,
       conf.level = 0.95)


```

```{r fig1}

mean_pr_df <- uk_df %>%
  group_by(Location) %>%
  summarise(Passrate = mean(na.omit(Passrate)))
woodg <- filter(mean_pr_df, Location == "Wood Green")$Passrate
worthi <- filter(mean_pr_df, Location == "Worthing")$Passrate
par(mfrow = c(1,1))
hist(mean_pr_df$Passrate, main = "Distribution of Pass Rates",
     xlab = "Pass Rate", col = "lightblue")
abline(v = worthi, lty = "dashed")
abline(v = woodg, lty = "dashed")
text(x = 34, y = 190, "Wood Green", col = "darkgray")
text(x = 58, y = 190, "Worthing", col = "darkgray")

```

```{r fig2}

uk_worthing_xyz <- uk_df %>%
  filter(Location == "Worthing") %>%
  
  filter(Gender == "F", Age == "19") %>%
  arrange(desc(Date))

uk_green_xyz <- uk_df  %>%
  filter(Location=="Wood Green (London)" | Location=="Wood Green" ) %>%
  mutate(Location = ifelse(Location == "Wood Green", "Wood Green (London)", as.character(Location)) ) %>%
  filter(Gender == "F", Age == "19") %>%
  arrange(desc(Date))

uk_worthing_xyz$year <- seq(from = 2008, to = 2018, by = 1)
uk_green_xyz$year <- seq(from = 2008, to = 2023, by = 1)

xaxis <- seq(from = 2008, to = 2023, by = 1)
yaxis <- rep(50,length(xaxis))
worthing_trend <- with(uk_worthing_xyz, lm(Passrate ~ year) ) 
green_trend <- with(uk_green_xyz, lm(Passrate ~ year) ) 
par(mfrow = c(1,1))
plot(xaxis, yaxis, type = 'l', lty = 3, ylim = c(35,60), col = "lightgray",
     main = "Time Series of Pass Rates and Estimated Trends", xlab = "Year", ylab = "Pass Rate")
lines(uk_worthing_xyz$year, uk_worthing_xyz$Passrate, lty = 1, lwd = 2, col = "darkblue" )
lines(uk_green_xyz$year, uk_green_xyz$Passrate, lwd = 2, col = "lightblue"  )
legend("topleft", legend = c("Worthing", "Wood Green"),
       col = c("darkblue", "lightblue"), lty = 1, lwd = 2,
       box.lwd = 0, bg = "transparent", cex = 0.8)
abline(worthing_trend, col = "darkgray", lty = 5)
abline(green_trend, col = "darkgray", lty = 5)

```

```{r fig3}

par(cex.lab = 1.5)
par(mfrow = c(2,2))
plot(lin_mod)

```

