{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e615e6cd",
      "metadata": {
        "id": "e615e6cd"
      },
      "source": [
        "# Reinforcement Learning for Limit Texas Hold'em"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f875978",
      "metadata": {
        "id": "8f875978"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "* [0. Prerequisites](#chap0)\n",
        "* [1. Abstract](#chap1)\n",
        "* [2. Introduction](#chap2)\n",
        "    * [2.1 Texas Hold'em](#2.1)\n",
        "    * [2.2 RL Card Environment](#2.2)\n",
        "    * [2.3 State Representation of Texas Hold'em](#2.3)\n",
        "    * [2.4 Demo Setup of RL Card](#2.4)\n",
        "* [3. Methodologies](#chap3)\n",
        "    * [3.1 Counterfactual Regret Minimization (CFR)](#3.1)\n",
        "    * [3.2 Double-Q-Learning](#3.2)\n",
        "    * [3.3 Double-DQN-Agent](#3.3)\n",
        "    * [3.4 Deep Fitted Q-Iteration](#3.4)\n",
        "    * [3.5 Policy Based methods](#3.5)\n",
        "    * [3.6 Neural Fictitious Self-Play (NFSP)](#3.6)\n",
        "    * [3.7 Demonstration of Manual Play against Methods trained on a Random Agent](#3.7)\n",
        "* [4. Applying Methods to Rule-Based Agents](#chap4)\n",
        "    * [4.1 Double-DQN-Agent vs. Rule-Based](#4.1)\n",
        "    * [4.2 Deep Fitted Q-Iteration vs. Rule-Based](#4.2)\n",
        "    * [4.3 Deep Fitted Q-Iteration vs. Double Deep Q-Network](#4.2)\n",
        "    * [4.4 Demonstration of Manual Play Against Implemented Agents](#4.3)\n",
        "* [5. Conclusion](#chap5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UZFsWS-8evWL",
      "metadata": {
        "id": "UZFsWS-8evWL"
      },
      "source": [
        "## 0. Prerequisites <a class=\"anchor\" id=\"chap0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3tdmRNElex9R",
      "metadata": {
        "id": "3tdmRNElex9R"
      },
      "outputs": [],
      "source": [
        "#!pip3 install rlcard\n",
        "#!pip3 install rlcard[torch]\n",
        "#!pip3 install argparse\n",
        "#!pip3 install pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "mnAorzvvez9Y",
      "metadata": {
        "id": "mnAorzvvez9Y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import rlcard\n",
        "import joblib\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from rlcard import models\n",
        "\n",
        "from rlcard.agents import RandomAgent, DQNAgent, NFSPAgent, CFRAgent\n",
        "from rlcard.agents import LimitholdemHumanAgent as HumanAgent\n",
        "\n",
        "from rlcard.utils import Logger, plot_curve, tournament, reorganize, set_seed\n",
        "from rlcard.utils.utils import remove_illegal, print_card\n",
        "\n",
        "from collections import namedtuple, defaultdict, deque\n",
        "from copy import deepcopy\n",
        "from sklearn.ensemble import GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UZhl8X7Ue1xJ",
      "metadata": {
        "id": "UZhl8X7Ue1xJ"
      },
      "outputs": [],
      "source": [
        "#os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54f05563",
      "metadata": {
        "id": "54f05563"
      },
      "source": [
        "## 1. Abstract <a class=\"anchor\" id=\"chap1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6f65954",
      "metadata": {
        "id": "e6f65954"
      },
      "source": [
        "### Abstract\n",
        "\n",
        "This project investigates and implements self-playing models for Texas Hold'em using the RLCard library. We develop custom reinforcement learning (RL) agents, focusing on value approximation and policy-based learning models, trained against random and rule-based opponents. Our research analyzes reward progression across different models and setups, comparing established methods like Double Deep Q-Network (Double DQN) and novel approaches such as Deep Fitted Q-Iteration and Advantage Actor-Critic (A2C) with Fitted Q Iteration.\n",
        "\n",
        "Findings indicate that while Double DQN performs well, novel methods, particularly Deep Fitted Q-Iteration, show promise by achieving high rewards against random agents and even outperforming the traditional method in a direct comparison. Methods like Counterfactual Regret Minimization (CFR) and Double Q-Learning face challenges due to poker's complexity. This study highlights the need for tailored RL approaches for strategic games and provides insights for developing more robust poker-playing agents, laying the foundation for further RL algorithm optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "525d650a",
      "metadata": {
        "id": "525d650a"
      },
      "source": [
        "## 2. Introduction <a class=\"anchor\" id=\"chap2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4021bf68",
      "metadata": {
        "id": "4021bf68"
      },
      "source": [
        "Texas Hold'em is one of the most widely known variants of poker (henceforth referred to simply as poker). While poker is often misconceived as merely a gambling game, beneath the allure of casino lights lies a complex interplay of skill, psychology, and mathematics. In this section, we explore why poker transcends pure chance:\n",
        "\n",
        "#### Skillful Decision-Making\n",
        "Unlike games of pure luck, poker demands strategic choices. Players assess incomplete information, including their hand cards and community cards, to decide when to fold, call, or raise. Mastery in poker involves reading opponents, managing bankrolls, and adapting to dynamic scenarios.\n",
        "\n",
        "#### Psychological Strategies\n",
        "Bluffing, a cornerstone of poker, allows players to manipulate perceptions. The amount a player bets at various stages significantly impacts the game's outcome. Successfully detecting opponents’ actions and leveraging this information in psychological mind games is crucial to winning in poker.\n",
        "\n",
        "#### Positional Advantage\n",
        "Each game starts with a different order of turns to be played. Early positions require caution due to limited information, while later positions benefit from observing opponents before making decisions. Understanding positional play is critical for success in poker.\n",
        "\n",
        "#### Mathematics and Probabilities\n",
        "Poker is fundamentally a numbers game. Calculating odds and expected values guides decisions, and risk-reward analysis helps determine optimal plays. This mathematical approach is essential for strategic decision-making.\n",
        "\n",
        "#### Adaptability and Game Theory\n",
        "Skilled players adjust their strategies based on opponents’ tendencies. Concepts from game theory, such as the Nash equilibrium, where players balance optimal strategies, are integral to high-level poker play.\n",
        "\n",
        "In summary, mastery in poker involves a synthesis of various skills underpinned by logical reasoning and strategic thinking. This project aims to implement reinforcement learning techniques to develop a self-playing model that integrates these commonly understood aspects of poker. By doing so, we seek to observe how an artificial agent can emulate and potentially master the strategic depth of the game."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6a043ab",
      "metadata": {
        "id": "e6a043ab"
      },
      "source": [
        "## 2.1 Texas Hold'em <a class=\"anchor\" id=\"2.1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eae6eeab",
      "metadata": {
        "id": "eae6eeab"
      },
      "source": [
        "For this project, we will be using Limit Texas Hold'em, a variant of Texas Hold'em where each player can only raise by a fixed amount, and the number of raises per round is limited to four.\n",
        "\n",
        "### Game Mechanics of Limit Texas Hold'em\n",
        "\n",
        "Here are the five general rounds of how a game of poker is played out:\n",
        "\n",
        "#### Round 0: Setup\n",
        "\n",
        "Players sit around a circular table. Each game, one player holds a 'button' (indicating the dealer position), and the button moves clockwise after each game. The player to the left of the button is the 'small blind,' and the player to the left of the small blind is the 'big blind.' The small blind and big blind make mandatory bets (SB and BB, where BB = 2 * SB) before the game begins. The amounts of SB and BB vary by game. Now, the four main rounds of a game begin, each involving card dealing/opening followed by a betting round.\n",
        "\n",
        "#### Round 1: Pre-Flop\n",
        "\n",
        "From a standard 52-card deck, the dealer deals two private cards (known as the hand) to each player. After all players receive their hands, starting from the player to the left of the big blind, players begin making bets in a clockwise order. Players can choose from three actions: fold (no longer participate in the game), call (match the highest bet of the round, or check if no bets have been made), or raise (increase the highest bet of the round). The round ends when every player has either called the highest bet or folded.\n",
        "\n",
        "#### Round 2: Flop\n",
        "\n",
        "After the pre-flop betting round, the dealer places three community cards face up in the center of the table (known as the flop). Players use their hand in combination with the flop to form the best possible five-card combination. Starting from the small blind, another round of betting occurs.\n",
        "\n",
        "#### Round 3: Turn\n",
        "\n",
        "The fourth community card (the turn card) is revealed. Players reassess their hands, and another round of betting occurs.\n",
        "\n",
        "#### Round 4: River\n",
        "\n",
        "The fifth and final community card (the river) is revealed. Players make their final assessments of their complete hands, and the last round of betting occurs. After the betting ends, the remaining players reveal their hole cards, and the best hand wins the pot.\n",
        "\n",
        "### Poker Hand Rankings\n",
        "\n",
        "Here is the ranking of each poker hand.\n",
        "\n",
        "![alt text](poker_hand_table_new.jpg \"poker hand ranking\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oO4fUqyOfM5k",
      "metadata": {
        "id": "oO4fUqyOfM5k"
      },
      "source": [
        "## 2.2 RL Card Environment <a class=\"anchor\" id=\"2.2\"></a>\n",
        "### About the RLCard Library\n",
        "\n",
        "RLCard, developed by DATA Lab at Rice University and Texas A&M University, is a toolkit designed to facilitate reinforcement learning applications in various card games. Featuring user-friendly interfaces, RLCard supports the implementation of a wide range of reinforcement learning algorithms and search techniques across multiple card game environments. The library provides pre-defined environments for popular card games, including Texas Hold'em, but also Blackjack, and UNO. RLCard includes a variety of pre-implemented agents which we will make use of, such as DQN, NFSP, and CFR, which serve as excellent baselines for benchmarking new approaches. Further, its compatibility with popular deep learning frameworks such as TensorFlow and PyTorch, enabling integration with existing machine learning pipelines.\n",
        "\n",
        "Overall, RLCard is a powerful and comprehensive toolkit that significantly lowers the barrier to entry for conducting advanced research in reinforcement learning for card games.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff35e361",
      "metadata": {
        "id": "ff35e361"
      },
      "source": [
        "## 2.3 State, Actions and Reward Representation <a class=\"anchor\" id=\"2.3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZcE4_TJpx-ah",
      "metadata": {
        "id": "ZcE4_TJpx-ah"
      },
      "source": [
        "This section details the implementation of poker into a reinforcement learning environment, following the setup provided by the RLCard library.\n",
        "\n",
        "The state is recorded as a vector with a length of 72. The first 52 indices represent the hand of each player, with each index corresponding to a specific card in ascending order. The hand is observed as the union of the player's hand and the community board cards. The remaining 20 indices represent the betting history, as Limit Texas Hold'em allows a maximum of four raises per round. The index representation for each card is as follows:\n",
        "\n",
        "| State Index | Representation          |\n",
        "|-------------|-------------------------|\n",
        "| 0~12        | Spade A ~ Spade K       |\n",
        "| 13~25       | Heart A ~ Heart K       |\n",
        "| 26~38       | Diamond A ~ Diamond K   |\n",
        "| 39~51       | Club A ~ Club K         |\n",
        "| 52~56       | Raise number in round 1 |\n",
        "| 57~61       | Raise number in round 2 |\n",
        "| 62~66       | Raise number in round 3 |\n",
        "| 67~71       | Raise number in round 4 |\n",
        "\n",
        "There are four possible actions, represented as follows:\n",
        "\n",
        "| Action Index | Representation |\n",
        "|--------------|----------------|\n",
        "| 0            | Call           |\n",
        "| 1            | Raise          |\n",
        "| 2            | Fold           |\n",
        "| 3            | Check          |\n",
        "\n",
        "The standard unit used for calculating the reward is big blinds per game (BB/game). For instance, a reward of 3/-3 indicates that the player won or lost three times the amount of the big blind.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f80bc0",
      "metadata": {
        "id": "97f80bc0"
      },
      "source": [
        "## 2.4 Demo Setup of RL Card <a class=\"anchor\" id=\"2.4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f-GW941fnD8",
      "metadata": {
        "id": "9f-GW941fnD8"
      },
      "source": [
        "In this subsection, we showcase the capabilities of RLCard by creating a limit-holdem environment and establishing an interface where users can play poker games against a random agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7i8TTVxKfmfX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i8TTVxKfmfX",
        "outputId": "561fa5cc-9fe8-4796-f449-032e68911448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of actions: 4\n",
            "Number of players: 2\n",
            "Shape of state: [[72], [72]]\n",
            "Shape of action: [None, None]\n"
          ]
        }
      ],
      "source": [
        "env = rlcard.make(\"limit-holdem\")\n",
        "\n",
        "print(\"Number of actions:\", env.num_actions)\n",
        "print(\"Number of players:\", env.num_players)\n",
        "print(\"Shape of state:\", env.state_shape)\n",
        "print(\"Shape of action:\", env.action_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WoWB6icBfsCg",
      "metadata": {
        "id": "WoWB6icBfsCg"
      },
      "source": [
        "As previously mentioned, the environment allows for four types of actions (fold, check, call, raise) and accommodates a maximum of two players. The state representation consists of 72 spaces: The first 52 represent hand and board checkers, while the last 20 capture action records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5etcr0VLucoU",
      "metadata": {
        "id": "5etcr0VLucoU"
      },
      "outputs": [],
      "source": [
        "def manual_play(opponent_agent, num_games):\n",
        "\n",
        "    env = rlcard.make('limit-holdem')\n",
        "    human_agent = HumanAgent(env.num_actions)\n",
        "    agent_0 = opponent_agent\n",
        "    env.set_agents([human_agent, agent_0,])\n",
        "\n",
        "    for i in range(num_games):\n",
        "        print(\">> Start a new game\")\n",
        "\n",
        "        trajectories, payoffs = env.run(is_training=False)\n",
        "        # If the human does not take the final action, we need to\n",
        "        # print other players action\n",
        "        if len(trajectories[0]) != 0:\n",
        "            final_state = trajectories[0][-1]\n",
        "            action_record = final_state['action_record']\n",
        "            state = final_state['raw_obs']\n",
        "            _action_list = []\n",
        "            for i in range(1, len(action_record)+1):\n",
        "                \"\"\"\n",
        "                if action_record[-i][0] == state['current_player']:\n",
        "                    break\n",
        "                \"\"\"\n",
        "                _action_list.insert(0, action_record[-i])\n",
        "            for pair in _action_list:\n",
        "                print('>> Player', pair[0], 'chooses', pair[1])\n",
        "\n",
        "        # Let's take a look at what the agent card is\n",
        "        print('=============     Random Agent    ============')\n",
        "        print_card(env.get_perfect_information()['hand_cards'][1])\n",
        "\n",
        "        print('===============     Result     ===============')\n",
        "        if payoffs[0] > 0:\n",
        "            print('You win {} chips!'.format(payoffs[0]))\n",
        "        elif payoffs[0] == 0:\n",
        "            print('It is a tie.')\n",
        "        else:\n",
        "            print('You lose {} chips!'.format(-payoffs[0]))\n",
        "        print('')\n",
        "\n",
        "        input(\"Press any key to continue...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "hdpZon1bfzmK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdpZon1bfzmK",
        "outputId": "008d4d9c-c9fd-4063-872b-a494d65f7ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │9        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        9│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │9        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        9│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│5        │   │8        │   │A        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♥    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        5│   │        8│   │        A│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │9        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        9│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++\n",
            "++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses fold\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 4.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│4        │   │4        │   │A        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♣    │   │    ♦    │   │    ♣    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        4│   │        4│   │        A│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++\n",
            "++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│4        │   │4        │   │A        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♣    │   │    ♦    │   │    ♣    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        4│   │        4│   │        A│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses fold\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│5        │   │5        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        5│   │        5│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 6.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│8        │   │9        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        8│   │        9│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses fold\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │4        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        4│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 1.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │6        │   │3        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♣    │   │    ♠    │   │    ♠    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        8│   │        6│   │        3│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++\n",
            "++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │6        │   │3        │   │5        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♣    │   │    ♠    │   │    ♠    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        8│   │        6│   │        3│   │        5│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses fold\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│2        │   │J        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        2│   │        J│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 5.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │7        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        7│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │7        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        7│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│Q        │   │2        │   │3        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♠    │   │    ♥    │   │    ♥    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        Q│   │        2│   │        3│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │7        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        7│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│Q        │   │2        │   │3        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♠    │   │    ♥    │   │    ♥    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        Q│   │        2│   │        3│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │7        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        7│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++\n",
            "++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses fold\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 7.0 chips!\n",
            "\n",
            "Press any key to continue...\n"
          ]
        }
      ],
      "source": [
        "manual_play(opponent_agent = RandomAgent(num_actions=env.num_actions), num_games = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dk7e7dQmf4se",
      "metadata": {
        "id": "dk7e7dQmf4se"
      },
      "source": [
        "Five games of poker were manually played using the RLCard environment against a random agent. The results reveal a strategy of consistently raising or calling, aiming to maximize rewards. This approach exploits the fact that the random agent is highly likely to eventually choose the option to fold."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4121530",
      "metadata": {
        "id": "c4121530"
      },
      "source": [
        "## 3. Methodology: Building a Limit Texas Hold'em Poker Agent <a class=\"anchor\" id=\"chap3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31da158c",
      "metadata": {
        "id": "31da158c"
      },
      "source": [
        "To create a Limit Texas Hold'em poker agent, we have multiple options from classical Reinforcement Learning (RL) methods such as Monte Carlo (MC) methods, Temporal Difference (TD) learning (like Q-learning), and more advanced techniques like Deep Reinforcement Learning. To implement a practical agent, we use methods provided in RLcard and extend them with our own code.\n",
        "\n",
        "Each approach follows a number of steps, where we set up appropriate environments and instances for the agent to interact with, and then implement a reinforcement learning agent to play the game. After training and fine-tuning we then analyse and compare the results. For any given method the process is simplified as follows:\n",
        "\n",
        "##### Step 1: Environment Setup\n",
        "We initialize the Texas Hold'em environment from RLCard. This environment will automatically handle the state and action representations:\n",
        "\n",
        "  ```python\n",
        "  import rlcard\n",
        "  from rlcard.agents import RandomAgent\n",
        "\n",
        "  env = rlcard.make('limit-holdem', config={'single_agent_mode':True})\n",
        "\n",
        "  ```\n",
        "\n",
        "##### Step 2: Defining and Implementing the RL Method\n",
        "\n",
        "Select one of the RL methods discussed below and implement an agent using the RLCard library and our own code. Some methods may require fine-tuning and specific adjustments to function optimally.\n",
        "\n",
        "##### Step 3: Training the Agent\n",
        "\n",
        "- **Simulation**: Conduct simulations where the agent competes against a random agent to gather experience.\n",
        "- **Rewards**: Use game outcomes as direct learning signals for the agent.\n",
        "- **Evaluation**: Regularly assess the agent's performance with a separate evaluation environment to track its progress and performance.\n",
        "\n",
        "##### Step 4: Integration and Tuning\n",
        "\n",
        "**Parameter Tuning**: Adjust learning rates, exploration rates, discount factors, and other key parameters based on the agent's performance. We test different parameter configurations for all methods and perform extensive grid searches for the most complex models to identify the optimal parameters.\n",
        "\n",
        "##### Step 5: Analyzing Performance and Comparing Methods\n",
        "\n",
        "Evaluate the agent's performance comprehensively and compare it to other methods to determine its effectiveness.\n",
        "\n",
        "##### Example Code Snippet\n",
        "\n",
        "Below is a simplified example demonstrating the setup with a random agent and a DQN agent provided by RLCard:\n",
        "\n",
        "```python\n",
        "import rlcard\n",
        "from rlcard.agents import RandomAgent, DQNAgent\n",
        "from rlcard.utils import Logger, plot_curve, tournament, reorganize\n",
        "\n",
        "# Make the environment with Limit Texas Hold'em\n",
        "env = rlcard.make('limit-holdem')\n",
        "eval_env = rlcard.make('limit-holdem')\n",
        "print(\"Number of actions:\", env.num_actions)\n",
        "print(\"Number of players:\", env.num_players)\n",
        "print(\"Shape of state:\", env.state_shape)\n",
        "print(\"Shape of action:\", env.action_shape)\n",
        "\n",
        "# Initialize a DQN agent\n",
        "agent = agent_name(\n",
        "    num_actions=env.num_actions,\n",
        "    state_shape=env.state_shape[0],\n",
        "    ...,\n",
        "    ...\n",
        ")\n",
        "\n",
        "# Set the agents in the environment\n",
        "env.set_agents([agent, RandomAgent(num_actions=env.num_actions)])\n",
        "eval_env.set_agents([agent, RandomAgent(num_actions=env.num_actions)])\n",
        "\n",
        "# Initialize the Logger\n",
        "with Logger(\"experiments/agent_name\") as logger:\n",
        "    for episode in range(5000):\n",
        "        # Generate data from the environment\n",
        "        trajectories, payoffs = env.run(is_training=True)\n",
        "\n",
        "        # Reorganize the data to be state, action, reward, next_state, done\n",
        "        trajectories = reorganize(trajectories, payoffs)\n",
        "\n",
        "        # Feed transitions into agent memory, and train the agent\n",
        "        for ts in trajectories[0]:\n",
        "            agent.feed(ts)\n",
        "\n",
        "        # Evaluate the performance every 100 episodes\n",
        "        if episode % 100 == 0:\n",
        "            print(f'Episode {episode}')\n",
        "            logger.log_performance(\n",
        "                env.timestep,\n",
        "                tournament(\n",
        "                    eval_env,\n",
        "                    1000  # Reduce for quicker evaluations\n",
        "                )[0]\n",
        "            )\n",
        "\n",
        "    # Get the paths for the learning curve\n",
        "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_curve(csv_path, fig_path, 'AgentName')\n",
        "```\n",
        "\n",
        "This code initializes the Texas Hold'em environment and uses a random agent to play the game, which can be replaced by any of the agents we discuss in the following. In the pursuit of creating an effective poker agent, particularly for a game as strategically complex as Limit Texas Hold'em, several reinforcement learning methodologies stand out for their relevance and efficacy. Each methodology offers unique advantages and operates under different assumptions about the environment and the agent's capabilities.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mCpp4M2LgCP6",
      "metadata": {
        "id": "mCpp4M2LgCP6"
      },
      "source": [
        "## 3.1 Counterfactual Regret Minimization (CFR) <a class=\"anchor\" id=\"3.1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xlCPWn_wgEBp",
      "metadata": {
        "id": "xlCPWn_wgEBp"
      },
      "source": [
        "Counterfactual Regret Minimization (CFR) algorithm presents a potent tool for tackling the complexities of strategic decision-making in games such as Texas Hold'em. In the realm of Limit Texas Hold'em, where actions reverberate across multiple betting rounds and decisions are intertwined with uncertainties regarding opponents' actions, CFR stands as a methodological cornerstone due to several factors:\n",
        "\n",
        "### 3.1.1 Key Characteristics of CFR\n",
        "\n",
        "- **Adaptability to Imperfect Information:** Unlike deterministic methods, CFR can navigate games with imperfect information, where players lack full knowledge of each other's cards. This adaptability is crucial in poker, where players must make decisions based on incomplete information about their opponents' holdings.\n",
        "- **Efficient Handling of Large State Spaces:** CFR efficiently handles the vast state spaces inherent in poker by focusing on learning from experience rather than exhaustive enumeration of all possible states. This is particularly pertinent in Texas Hold'em, where the number of potential game states grows exponentially with the number of players and betting rounds.\n",
        "- **Ability to Learn Online:** CFR's iterative nature enables online learning, allowing agents to continually refine their strategies as they encounter new situations and opponents. This real-time adaptation is invaluable in dynamic environments like poker, where opponents may adjust their strategies in response to the agent's actions.\n",
        "\n",
        "Given these considerations, CFR emerges as a prime candidate for implementing reinforcement learning strategies in Texas Hold'em, offering a principled approach to learning effective strategies in the face of uncertainty.\n",
        "\n",
        "### 3.1.2 How CFR Works\n",
        "Counterfactual Regret Minimization operates by iteratively improving strategies through self-play, iteratively correcting regrets associated with past actions. Here's a breakdown of the algorithm's steps as applied to Texas Hold'em:\n",
        "\n",
        "**Regret Calculation and Strategy Improvement**\n",
        "\n",
        "- **Information Set Formation:** Define information sets for each player, encapsulating the possible private information each player may hold at any point in the game.\n",
        "- **Regret Calculation:** For each information set, calculate the regret associated with each action taken in the past. Regret is the difference between the utility of the action taken and the utility that would have been achieved by taking the optimal action at that information set.\n",
        "- **Strategy Improvement:** Adjust the strategy for each information set based on the accumulated regrets. Actions with higher cumulative positive regrets are favored, while those with negative regrets are deemphasized.\n",
        "\n",
        "**Exploration and Exploitation**\n",
        "\n",
        "- **Stochastic Strategy:** CFR introduces stochasticity into the agent's strategy, allowing for exploration of different actions and adaptation to opponents' strategies over time.\n",
        "- **Regret Matching:** The strategy update step employs regret matching, where the probability of selecting an action is proportional to its cumulative positive regret. This encourages exploration of actions with potentially high payoffs while gradually exploiting more successful actions.\n",
        "\n",
        "### 3.1.3 Application to Limit Texas Hold'em Poker\n",
        "- **Nash Equilibrium Approximation:** CFR converges to a Nash equilibrium strategy, providing a robust benchmark for optimal play against any opponent strategy.\n",
        "- **Counterfactual Thinking:**  By simulating counterfactual scenarios and updating strategies based on regret, CFR encourages agents to consider alternative actions and anticipate opponents' responses, leading to more nuanced and adaptive gameplay.\n",
        "\n",
        "**Implementation Considerations**\n",
        "- **Memory Efficiency:** CFR's memory requirements can be significant, especially when dealing with large state spaces. Techniques such as abstraction and pruning are often employed to mitigate memory overhead.\n",
        "- **Computational Complexity:** The computational demands of CFR can be substantial, particularly during the initial stages of learning. Parallelization and optimization techniques are commonly used to enhance efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kp0zVuB8gkhZ",
      "metadata": {
        "id": "kp0zVuB8gkhZ"
      },
      "source": [
        "### 3.1.4 Implementing CFR to Poker\n",
        "\n",
        "To implement the CFR agent, the code structure needs to be changed slightly compared to the example we've seen above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "rd019-JcglGS",
      "metadata": {
        "id": "rd019-JcglGS"
      },
      "outputs": [],
      "source": [
        "env = rlcard.make('limit-holdem',config={'allow_step_back': True})\n",
        "eval_env = rlcard.make('limit-holdem')\n",
        "\n",
        "CFRagent = CFRAgent(env,\"experiments/limit_holdem_cfr_result/cfr_model\")\n",
        "\n",
        "eval_env.set_agents([\n",
        "    CFRagent,\n",
        "    RandomAgent(num_actions=env.num_actions),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "nKdmJ8UYgzVV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKdmJ8UYgzVV",
        "outputId": "252647a4-9cc1-4ce9-9e74-2a9ce3bef99d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0\n",
            "----------------------------------------\n",
            "  episode      |  93131\n",
            "  reward       |  -0.067\n",
            "----------------------------------------\n",
            "Iteration 5\n",
            "----------------------------------------\n",
            "  episode      |  322731\n",
            "  reward       |  -0.033\n",
            "----------------------------------------\n",
            "Iteration 10\n",
            "----------------------------------------\n",
            "  episode      |  552331\n",
            "  reward       |  0.0205\n",
            "----------------------------------------\n",
            "Iteration 15\n",
            "----------------------------------------\n",
            "  episode      |  781931\n",
            "  reward       |  -0.0005\n",
            "----------------------------------------\n",
            "Iteration 20\n",
            "----------------------------------------\n",
            "  episode      |  1011531\n",
            "  reward       |  -0.105\n",
            "----------------------------------------\n",
            "Iteration 25\n",
            "----------------------------------------\n",
            "  episode      |  1241131\n",
            "  reward       |  0.07\n",
            "----------------------------------------\n",
            "Iteration 30\n",
            "----------------------------------------\n",
            "  episode      |  1470731\n",
            "  reward       |  0.004\n",
            "----------------------------------------\n",
            "Iteration 35\n",
            "----------------------------------------\n",
            "  episode      |  1700331\n",
            "  reward       |  -0.043\n",
            "----------------------------------------\n",
            "Iteration 40\n",
            "----------------------------------------\n",
            "  episode      |  1929931\n",
            "  reward       |  -0.033\n",
            "----------------------------------------\n",
            "Iteration 45\n",
            "----------------------------------------\n",
            "  episode      |  2159531\n",
            "  reward       |  -0.081\n",
            "----------------------------------------\n",
            "Iteration 50\n",
            "----------------------------------------\n",
            "  episode      |  2389131\n",
            "  reward       |  0.01\n",
            "----------------------------------------\n",
            "Iteration 55\n",
            "----------------------------------------\n",
            "  episode      |  2618731\n",
            "  reward       |  0.043\n",
            "----------------------------------------\n",
            "Iteration 60\n",
            "----------------------------------------\n",
            "  episode      |  2848331\n",
            "  reward       |  -0.12\n",
            "----------------------------------------\n",
            "Iteration 65\n",
            "----------------------------------------\n",
            "  episode      |  3077931\n",
            "  reward       |  -0.1075\n",
            "----------------------------------------\n",
            "Iteration 70\n",
            "----------------------------------------\n",
            "  episode      |  3307531\n",
            "  reward       |  0.059\n",
            "----------------------------------------\n",
            "Iteration 75\n",
            "----------------------------------------\n",
            "  episode      |  3537131\n",
            "  reward       |  0.0115\n",
            "----------------------------------------\n",
            "Iteration 80\n",
            "----------------------------------------\n",
            "  episode      |  3766731\n",
            "  reward       |  -0.0445\n",
            "----------------------------------------\n",
            "Iteration 85\n",
            "----------------------------------------\n",
            "  episode      |  3996331\n",
            "  reward       |  0.1885\n",
            "----------------------------------------\n",
            "Iteration 90\n",
            "----------------------------------------\n",
            "  episode      |  4225931\n",
            "  reward       |  0.0945\n",
            "----------------------------------------\n",
            "Iteration 95\n",
            "----------------------------------------\n",
            "  episode      |  4455531\n",
            "  reward       |  0.0085\n",
            "----------------------------------------\n",
            "Iteration 99\n",
            "Logs saved in experiments/limit_holdem_cfr_result\n"
          ]
        }
      ],
      "source": [
        "with Logger(\"experiments/limit_holdem_cfr_result\") as logger:\n",
        "    for episode in range(100):\n",
        "        CFRagent.train()\n",
        "        print('\\rIteration {}'.format(episode), end='')\n",
        "        # Evaluate the performance. Play with Random agent.\n",
        "        if episode % 5 == 0:\n",
        "            logger.log_performance(\n",
        "                env.timestep,\n",
        "                tournament(\n",
        "                    eval_env,\n",
        "                    1000,\n",
        "                )[0]\n",
        "            )\n",
        "\n",
        "    # Get the paths\n",
        "    csv_path, fig_path = logger.csv_path, logger.fig_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sGxTZlBX0DNN",
      "metadata": {
        "id": "sGxTZlBX0DNN"
      },
      "source": [
        "Graph depicting CFR rewards across episodes after lengthy training:\n",
        "![alt text](cfr_graph.jpeg \"poker hand ranking\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XLearmq2hKUN",
      "metadata": {
        "id": "XLearmq2hKUN"
      },
      "source": [
        "### 3.1.5 Conclusion\n",
        "\n",
        "In applying CFR to poker, we encountered challenges in achieving improved rewards over successive episodes. Despite its theoretical effectiveness, our empirical results suggest limitations in the current implementation or parameterization of CFR. The observed stagnation in rewards underscores the complexity of the poker domain and highlights the need for further research and refinement in algorithmic approaches and training methodologies. Moving forward, addressing these challenges demands a comprehensive examination of agent behavior and strategy adaptation, alongside exploration of alternative algorithms and refinement of training procedures. While the current results may not meet expectations, they provide valuable insights for future endeavors aimed at advancing the development of robust and proficient poker-playing agents."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a379635e",
      "metadata": {
        "id": "a379635e"
      },
      "source": [
        "## 3.2 Double Q-Learning <a class=\"anchor\" id=\"3.2\"></a>\n",
        "\n",
        "Double Q-learning is a reinforcement learning method that addresses a common problem in standard Q-learning known as maximization bias. This bias occurs because Q-learning uses the maximum estimated action value to both choose and evaluate an action, which can lead to systematically overestimated action values. Double Q-learning effectively reduces this overestimation by maintaining and updating two separate action-value functions, $ Q_A $ and $ Q_B $. These functions are used alternately to decouple the action selection and action evaluation steps, leading to more reliable and stable learning outcomes.\n",
        "\n",
        "### 3.2.1 Key Characteristics of Double Q-Learning\n",
        "\n",
        "1. **Reduced Overestimation**: By using two separate Q-functions, Double Q-learning avoids the maximization bias by ensuring that the selection of the best action and the evaluation of that action's value are based on different sets of information.\n",
        "\n",
        "2. **Stability and Accuracy**: The use of two Q-functions helps average out errors and leads to more accurate estimation of action values, which contributes to the stability of the learning process.\n",
        "\n",
        "3. **Exploration and Exploitation**: Similar to other Q-learning variants, Double Q-learning uses an epsilon-greedy strategy to balance exploration and exploitation. This approach allows the poker agent to explore various actions to find more profitable strategies while exploiting the current best-known strategies to win games.\n",
        "\n",
        "### 3.2.2 How Double Q-Learning Works\n",
        "\n",
        "Double Q-learning maintains two separate estimators (Q-tables), $ Q_A $ and $ Q_B $, to decouple the action selection and evaluation. This approach reduces the overoptimistic value estimates that arise from the maximization step in standard Q-learning.\n",
        "\n",
        "The following outlines the algorithm:\n",
        "\n",
        "1. **Initialize Two Q-Tables**: Start with two action-value functions, $ Q_A $ and $ Q_B $, initialized randomly.\n",
        "\n",
        "2. **Choose an Action**: Use an epsilon-greedy strategy based on the combined values $ Q_A + Q_B $ to choose an action $ a $.\n",
        "\n",
        "3. **Update Rule**: At each step, randomly update one of the two Q-tables:\n",
        "   - With 50% probability, update $ Q_A $ using:\n",
        "\n",
        "      $ Q_A(s_t, a_t) \\leftarrow Q_A(s_t, a_t) + \\alpha \\left[ r_{t+1} + \\gamma Q_B(s_{t+1}, \\arg \\max_a Q_A(s_{t+1}, a)) - Q_A(s_t, a_t) \\right] $\n",
        "\n",
        "   - Otherwise, update $ Q_B $ using:\n",
        "     $ Q_B(s_t, a_t) \\leftarrow Q_B(s_t, a_t) + \\alpha \\left[ r_{t+1} + \\gamma Q_A(s_{t+1}, \\arg \\max_a Q_B(s_{t+1}, a)) - Q_B(s_t, a_t)\\right] $\n",
        "\n",
        "4. **Action Evaluation**: The action from the state $ s_{t+1} $ is selected by the Q-table not being updated, reducing the bias introduced by the maximization step.\n",
        "\n",
        "### 3.2.3 Application to Limit Texas Hold'em Poker\n",
        "\n",
        "In the context of Limit Texas Hold'em, Double Q-learning may be applied to develop a strategy that adapts to different game dynamics and opponent behaviors. We outline how a Double-Q-learner may function in a poker environment:\n",
        "\n",
        "1. **Learning Betting Strategies**: By updating the Q-values based on actual rewards and using an epsilon-greedy approach, the agent can learn when to call, raise, fold, or check. These actions are learned by trial and error but are guided by the feedback from the game outcomes.\n",
        "\n",
        "2. **Handling Partial Information**: Poker is a game of imperfect information. Double Q-learning can help mitigate the risks of overestimation in uncertain environments, making the agent's strategy more robust in situations where it must act with incomplete knowledge of the opponents' cards.\n",
        "\n",
        "3. **Adjusting to Opponents**: Double Q-learning can adapt the agent’s strategy based on the observed behavior of opponents. By learning from the outcomes of games against different types of players, the agent can refine its strategy to maximize winnings against a variety of strategies.\n",
        "\n",
        "4. **Incremental Learning**: As with other TD methods, Double Q-learning allows the agent to learn from each step of the game. This is ideal for poker, where learning from every round of betting can provide insights that are crucial for adjusting strategies in real-time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3089828",
      "metadata": {
        "id": "c3089828"
      },
      "source": [
        "\n",
        "### 3.2.3 Implementing Double Q-Learning for Poker\n",
        "\n",
        "Building on the structure of agents implemented in RLCard, such as the DQN agent discussed in the next subsection, we present the implementation of a Double Q-Learning agent. This agent interacts with the environments provided by RLCard, specifically designed for poker games like Limit Texas Hold'em.\n",
        "\n",
        "The `DoubleQLearningAgent` class incorporates the methodology outlined above. Below, we provide the full code:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "qwCO11GTCmuk",
      "metadata": {
        "id": "qwCO11GTCmuk"
      },
      "outputs": [],
      "source": [
        "class DoubleQLearningAgent:\n",
        "    ''' A simple tabular Double-Q learning agent '''\n",
        "    def __init__(self,\n",
        "                 num_actions,\n",
        "                 epsilon=1.0,\n",
        "                 epsilon_min=0.1,\n",
        "                 epsilon_decay=0.995,\n",
        "                 alpha=0.3,\n",
        "                 gamma=0.9,\n",
        "                 training=True):\n",
        "        ''' Initialize the Double-Q learning agent\n",
        "        Args:\n",
        "            num_actions (int): number of actions\n",
        "            epsilon (float): initial exploration rate\n",
        "            epsilon_min (float): minimum exploration rate\n",
        "            epsilon_decay (float): decay rate of exploration probability\n",
        "            alpha (float): learning rate\n",
        "            gamma (float): discount factor\n",
        "            training (bool): flag to indicate if the agent is training\n",
        "        '''\n",
        "        self.num_actions = num_actions\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_min = epsilon_min\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.training = training\n",
        "\n",
        "        # Initialize Q-tables\n",
        "        self.Q1 = defaultdict(lambda: np.zeros(num_actions))\n",
        "        self.Q2 = defaultdict(lambda: np.zeros(num_actions))\n",
        "\n",
        "        # Set use_raw to False since we are using a tabular method\n",
        "        self.use_raw = False\n",
        "\n",
        "    def step(self, state):\n",
        "        ''' Returns the action to be taken by the agent\n",
        "        Args:\n",
        "            state (dict): the current state\n",
        "        Returns:\n",
        "            action (int): the action taken by the agent\n",
        "        '''\n",
        "        # Convert state['obs'] to a hashable state\n",
        "        state_key = tuple(state['obs'])\n",
        "        if self.training and random.random() < self.epsilon:\n",
        "            return random.choice(range(self.num_actions))\n",
        "        return np.argmax(self.Q1[state_key] + self.Q2[state_key])\n",
        "\n",
        "\n",
        "    def feed(self, ts):\n",
        "        ''' Process and train on a single transition\n",
        "        Args:\n",
        "            ts (dict): A transition tuple (state, action, reward, next_state, done)\n",
        "        '''\n",
        "        (state, action, reward, next_state, done) = tuple(ts)\n",
        "\n",
        "        # Convert states to a hashable format\n",
        "        state_key = tuple(state['obs'])\n",
        "        next_state_key = tuple(next_state['obs'])\n",
        "\n",
        "        self.train(state_key, action, reward, next_state_key, done)\n",
        "        #self.train(state, action, reward, next_state, done)\n",
        "\n",
        "\n",
        "    def train(self, state_key, action, reward, next_state_key, done):\n",
        "        ''' Updates the Q-values based on the agent's experience\n",
        "        Args:\n",
        "            state_key (tuple): the current state in hashable form\n",
        "            action (int): the action taken\n",
        "            reward (float): the reward received\n",
        "            next_state_key (tuple): the next state in hashable form\n",
        "            done (bool): flag indicating if the episode has ended\n",
        "        '''\n",
        "        if random.random() < 0.5:\n",
        "            # Update Q1\n",
        "            best_action_next = np.argmax(self.Q1[next_state_key])\n",
        "            td_target = reward + self.gamma * self.Q2[next_state_key][best_action_next] * (not done)\n",
        "            td_error = td_target - self.Q1[state_key][action]\n",
        "            self.Q1[state_key][action] += self.alpha * td_error\n",
        "        else:\n",
        "            # Update Q2\n",
        "            best_action_next = np.argmax(self.Q2[next_state_key])\n",
        "            td_target = reward + self.gamma * self.Q1[next_state_key][best_action_next] * (not done)\n",
        "            td_error = td_target - self.Q2[state_key][action]\n",
        "            self.Q2[state_key][action] += self.alpha * td_error\n",
        "\n",
        "        # Decay epsilon\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def eval_step(self, state):\n",
        "        ''' Predict the action for evaluation (greedy based on Q1 + Q2)\n",
        "        Args:\n",
        "            state (dict): the current state\n",
        "        Returns:\n",
        "            action (int): the action predicted by the agent\n",
        "            info (dict): additional information, e.g., action probabilities\n",
        "        '''\n",
        "        state_key = tuple(state['obs'])\n",
        "        best_action = np.argmax(self.Q1[state_key] + self.Q2[state_key])\n",
        "\n",
        "        # Normally, action probabilities are provided; here we can use a simple approach\n",
        "        action_probs = np.zeros(self.num_actions)\n",
        "        action_probs[best_action] = 1.0\n",
        "\n",
        "        # Return the action and a dictionary containing additional info\n",
        "        return best_action, {'action_probs': action_probs}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "tGaxSdnBTjsY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tGaxSdnBTjsY",
        "outputId": "97f01531-4665-47b5-8088-3098d2b31295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1\n",
            "  reward       |  1.125\n",
            "----------------------------------------\n",
            "Episode 100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  293\n",
            "  reward       |  1.1895\n",
            "----------------------------------------\n",
            "Episode 200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  641\n",
            "  reward       |  1.103\n",
            "----------------------------------------\n",
            "Episode 300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1084\n",
            "  reward       |  1.0465\n",
            "----------------------------------------\n",
            "Episode 400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1494\n",
            "  reward       |  1.074\n",
            "----------------------------------------\n",
            "Episode 500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1917\n",
            "  reward       |  1.138\n",
            "----------------------------------------\n",
            "Episode 600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2360\n",
            "  reward       |  1.2595\n",
            "----------------------------------------\n",
            "Episode 700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2739\n",
            "  reward       |  1.117\n",
            "----------------------------------------\n",
            "Episode 800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3155\n",
            "  reward       |  1.094\n",
            "----------------------------------------\n",
            "Episode 900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3559\n",
            "  reward       |  1.225\n",
            "----------------------------------------\n",
            "Episode 1000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3969\n",
            "  reward       |  1.088\n",
            "----------------------------------------\n",
            "Episode 1100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4379\n",
            "  reward       |  1.175\n",
            "----------------------------------------\n",
            "Episode 1200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4759\n",
            "  reward       |  1.18\n",
            "----------------------------------------\n",
            "Episode 1300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5200\n",
            "  reward       |  1.2255\n",
            "----------------------------------------\n",
            "Episode 1400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5633\n",
            "  reward       |  1.113\n",
            "----------------------------------------\n",
            "Episode 1500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6069\n",
            "  reward       |  1.2645\n",
            "----------------------------------------\n",
            "Episode 1600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6539\n",
            "  reward       |  1.216\n",
            "----------------------------------------\n",
            "Episode 1700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6990\n",
            "  reward       |  1.135\n",
            "----------------------------------------\n",
            "Episode 1800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7455\n",
            "  reward       |  1.1435\n",
            "----------------------------------------\n",
            "Episode 1900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7881\n",
            "  reward       |  1.1795\n",
            "----------------------------------------\n",
            "Episode 2000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8287\n",
            "  reward       |  1.3315\n",
            "----------------------------------------\n",
            "Episode 2100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8739\n",
            "  reward       |  1.048\n",
            "----------------------------------------\n",
            "Episode 2200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9176\n",
            "  reward       |  1.2175\n",
            "----------------------------------------\n",
            "Episode 2300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9608\n",
            "  reward       |  1.0805\n",
            "----------------------------------------\n",
            "Episode 2400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10022\n",
            "  reward       |  1.2055\n",
            "----------------------------------------\n",
            "Episode 2500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10433\n",
            "  reward       |  1.2105\n",
            "----------------------------------------\n",
            "Episode 2600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10901\n",
            "  reward       |  1.205\n",
            "----------------------------------------\n",
            "Episode 2700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11321\n",
            "  reward       |  1.0445\n",
            "----------------------------------------\n",
            "Episode 2800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11750\n",
            "  reward       |  1.156\n",
            "----------------------------------------\n",
            "Episode 2900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12217\n",
            "  reward       |  1.1595\n",
            "----------------------------------------\n",
            "Episode 3000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12668\n",
            "  reward       |  1.1525\n",
            "----------------------------------------\n",
            "Episode 3100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13111\n",
            "  reward       |  1.202\n",
            "----------------------------------------\n",
            "Episode 3200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13520\n",
            "  reward       |  1.242\n",
            "----------------------------------------\n",
            "Episode 3300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13979\n",
            "  reward       |  1.1835\n",
            "----------------------------------------\n",
            "Episode 3400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14446\n",
            "  reward       |  1.1805\n",
            "----------------------------------------\n",
            "Episode 3500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14909\n",
            "  reward       |  1.233\n",
            "----------------------------------------\n",
            "Episode 3600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15317\n",
            "  reward       |  1.091\n",
            "----------------------------------------\n",
            "Episode 3700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15717\n",
            "  reward       |  1.1655\n",
            "----------------------------------------\n",
            "Episode 3800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  16169\n",
            "  reward       |  1.2375\n",
            "----------------------------------------\n",
            "Episode 3900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  16623\n",
            "  reward       |  1.137\n",
            "----------------------------------------\n",
            "Episode 4000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  17070\n",
            "  reward       |  1.2745\n",
            "----------------------------------------\n",
            "Episode 4100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  17541\n",
            "  reward       |  1.109\n",
            "----------------------------------------\n",
            "Episode 4200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  18044\n",
            "  reward       |  1.1315\n",
            "----------------------------------------\n",
            "Episode 4300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  18441\n",
            "  reward       |  1.192\n",
            "----------------------------------------\n",
            "Episode 4400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  18882\n",
            "  reward       |  1.2745\n",
            "----------------------------------------\n",
            "Episode 4500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  19331\n",
            "  reward       |  1.1175\n",
            "----------------------------------------\n",
            "Episode 4600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  19806\n",
            "  reward       |  1.132\n",
            "----------------------------------------\n",
            "Episode 4700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  20203\n",
            "  reward       |  1.204\n",
            "----------------------------------------\n",
            "Episode 4800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  20633\n",
            "  reward       |  1.267\n",
            "----------------------------------------\n",
            "Episode 4900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  21111\n",
            "  reward       |  1.247\n",
            "----------------------------------------\n",
            "\n",
            "Logs saved in experiments/limit_holdem_doublq_result/\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make the environments with Limit Texas Hold'em\n",
        "env = rlcard.make('limit-holdem')\n",
        "eval_env = rlcard.make('limit-holdem')\n",
        "\n",
        "# Initialize the DoubleQLearningAgent\n",
        "DoubleQAgent = DoubleQLearningAgent(num_actions=env.num_actions)\n",
        "\n",
        "# Set the agents in the environment\n",
        "env.set_agents([DoubleQAgent, RandomAgent(num_actions=env.num_actions)])\n",
        "eval_env.set_agents([DoubleQAgent, RandomAgent(num_actions=env.num_actions)])\n",
        "\n",
        "\n",
        "with Logger(\"experiments/limit_holdem_doublq_result/\") as logger:\n",
        "    for episode in range(5000):\n",
        "        # Generate data from the environment\n",
        "        trajectories, payoffs = env.run(is_training=True)\n",
        "\n",
        "        # Reorganize the data to be state, action, reward, next_state, done\n",
        "        trajectories = reorganize(trajectories, payoffs)\n",
        "\n",
        "        # Feed transitions into agent memory, and train the agent\n",
        "        for ts in trajectories[0]:  # Only use trajectories of the learning agent\n",
        "            DoubleQAgent.feed(ts)\n",
        "\n",
        "        # Evaluate the performance every 100 episodes\n",
        "        if episode % 100 == 0:\n",
        "            print(f'Episode {episode}')\n",
        "            logger.log_performance(\n",
        "                env.timestep,\n",
        "                tournament(\n",
        "                    eval_env,\n",
        "                    1000\n",
        "                )[0]\n",
        "            )\n",
        "\n",
        "    # Get the paths for the learning curve\n",
        "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_curve(csv_path, fig_path, 'Double-Q-Learning on Limit Texas Hold\\'em')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2367e2f3",
      "metadata": {
        "id": "2367e2f3"
      },
      "source": [
        "\n",
        "### 3.2.4 Conclusion\n",
        "\n",
        "Despite experimenting with various parameter setups, double Q-Learning seems to struggle with poker, likely due to the inherent complexities of the game, which include partial observability, high dimensionality, and the stochastic nature of outcomes. Since poker is a game of incomplete information where players cannot see their opponents' cards, tabular methods like Double Q-Learning may struggle accurately assess and learn effective strategies. The high variance in rewards, driven by the random dealing of cards and the complex interplay of strategic decisions, further complicates the learning process, leading to instability and poor convergence in the agent's performance. These factors challenge the Double Q-Learning algorithm, causing it to struggle in effectively learning and optimizing strategies in the context of poker. Nonetheless, the agent achieves positive rewards around 1.15, clearly outperforming the random agent."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccf8d3cb",
      "metadata": {
        "id": "ccf8d3cb"
      },
      "source": [
        "## 3.3 Extending Standard Double Q-Learning to a Double Deep Q-Network (Double DQN) <a class=\"anchor\" id=\"3.3\"></a>\n",
        "\n",
        "Moving from standard Double Q-learning with a Double Deep Q-Network (Double DQN) is a logical progression, given the previous algorithms struggle with the complex environment of poker, which features large state spaces. As outlined previoulsy, standard methods may not be sophisticated enough for limit-holdem: By extending the double-Q learning meachnism with the deep learning approach of DQN, we aim to enhance the agent's performance and stability.\n",
        "\n",
        "### 3.3.1 Advantages of Double DQN Over Standard Double Q-Learning\n",
        "\n",
        "1. **Reduction of Overestimation Bias**: Double DQN retains the primary advantage of Double Q-learning, significantly reducing the overestimation bias by decoupling the selection of the action from its evaluation. This is done by using two networks, which independently approximate the Q-function, but unlike standard Double Q-learning, they use deep neural networks to manage complex state representations.\n",
        "\n",
        "2. **Handling Large State Spaces**: Double Q-learning, in its tabular form, struggles with large state spaces due to the curse of dimensionality. Double DQN uses neural networks to approximate the Q-function, allowing it to efficiently handle high-dimensional state spaces found in games like poker.\n",
        "\n",
        "3. **Improved Generalization**: Neural networks can generalize across similar states due to their function approximation capabilities. This means that in poker, Double DQN can learn strategic similarities across different but related game situations, which tabular methods cannot efficiently accomplish.\n",
        "\n",
        "4. **Stability and Efficiency**: Double DQN incorporates experience replay and fixed Q-targets. These features help stabilize the learning process by breaking correlations between updates and making learning more efficient through repeated sampling of past experiences. Further, it can perform batch updates using mini-batches from the replay buffer, enhancing learning from a diverse set of experiences.\n",
        "\n",
        "### 3.3.2 Double Deep Q-Network (Double DQN) Outline\n",
        "\n",
        "Double DQN extends (sinlge) DQN by using two neural networks, typically referred to as the evaluation network and the target network, to reduce bias in the Q-function approximation:\n",
        "\n",
        "1. **Neural Network Approximators**:\n",
        "   - Two neural networks are used, $ Q(s, a; \\theta) $ and $ Q(s, a; \\theta') $, where $ \\theta $ are the parameters of the primary (online) network and $ \\theta' $ are the parameters of the target network.\n",
        "   - These networks have the same architecture but are updated differently to reduce overestimation bias.\n",
        "\n",
        "2. **Experience Replay**:\n",
        "   - Like DQN, Double DQN uses a replay buffer to store transitions $ (s, a, r, s') $ and samples random mini-batches from this buffer to update the network, which helps to reduce correlation between sequential updates.\n",
        "\n",
        "3. **Target Calculation with Double Q-Learning**:\n",
        "   - Double DQN modifies the target calculation to reduce overestimation by decoupling the selection and evaluation of the action:\n",
        "     $\n",
        "     y = r + \\gamma Q(s', \\arg \\max_{a'} Q(s', a'; \\theta); \\theta')\n",
        "     $\n",
        "     Here, $ \\arg \\max_{a'} Q(s', a'; \\theta) $ selects the action using the online network, but the evaluation (action value) is done using the target network $ \\theta' $.\n",
        "\n",
        "4. **Loss Function and Optimization**:\n",
        "   - The loss function remains the mean-squared error, but the targets are computed as:\n",
        "     $\n",
        "     L(\\theta) = \\mathbb{E}_{(s, a, r, s') \\sim \\mathcal{D}} \\left[ \\left( y - Q(s, a; \\theta) \\right)^2 \\right],\n",
        "     $\n",
        "     where $ y $ is computed using the Double DQN target.\n",
        "   - Update the parameters $ \\theta $ using an optimizer like Adam on this loss.\n",
        "\n",
        "5. **Periodic Updates**:\n",
        "   - Periodically update the parameters $ \\theta' $ of the target network to match those of the online network $ \\theta $, stabilizing the targets.\n",
        "\n",
        "### 3.3.3 Application to Poker\n",
        "\n",
        "In poker, specifically in games like Limit Texas Hold'em, applying Double DQN involves several adaptations to suit the specifics of the game:\n",
        "\n",
        "1. **State and Action Representation**:\n",
        "   - The state $ s $ includes numerical representations of the cards, betting history, and other features.\n",
        "   - Actions (fold, check, call, bet/raise) are represented as the output of the neural network, with each output node providing the Q-value for one action.\n",
        "\n",
        "2. **Learning from Experience**:\n",
        "   - As the agent plays hands of poker, it stores the transitions in the replay buffer.\n",
        "   - It then samples from this buffer to train the network, adjusting the network weights to minimize the difference between the predicted Q-values and the Double DQN targets.\n",
        "\n",
        "3. **Strategy Adaptation**:\n",
        "   - Uses an epsilon-greedy policy based on the Q-values to explore different actions and refines the strategy.\n",
        "   - Decreases epsilon over time to move from exploration to exploitation as the agent's strategy improves.\n",
        "\n",
        "4. **Network Training**:\n",
        "   - The neural network is trained using experiences sampled from the replay buffer.\n",
        "   - Target network is periodically updated to help stabilize the learning process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a15790c",
      "metadata": {
        "id": "3a15790c"
      },
      "source": [
        "### 3.3.4 Implementing Double DQN for Poker\n",
        "\n",
        "To implement Double DQN, we can utilize the existing `DQNAgent` provided by RLCard. Upon closer examination, the `DQN agent` mentioned in RLCard's documentation is actually a Double DQN agent. Therefore, we can directly call this method and use it with the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "k36ZdwjMoyY1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k36ZdwjMoyY1",
        "outputId": "7ab6c5d9-6fd4-4749-dccf-60aa6bd73057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1\n",
            "  reward       |  0.763\n",
            "----------------------------------------\n",
            "INFO - Step 100, rl-loss: 3.6449947357177734\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 137, rl-loss: 2.985814094543457Episode 100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  269\n",
            "  reward       |  -0.0145\n",
            "----------------------------------------\n",
            "INFO - Step 267, rl-loss: 2.0871012210845947Episode 200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  540\n",
            "  reward       |  0.2385\n",
            "----------------------------------------\n",
            "INFO - Step 406, rl-loss: 1.8655469417572021Episode 300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  812\n",
            "  reward       |  0.5845\n",
            "----------------------------------------\n",
            "INFO - Step 562, rl-loss: 2.28468656539917Episode 400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1126\n",
            "  reward       |  0.741\n",
            "----------------------------------------\n",
            "INFO - Step 701, rl-loss: 2.234687089920044Episode 500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1397\n",
            "  reward       |  0.927\n",
            "----------------------------------------\n",
            "INFO - Step 864, rl-loss: 4.452870845794678Episode 600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1721\n",
            "  reward       |  1.2615\n",
            "----------------------------------------\n",
            "INFO - Step 1041, rl-loss: 0.9412297010421753Episode 700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2064\n",
            "  reward       |  1.476\n",
            "----------------------------------------\n",
            "INFO - Step 1100, rl-loss: 1.062719464302063\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 1176, rl-loss: 1.5686845779418945Episode 800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2338\n",
            "  reward       |  1.4655\n",
            "----------------------------------------\n",
            "INFO - Step 1331, rl-loss: 4.730869770050049Episode 900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2637\n",
            "  reward       |  1.6885\n",
            "----------------------------------------\n",
            "INFO - Step 1483, rl-loss: 0.7789482474327087Episode 1000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2946\n",
            "  reward       |  1.6975\n",
            "----------------------------------------\n",
            "INFO - Step 1640, rl-loss: 0.916500985622406Episode 1100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3253\n",
            "  reward       |  1.487\n",
            "----------------------------------------\n",
            "INFO - Step 1791, rl-loss: 0.7212046384811401Episode 1200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3545\n",
            "  reward       |  2.1015\n",
            "----------------------------------------\n",
            "INFO - Step 1932, rl-loss: 0.6052606105804443Episode 1300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3828\n",
            "  reward       |  1.685\n",
            "----------------------------------------\n",
            "INFO - Step 2070, rl-loss: 1.6956108808517456Episode 1400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4113\n",
            "  reward       |  2.105\n",
            "----------------------------------------\n",
            "INFO - Step 2100, rl-loss: 1.0325556993484497\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 2201, rl-loss: 3.7491607666015625Episode 1500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4385\n",
            "  reward       |  2.01\n",
            "----------------------------------------\n",
            "INFO - Step 2367, rl-loss: 1.9917359352111816Episode 1600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4693\n",
            "  reward       |  1.765\n",
            "----------------------------------------\n",
            "INFO - Step 2517, rl-loss: 0.7170793414115906Episode 1700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4999\n",
            "  reward       |  2.113\n",
            "----------------------------------------\n",
            "INFO - Step 2668, rl-loss: 0.9079917669296265Episode 1800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5298\n",
            "  reward       |  2.137\n",
            "----------------------------------------\n",
            "INFO - Step 2831, rl-loss: 3.488947868347168Episode 1900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5626\n",
            "  reward       |  2.121\n",
            "----------------------------------------\n",
            "INFO - Step 2976, rl-loss: 2.040963649749756Episode 2000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5911\n",
            "  reward       |  2.0745\n",
            "----------------------------------------\n",
            "INFO - Step 3100, rl-loss: 0.48154541850090027\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 3149, rl-loss: 1.086915135383606Episode 2100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6252\n",
            "  reward       |  2.3475\n",
            "----------------------------------------\n",
            "INFO - Step 3319, rl-loss: 1.4897922277450562Episode 2200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6593\n",
            "  reward       |  2.1825\n",
            "----------------------------------------\n",
            "INFO - Step 3468, rl-loss: 0.5070288777351379Episode 2300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6908\n",
            "  reward       |  2.0255\n",
            "----------------------------------------\n",
            "INFO - Step 3638, rl-loss: 1.5233739614486694Episode 2400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7265\n",
            "  reward       |  2.238\n",
            "----------------------------------------\n",
            "INFO - Step 3792, rl-loss: 1.1739776134490967Episode 2500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7555\n",
            "  reward       |  2.2015\n",
            "----------------------------------------\n",
            "INFO - Step 3962, rl-loss: 0.5176903009414673Episode 2600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7906\n",
            "  reward       |  2.168\n",
            "----------------------------------------\n",
            "INFO - Step 4100, rl-loss: 1.8566880226135254\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 4129, rl-loss: 0.9325404763221741Episode 2700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8241\n",
            "  reward       |  2.107\n",
            "----------------------------------------\n",
            "INFO - Step 4299, rl-loss: 0.59315425157547Episode 2800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8585\n",
            "  reward       |  2.3425\n",
            "----------------------------------------\n",
            "INFO - Step 4453, rl-loss: 0.69315505027771Episode 2900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8896\n",
            "  reward       |  2.038\n",
            "----------------------------------------\n",
            "INFO - Step 4616, rl-loss: 2.4564597606658936Episode 3000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9221\n",
            "  reward       |  2.0955\n",
            "----------------------------------------\n",
            "INFO - Step 4795, rl-loss: 1.5662524700164795Episode 3100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9575\n",
            "  reward       |  2.176\n",
            "----------------------------------------\n",
            "INFO - Step 4949, rl-loss: 5.798101425170898Episode 3200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9889\n",
            "  reward       |  2.09\n",
            "----------------------------------------\n",
            "INFO - Step 5100, rl-loss: 3.521867513656616\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 5115, rl-loss: 2.6942262649536133Episode 3300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10237\n",
            "  reward       |  2.1995\n",
            "----------------------------------------\n",
            "INFO - Step 5285, rl-loss: 2.0500621795654297Episode 3400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10587\n",
            "  reward       |  1.915\n",
            "----------------------------------------\n",
            "INFO - Step 5446, rl-loss: 0.8190786242485046Episode 3500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10918\n",
            "  reward       |  2.4005\n",
            "----------------------------------------\n",
            "INFO - Step 5626, rl-loss: 0.5282663702964783Episode 3600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11282\n",
            "  reward       |  2.2135\n",
            "----------------------------------------\n",
            "INFO - Step 5785, rl-loss: 3.00771164894104Episode 3700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11600\n",
            "  reward       |  2.2625\n",
            "----------------------------------------\n",
            "INFO - Step 5938, rl-loss: 1.8960856199264526Episode 3800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11914\n",
            "  reward       |  2.349\n",
            "----------------------------------------\n",
            "INFO - Step 6096, rl-loss: 0.4981987476348877Episode 3900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12249\n",
            "  reward       |  2.256\n",
            "----------------------------------------\n",
            "INFO - Step 6100, rl-loss: 2.4852747917175293\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 6245, rl-loss: 1.0665967464447021Episode 4000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12558\n",
            "  reward       |  2.23\n",
            "----------------------------------------\n",
            "INFO - Step 6406, rl-loss: 0.9300532341003418Episode 4100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12885\n",
            "  reward       |  2.3185\n",
            "----------------------------------------\n",
            "INFO - Step 6556, rl-loss: 1.3656927347183228Episode 4200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13198\n",
            "  reward       |  2.046\n",
            "----------------------------------------\n",
            "INFO - Step 6720, rl-loss: 0.40031784772872925Episode 4300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13525\n",
            "  reward       |  2.0295\n",
            "----------------------------------------\n",
            "INFO - Step 6861, rl-loss: 0.5662065744400024Episode 4400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13834\n",
            "  reward       |  2.2205\n",
            "----------------------------------------\n",
            "INFO - Step 7029, rl-loss: 6.433093070983887Episode 4500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14179\n",
            "  reward       |  2.1115\n",
            "----------------------------------------\n",
            "INFO - Step 7100, rl-loss: 2.8452036380767822\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 7213, rl-loss: 1.9105793237686157Episode 4600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14562\n",
            "  reward       |  2.0485\n",
            "----------------------------------------\n",
            "INFO - Step 7386, rl-loss: 3.2277181148529053Episode 4700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14920\n",
            "  reward       |  2.4465\n",
            "----------------------------------------\n",
            "INFO - Step 7568, rl-loss: 1.9546263217926025Episode 4800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15299\n",
            "  reward       |  2.2265\n",
            "----------------------------------------\n",
            "INFO - Step 7753, rl-loss: 0.4928933382034302Episode 4900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15675\n",
            "  reward       |  2.1685\n",
            "----------------------------------------\n",
            "INFO - Step 7917, rl-loss: 6.39052152633667\n",
            "Logs saved in experiments/limit_holdem_dqn_result/\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB550lEQVR4nO3dd3yT1f4H8E+SJulMF520pWVDgVJ2GYLKRhH1KuJAvMq9KvwcKF5xol7FqyJw1QuOqzgvTlwoUIGCQNl775bRBR3pTDPO74/0SRua7ow2+bxfr760yZPnOScJybfnfM/3yIQQAkREREQeRO7qBhARERE5GwMgIiIi8jgMgIiIiMjjMAAiIiIij8MAiIiIiDwOAyAiIiLyOAyAiIiIyON4uboBzmYymXDp0iUEBARAJpO5ujlERETUCEIIFBcXIzo6GnJ5y8dvPC4AunTpEmJjY13dDCIiImqG8+fPIyYmpsXn8bgAKCAgAID5CdRoNHY9t16vx9q1azF27FgolUq7nru18IQ+Ap7RT0/oI+AZ/fSEPgLspztpTh+1Wi1iY2Mt3+Mt5XEBkDTtpdFoHBIA+fr6QqPRuPWb1t37CHhGPz2hj4Bn9NMT+giwn+6kJX20V/oKk6CJiIjI4zAAIiIiIo/DAIiIiIg8jksDoAULFmDgwIEICAhAeHg4pkyZguPHj9f7mOXLl0Mmk1n9eHt7O6nFRERE5A5cGgBt3LgRs2bNwrZt25Camgq9Xo+xY8eitLS03sdpNBpkZWVZfjIyMpzUYiIiInIHLl0Ftnr1aqvfly9fjvDwcOzevRvXXHNNnY+TyWSIjIx0dPOIiIjITbWqZfBFRUUAgJCQkHqPKykpQYcOHWAymdCvXz+89tprSExMtHmsTqeDTqez/K7VagGYl+Dp9Xo7tRyWc9b8rzvyhD4CntFPT+gj4Bn99IQ+AuynO2lOH+39fMiEEMKuZ2wmk8mEyZMno7CwEJs3b67zuPT0dJw8eRJ9+vRBUVER3nrrLWzatAmHDx+2WRly/vz5eOmll2rd/tVXX8HX19eufSAiIiLHKCsrw5133omioiK71PFrNQHQQw89hN9//x2bN29uUolrvV6PHj16YNq0aXjllVdq3W9rBCg2NhaXL192SCHE1NRUjBkzxq2LV7l7HwHP6Kcn9BHwjH56Qh8B9tOdNKePWq0W7dq1s1sA1CqmwGbPno1ff/0VmzZtavL+HkqlEsnJyTh16pTN+9VqNdRqtc3HOeqN5chztxae0EfAM/rpCX0EPKOfntBHgP10J03po72fC5euAhNCYPbs2Vi5ciXWr1+PhISEJp/DaDTi4MGDiIqKckALiYiIyB25dARo1qxZ+Oqrr/DTTz8hICAA2dnZAIDAwED4+PgAAKZPn4727dtjwYIFAICXX34ZQ4YMQefOnVFYWIg333wTGRkZeOCBB1zWDyIiImpbXBoALV26FAAwatQoq9s/+eQTzJgxAwCQmZkJubx6oKqgoAAzZ85EdnY2goOD0b9/f2zduhU9e/Z0VrOJiIjaPJNJwCgElArP3BTCpQFQY/Kv09LSrH5ftGgRFi1a5KAWERERuT+jSWDSv/+EwSTw6/8Nh7dS4eomOZ1nhn1EREQe7OzlEhzLLsap3BKsO5rr6ua4BAMgIiIiD3P4ktby/yv3XnBhS1yHARAREZGHOVIjAEo7nocrJbp6jnZPDICIiIg8TM0RIINJYNXBLBe2xjUYABEREXkQIQSOZJkDoCl9owEAP+y56MomuQQDICIiahSjSeCJb/bjnXUnXd0UaoFsbQXySyuhkMvw5LhuUMhl2He+EGfySlzdNKdiAERERI1y4EIhvt9zAQtTT+Dc5VJXN4eaScr/6Rzmj5hgX4zo0g4A8ONezxoFYgBERESNcu5KddDz1Y5MF7aEWkLK/+kZbd5Q9Obk9gCAlfsuNqo+n7tgAERERI1y9nKZ5f+/3XUeFXqjC1tDzSWNACVWBUBje0bCT6XA+fxy7MoocGXTnIoBEBERNUrNaa+CMj1+P+R5K4fcweGsIgBAzyhzAOSjUmB8L/OG4p6UDM0AiIiIGiWjagqsd/tAAMAX2zgN1tYUletxPr8cQPUUGADc0s88DbbqwCWPGdljAERERA0SQuBs1QjQU+O7wUsuw+6MAhzN0jbwSGpNpNerfZAPgnxVltuHdAxFpMYb2goDNhzzjK0xGAARUS0VeiOW/HESp3KLXd0UaiUKyvTQVhgAAAM6hGBcYiQA4IttGQ697oELhZj52S7sOJvv0Ot4iiNXJUBLFHIZbkquqgnkIavBGAARUS1fbs/Eoj9O4P/+t8+jVoXYkl9aiduXpeOjP8+4uikuJY3+RAV6w0elwF1D4gCYl06X6AwOuWZesQ4PfLoLqUdyMPOzXbhYWO6Q63gSywqwKE2t+25JjgEApB3PRUFppVPb5QoMgIiols0n8wCYh8u3e/hf3j/suYAd5/KxNO20RweDUgJ0fKgfACClYyg6hfmhtNKIlQ4YMTCaBB5dsRe5xeY9qorK9Xj06wMwmOx+KY8iVYBOjK4dAHWLDEDPKA30RoFfPWBrDAZARGSl0mCyCno+3nzWha1xvdQjOQCAK6WVuFDguSMQUgJ0fDtfAIBMJsNdgzsAAL7clmH34HDxHyew9fQV+KoU+OS+gdB4e2H/hSL8nMGvrebSGYw4mWOe1r56CkwiJUOv3OP+O8TznUREVvZfKERZpRG+KgUAIPVoDjKvlDXwKPdUUFppVRdl7/lC1zXGxc5WvQekESAAuLV/DLyVchzLLsZuO9aP2XA8F++sPwUAWHBLb1zbLRwLb+8LANiYLcfqwzl2u9bVzuSV4J+/HkGOtsJh13CVkzklMJgEAn2UaB/kY/OYyUnRkMuAPZmFbl/tmwEQEVnZcuoyAODa7uG4pmsYhAA+TT/n2ka5yIbjuTCaqkc29mUWuq4xLmaZAmtXHQAF+igxOcmcOGuvZOiLheV4/Ot9AIB7hnTATX3NIxJjekbggeHxAIB5Kw875Mu5qEyPez/ZgY82n8X7G90v56tmAUSZTGbzmHCNN4Z3CQMAh0xttiYMgIjIihQADe/cDvcNiwcAfLPzvMMSXVszaforoepLf995z6mSW5MQwhJwJNQIgADg7iHmabDfDmbjSomuRdepNJjw8Jd7UFimR5+YQDx3Qw+r++eM7oyOAQIlOgMe/nKPXevVmEwCj32911IjZ/vZK3Y7d2tx+JJ1AcS63FK1NcaPbr41BgMgIrIo1Rmwt2qUY1indhjZJQwdw/xQrDPgu13nXds4J6vQG7HxhDkZ/PExXQEAhy5pUemBWbj5pZUo1hkgkwFxIb5W9/WJCUKfmEBUGk34dnfL8kZe++0o9p8vRKCPEu/d2Q9qL4XV/UqFHPd2MSLYV4kjWVq89MuRFl2vpnc3nMKG43lQeZm/Fo9kaaGt0Nvt/K2BJQG6ff0B0NjECPiqFMi4UoY9me4b9DMAIiKLHWfzYTAJxIb4IC7UF3K5DPcNjQcALN96DiaT+/41eLX001dQVmlEpMYbN/SOQpCvEpUGE45le17hP2kT1CiNN7yVilr3312VDP3V9sxmv0d+2X8Jy7eeAwC8fXsSYq8KtCRBauDt2/pAJgP+tyMTK/e2PFk37XguFv1xAgDw6pReiA/1hRDA7nPu8+VvMonqGkBRgfUe66vywvhe5jpP7rw1BgMgIrKQpr+GdWpnue2WfjHQeHvh3JUybDjuGRViAWBt1fTX6J7hkMtlSIoJAgDs88BEaGkT1Pirpr8kNyZFQ+Pthcz8MmyqKqHQFKdyS/D09wcAAA+P6oTre0TUe/zwzqF45LouAIBnfjhkWdnUHOfzy/DY1/sgBHDn4DjcNiAWgxJCAMCtSkBk5pehtNIIlZccncJsv441STWBfj2QBZ3BPbfGYABERBZbTpvzHoZ2rg6A/NReuGOQuejdJ1vOuaJZTmcyCaw7ag6AxvQ0/yWcHBcEAJYpQk9iKwG6Jh+VArf2N39hNnV/sLJKAx7+cjdKK40Y0jEEc6qmGxvyyPVdMKxzKMr1Rjz05R6UVTY9R61Cb7TkHCXFBOLFG3sCAAYlhAIAdrhRHpBUALF7ZAC8FA1/9ad0CkWERo2icj02HGt6UNsWMAAiIgDA5RKdZZ+goZ1Cre6bntIBchmw+dRlHM92/+0xDlwsQm6xDv5qLwzpaB4N6BsbBMBDR4CqpsASQuseOZBqAq0/ltPois1CCDy38hBO5JQgLECNf09LbtSXM2DeumHx1GSEB6hxKrcEz6481OSE3fk/H8bBi0UI9lXiP3f3t+QcDa4aATpwoQjlle4x+nGkagd4WwUQbVHIZZhStQLPHtOMrREDICICYM55Acx/IbbzV1vdFxPsa9n7aflW9y+MmHokGwAwsmuY5UtRCoDOXi5FYZn7bxNQk1QEsUOo7bwcAOgc7o+UjqEwCWDFjoZHgQxGE/61+jh+2HsRchnwzrRkhAd4N6ldYQFqvDMtGQq5DCv3XsSKnY1P1P9m53ms2HkeMhnw72nJVnVxYoJ9EBXoDYNJYK+bJAHXtwVGXW6uKoq4/liuW77nGQAREQBg6+nq5e+2/HV4AgBzUmS+m+8TJC1/H9OzOhclyFdVYzl8oSua5RLmJfDmHKCrl8BfTVoSv2LneeiNda+Wu1BQhqkfbMOyjacBAE9P6I4hHUPrPL4+gzuG4smx3QAAz/94CLO+3IPNJy/Xm4x96GIRnvvpEADgiTFdMaKq7o1EJpO5XR5Q9Sao9SdA19Q9UoMeVVtjrHLDrTEYABERAPP0FgAMqyMAGtAhGL3aa6AzmPC/RvyF31ZlXCnFiZwSKOQyXNst3Oo+T5wGu1xSiZKqJfB1rcySjE2MQFiAGnnFOqyto1rz7wezMHHJn9idUYAAby+8d2c//O2aTi1q49+v6YgpfaNhMJm/qO/+73ZcuzANS9NOI6/YujZRYVklHvxiNyoNJozuEY6HR3W2eU4pAHKHXejzinXILdZBJjOP8DaFVBNopRuuBmMARETIvFKG8/nl8JJX/+V7NZlMhr8OM48CfZ6eUe9f+M1hNAm8u/4kvt113qr6srNJoz+DE0IQ6Ku0us8TAyBpCXx0oI/NJfA1KRVy3DEwFkDtytAVeiOeWXkQD325B9oKA5LjgvDbIyMwqU9Ui9sol8uw+I5krHpkOO4Z0gEBai9kXCnDv1YfQ8qCdXj4y93482QeDEYTHvt6Hy4UlKNDqC8W3t4XcrntishSHtCezII2X/tJqv+T0M4PfmqvJj32pr7mrTF2ZRS43ZY4DICICFuqpr+S44Lq/YCc1CcK7fzVyNZW4PdD2XZtw68HLuGttScw97sDmPLeFpflXkgB0GgbS7GlAGj/+UK3rpBbU10VoOsybVAc5DIg/cwVnMotAQCcyCnGTe9uwVfbMyGTmZe6f/P3lAZHlJoqMToQr0zphe3PXo83/tIHfWODYDAJ/HYwG/f8dwcGvvoH0o7nwVspx9K7+iPQR1nnuTqF+SPETwWdwYSDFwvt2k5na2wFaFvCNd6WUWF32xqDARARWer/DO1ke/pLovZS4J6qPA977xL/Y40P14MXi3Dzf7biqe/2t3h7haYoKK3EznPmKY+a+T+SHlEaqLzkKCjTI8PN/hquy7lGJEDXFB3kg+u6m5+7L7dn4KvtmZj87mYczylGWIAan/91MJ4a3x3KRq72ag5flRduHxCLH2cNw2+PjMD0FPOoUEGZubLzq1N617kbukQmk2FQvOPzgM5eLkWpg7eZqd4DrPH5PzXdXDUN9sX2DBy8UGS3drkaAyAiD2cyCcsKsLryf2q6c3AcVAo59p0vtFuZ/CslOmw6aQ7Cvvl7Cv5SVVPmm10XcO1bafgs/ZxTpsXWH8uFSZjzJGyNTqi85JZlxJ4yDdbYBOia7h5irhu1fOs5PLPyICr0JozsGobfHx2B4V0afo/ZU89oDV6+yTwqtGhqEt69M9lSs6ghjs4DOnChENcvTMPUD9IdOs1WnQDd9BEgABjfKxLxob7IK9bhlqVb8NGfZ9xiBJQBEJGHO55TgiullfBVKSxTPPUJC1Bjcl/zDuD2Koz428EsGE0CvdsHYlBCCN66LQnfP5SCxGgNtBUGvPDTYdz4zmbsznBsQqo0/TXWxuiPxNPygM5KRRDrqQF0tWu6hCEuxLydhJdchmcn9sAnMwbWKq/gTL4qL9ycHIMb+kQ3+jFSALTrXIFDAvDvdl+ASQCHLmrx7oZTdj8/YN7fT6rj1JwpMMD83P04axjGJUZAbxT456qj+OvynU4dnXUEBkBEHi79jHn0Z1BCiGUjyIZIu8T/fjALWUWNK3pXnx/3XQJgTriU9O8Qgp9nD8crNyVC4+2FI1la3Lo0HY9/vQ+ncu1fjLFCb7Rs4yBVf7ZFCoD2tpEAKL+0EmnHc5v1F7sQwjIFVlcVaFvkchn+dWsf3NAnCt8/NBQzr+lYZ7Jxa9YjSoMAtRdKdAZLkVB7MRhN+K3G0vL/bDiFQxftP710LFsLIYDwADXCApofgAb5qrDs7v54ZUovqLzk2HA8DxOW/Gkpn9EWMQAi8nBbz5hHVeqq/2NLYnQgBieEwGAS+Dw9o+EH1ON8fhl2ZxRAJjPvKVWTQi7DPSnx2PDkKEwdYF5dtHLvRYx+exPuX74T285csdtQfM3NT3vVs1t2cmwwAODIpSJU6Ft3leAKvRG3v5+OGZ/sxPpjTd/HLa9Eh7JKI+QyIDbEp+EH1JDSKRTv3tkPSY0YVWytFHIZBsSbX297T4NtP5uPyyWVCPJVYmzPCBhMAk9+u9/uU2HV+T/NG/2pSSaT4Z4hHfDTrGHoHO6P3GId7vpoOxauPQ6DnVeFOgMDICIPZjABO6t2vG4oAfpq91Utif/fjswWbRfw8/5LVdcPRYTGdiXgUH81/vWXPvh59jCMT4yETAasO5aLOz7YhsnvbsHP+y+1+AO45uanMlndoxWxIT4I9VNBbxSW5cWt1aLUE5aVWM0JgKT8n+ggH0tFbE9TvS+YfQOgXw+Y3/cTekXitVt6I8RPhWPZxXafCjvcwvwfW3pEafDz7GG4Y2AshADeWX8Kd3ywrdFboLQWDICIPFhGCVBWaUSIn6rJBdLG9IxATLAPCsr0+HFf85bHCiEsq79uqtp3qD59YoKw7J7+WP/EKNwzpAO8lXIcvFiER/63FyPfTMN/N59FSTNW1JhMAn9ctflpXWQyWXUekIM2RjWZBApaWG17T2YBPvzzjOV3KdG9KZq6BN4dWRKhz+XbbbRRbzRZykjc0Cca7fzVePmmRADmqTApaLEHKUhv7gqwuviqvPD6rX3wzrRkBKi9sCujABMWb8LqQ22nYjQDICIPdqLI/BEwtFNok3M0FHIZZgyNBwB8uvVcs74cjmYV42RuCVRecozvVX/gUVNCOz+8MqUXtj59PeaM6YpQPxUuFpbjlV+PIGXBOrz++zFkF1U0+nz7LxQi76rNT+vjyETo4go9blm6FYNfW4f1x2xXU25Ihd6IJ7/dD5MAxiVGQC4DzlwubXK+lpQ825QEaHfTu30gvJVy5JdW4nReiV3OufnUZRSW6dHOX23ZAmRS7yhM6BUJg0ng6R8OwR4zYXqjCceqNi9ubgJ0Q25MisaqR0YgKTYI2goDHvxiD5778WCrnx4GGAARebQTReagpzHL3225rX8svJVyHMsutkylNcVPVSNH13cPh8a77qJ0dQnxU+GR67tgy9PXYcEtvdExzA/FFQYs23gaI9/cYJlea4i0+qvm5qf16RsXBMD+AVCF3oiZn+3CvvOFqDSa8NiKfTif3/R6QwvXHseZvFKEB6jxxq1J6B1jbu/WU00bBcpoRgK0u1F5ydEvzpwHZK96QL/uN4+STOwdCUXVHx4ymQyvTOllngrLKcHaiy3/ej6TV4pKgwn+ai/E2bnoZE1xob747sEU/H1kRwDAF9syMeW9LS2aGncGBkBEHqpUZ8C5qj9ohzUx/0cS6Ku0FEn7NP1ckx5rMglLgNKY6a/6eCsVmDYoDn88PhIfTR+AfnFB0BlMeOR/e7F04xk0NDhla/PT+vSpCigy88vsthTYYDRh9ld7se1MPvzVXugeGQBthQEPfbm7SX9N787Ix0dVRSoX3NIbgb5KDO1kHmXY2sRpsLNVOUDxjSyC6K7sWQ9IZzBi7ZHq6a+aak6FpV6UtXgqTKoA3SMqwOGr8JQKOeZN6IHP/joI7fxVGNIxFD6q1p03xgCIyEPtzCiAScgQE+yDuBZ8wU1PiQcArD6U3aRppx3n8pFVVIEAby+M6hbW8AMaQS6XYXTPCHz74FDcX7V7/dt/nMKKM/I69y47d7kUJ3Ntb35al0AfJTqFmUdF9l8obHG7TSaBf3x/EH8czYHKS44Ppw/AxzMGIsRPhUMXtXjplyONOk95pRFPfnsAQgC39ovB9VXbeVQHQJcbPVUphOAIUBXLzvBnWp4HtOnEZRRXGBCp8caADsG17r+hTzTGJ0bAJGR4+odDLVoV1tIK0M1xTdcw/P7oNZg3sbvTrtlcDICIPFT6afNfs0MbkfNSnx5RGgxKCIHRJPDV9sYviZemvyb2impwk82mUshleP6Gnnj5pkTIZcC2XDlmfr4X2gp9rWOl5Gdbm5/Wp2/VcviWJkILIfDqb0fx/Z4LUMhleO/OfkjpFIroIB8suaMvZDLzSrvvd19o8FyL1p3C2culiNCo8cKNPS23D+gQApVCjqyiCpxr5BYeucU1lsAHe/YIUHJsMJQKGbK1FbhQ0LKVTr9UjXpO6hNV56jM/Bu6w89L4FhOCd5df7LZ17KsAHNQ/k9dwgLUbWLVIAMgolbOYDRh/bEcPPzlbtz4zmY8s/IgfthzAZlXylr016hU/0caHWiJe6tGgb7akQmdoeHpGp3BiN8OmqcBahY/tLfpKfFYelcyVHKBLaev4Lal6bWW6q5t4vSXRMoDamlBxPc2nMJ/q6as3ri1j1U7RnQJw2PXdwUAPPvjQRzLrntK5LQWWF5Vk+n1W/tYbfTpo1Iguaq9jS1cJ1WAjgn2bXSBTHflo1JYpj1bkgdUXmm0BNw39Imq87hQfzVuSzCP/LyXdrpZBRKFqC7TYM8l8O7Es9/VRK3Y6bwSvP77MQx9fT3+unwXfjuYjYMXi/DV9kzM+WY/rnlzAwa/tg4Pf7kb/918FvvPF9Y5zXO1yyU6y+qQxqx6asjYxAhEaNS4XFKJ1Y3YJX7j8TwUlesRoVFjcMeWB2D1ua5bGB5JNCI8QI3jOcWY8t4Wy4aO+aWV2FW1+amt3d/rk1xjZ3hTM7dJ+HxbBt5aewIA8MINPW3uUfV/13XGyK5hqNCb8NAXe2yOYpVXGvHVaQWEAG4fEGNzKk+q89TYRGhOf1kbGC/lATW9nIBkw/FclFUaERPs0+C2M8ntBMYnRsDYzAKJFwvLUVSuh5dchi4R/s1usztjAETUipToDPh6ZyZuXboV1y/ciGUbTyO3WIdgXyXuGxaPd6YlY+aIBCTHBUGpkCG3WIffDmbjlV+P4Kb3tqDP/LWY9sE2bGig6J1UEybaVyDUT9XidisVctw12LxL/PKt5xo8/qeqrS8mJ0VbVsE4Uqw/8N3fB6N7ZADyinW4/f10/HEkp8HNT+vTLTIAai85tBXVey01xc/7L+GFnw4BAB65rjP+WpWzdDW5XIbFU/uifZAPzl4uxVPfHqg18rfwj5O4XCFDpEaN527oafM8wzqbA830M1caFbAxAdraYDskQkvFDyf1iaq32KZk/g3dqwskNnEqTMr/6RIR0Camo1zBy9UNICKgqEyPV387gl/2Z6G8asWPXAaM6haO2/qbk1mlaQhpu4gKvRH7zxdiV0YBdlf9FJXrkX7mCtLPXMGsazthzphuNgOMLafM0yBdA+23weMdg2LxzvqT2JtZiAMXCi1TBlcrrtBbpgFauvqrKaICvfHtgyl4+Ms9+PPkZfzt812IDjJv71Df5qd1USrk6N0+ELsyCrAvsxCdwhr/V/aG47mY8/U+CAFMT+mAx8d0rff4YD8V3rurH25bthWrD2fjv5vP4oER5iXH289cwWfbMgEAr01JrLOcQJ+YIPiqFMgvrcTxnGL0aCAv5FwzNkF1Z/3jgyGTAeeulCFHW1Fn1fK6lOgMWHfU/IfJjY3ckDW0alXY7K/24r200xibGIle7RuX0Oyq/J+2hCNA5PZaumrjwIVCyzJpR/l6Vya+2XUB5XojOrbzwz/Gd0f6vOvx8YyBmNA7ymYOhrdSgcEdQzHr2s74eMZA7H1+DFIfvwbTU8wjMe9tOI3pH2+3uUx7y2n7B0DhAd6Y1Nuc1/BZPfuDrTmcA53BhE5hfnbZn6gpAryV+HjGQEwbFAuTgCWhtaHqz3Wp3hi18TWQdp3Lx0Nf7IbBJDA5KRrzb0xs1GhA39ggPF81urPg92PYeS4fZZUGzP3OvOorJdyEEV3qLmeg8pJbpnGkALg+0iaonlwFuiaNt9ISTDRnFGjdUfP7PqFd0973N/SJxsTekTCaBO7573ZsPtm4HK7qCtAMgOrCAIjcWl6xDkNfX4/XfjvarMcLITDzs12Y+dkuhwZBhy6aP6weGtUJ654YiYdGdWryX5hyuQxdIgLw8k298O9pyfBVKbDl1BXc8M5m7Mms/oLOvFKG8/nl8JLL0FljvwAIAKZXVYb+ef8l5NexlYO0+mtK3/aN+uK3N6VCjtdu7o1/jDcv001o51fv5qf1Sa4qkNfYgohHs7T46/KdqNCbcG23MCy8PalJ9VnuGdIBk5OiYTQJzPpyD55beQiZ+WWICvTGlA4N54hYpsEaqAfU3F3g3V1L6gH9UlX88IZGTn/V9M8pvdGrvQYFZXpM/3g73ttwqsFpzCMO2APM3TAAIre2O8Nca0bab6qpCsv1yNGaR1Dm/3zYYZVNpb/WBiWE2CUomJwUjR9nDUPHMD9kFVVg6vvp+CzdvF2FNPrTNzYQajunBiTHBqF3+0BUGkz4euf5WvfnFldYRh8mO3D1V0NkMhkeGtUJax67Bl//bUizn3NpJdixrOIGixXuPJePuz7aDm2FAQPjg/Gfu/pDqWjaR7BMJsOCW3pbduL+oep9/dqURHg3IqFBSoTefja/3s1jc7Q6VOhNUMjNdaLIrLl5QEXlemw6kQegdvHDxgjxU+G7B4di6gDzyOWba47j71/stpkQDwCFZZWW1Y4MgOrGAIjcWm6xzvLfssqmb5JZs2bKxcJyLE2z707NgDmX50zVHkP2nK/vGhGAn2cPx8TekdAbBV746TAe+3of1lXl36TYYfXX1WQymWUK7ottGbW+ZH/dnwWTAJLjgtChFeSWdIsMQHgTR9pqig70RliAGgaTqHep8ve7L+CuD7cjv7QSfWIC8dG9A5tdJddP7YVld/eDb9Xjpw2Kw/DOjVtJ1zNKg0AfJUp0Bhyop73VS+B9mhykuTNpCvF4TnGTNqtdezgblUYTukb4o1sTNx2WeCsV+Ndf+uD1W3pD5SVH6pEcTH5ns83SCNLoT2yIT7O2mPEUfGeTW8vRVlcmPne56XsqZVYFQAFVf14v23jG8uVgL8ezi2ESQKifCuEBarue21/thffu7IfnJvWAQi7DT/su4Y+qREx71P+x5cakaAT7KnGxsBzrrlqNJk1/3ZTkutEfe7LaGd7GNJjJJPCv1cfwxLf7UWk0YUKvSHz9txSrGj3N0Tk8AP+9dyAeHNkJz03q0ejHyeUypHRseBrsHDdBtSnUX43O4eZk953nGj8K9OsBafqr5e/7OwbF4bsHU9A+yAfnrpTh5ve2Wv5dSaQE6MQo51WAbosYAJFby9VWJwCfa8ZSZWkEaFLvKFzTNQyVRhNe/PlwixOrazpaNf3VI0rjkJwYmUyGB0Z0xP9mDrEEWL4qBfo0cjVJU3krFbhjUBwA4LMa+4OdvVyK/ReKoJDLcIObBEBAzUToQqvbyyrN+3gtTTsNAJh9bWe8d2c/u+2PlNIpFE9P6A4/ddMW8w7tXL0tRl2kFWBMgK6tqXlABaWVlmnf+oofNkWfmCD88n/DMaJLO5TrjXh0xT7M//mwpVYQCyA2DgMgcms5xfYJgOLb+eGlyYlQKeTYdCIPaw43XOyvsZz1YTUoIQS/PjIcf+kfgxdu6OnQ6r53DY6DXAZsOXUFp3LNBRelv1KHd26Hdv72HelyJakgYs0tMbKKyvGXpelYczgHKoUci6Ym4clx3Ry+IWVjSHlAu84V1Jm3VD0CxBpAV7PkATVyBGj14WwYTAKJ0Rp0bEKphIaE+Kmw/L5B+L/rOgMw19+a9uE25GgrLJugcgVY/RgAkVvLtZoCa3oAlJkvFYPzQ0I7P/x9pLn2ysu/HGlWTpEt1SNAzcsNaIrwAG+8dVuSZYTGUWKCfS2VlT/dmgEhBH7eJ+387j6jPwDQOyYQMpk5RyyvWIf95wsx+d0tOJKlRTt/Ff73tyG4Obl2hWdX6RTmh/AANXQGk9XqwJqk6eIOHAGqRcoDOnSxCCW6hj8DpL2/7DH9dTWFXIYnxnbDR9MHIMDbC7szCjDp35txOs/8WccRoPoxACK3lltzBKiJOUBC1BwBMv8l/PCozogJ9sGlogq8s77lCdEmk8DRLPMISU83m6+/t2pJ/Pd7LiD99BWcuVwKb6UcYxObV3OntQrwVqJLVV7IwrXHcfv76cgr1qFbRAB+nDUM/W3s+O1KMpnMkv9lKw/IZKpeAp/AHKBaooN8EBviA5MwBzf1bVGRV6zDtjPm59he01+2jO4ZgV9mD0f3yABcLtHBaBII8VMhsgUJ/p6AARC5LZ3BaFWLpqlTYGUGQFth/guvQ4j5i8BHpcCLNyYCAD768wxO5Za0qI0XCspRojNApZCjY5h7fdkM7RSKzuH+KKs04vFv9gEwFxz0b2LOSlsg5QGt2HkeOoMJ13UPx/cPD0VMK91FfWhn8zSYrYKI2doK6AwmeHEJfJ0GJ5gDyHk/HESfl9bgjg/S8fba4/jzZB5Ka4wK/X7IvOoxKTaoyVutNFV8Oz+sfHgYbk5uX9VG+5TUcGfu90lEVCWvavRHLgNMwjwaVKozNDppNK9q9iwq0NsqcXV0j3Bc1z0c64/lYv7Ph/H5/YOa/UEj5f90ifB3u+XGMpkM96Z0wPM/HbbUUnKX1V9XS44Lxje7LgAAHhiegHkTezhlj7PmkkaA9l8wT+PUDEqlPxRiQ3zh5WbvSXuZdW1nlFQYsONcPvJLK7HtTD62nTHnBCnkMvSK1mBgfAg2VwWYNzpw9KcmH5UCb9+ehL8OS0CCm/1B5QgMgMhtSdNfUYE+KKs0oKBMj4wrZY2eF8+rMH+BdbgqEVQmk2H+jYnYfOoyNp+6jFUHs5o9v29JgHbT/Xpu7heDf60+jhKdAUG+SlzTNczVTXKIG/pEYee5fAzv3A639Gs9+T51iQn2RVyILzLzy7Dj7BVc1716L7Rz3AS1QQnt/LDsnv4QQuB0Xgl2nC3AjrNXsPNcAS4WlmP/hSLsv1BdZ2mSkwIgwPz51DvGvabTHcWl4f2CBQswcOBABAQEIDw8HFOmTMHx48cbfNy3336L7t27w9vbG71798Zvv/3mhNZSWyMlQEdo1JZy/k2ZBpMCIFtLgeNCffHwqE4AgFd+PdKoZEhbai6Bd0f+ai/cPiAWgHn0x5Erz1wpwFuJt2/v2yaCH4m0LcbWU9Z5QNK/kdZQqLK1k8lk6BwegDsHx2HxHcnY8vR12PL0dVg8tS/uHByHHlEa/O2ajogK5FRia+TST6ONGzdi1qxZ2LZtG1JTU6HX6zF27FiUltb9JbV161ZMmzYN999/P/bu3YspU6ZgypQpOHTokBNbTm2BNAIUHuBtSeZsShHDPHMl+Tq/CB4c2QlxIb7I0erw73Unm9VGT9iv5x8TumHJHX3xjwndXd0UqiGlajn81qsSoc+yBlCLtA/ywZTk9njt5t74/dEReGZi4wtVknO5NABavXo1ZsyYgcTERCQlJWH58uXIzMzE7t2763zMkiVLMH78eMydOxc9evTAK6+8gn79+uHdd991YsupLcipMQIkBTEZTRgBulw1AlRXNVxvpQIvTTYnRC/fcq7Jy+KLyvWW/Xp6RLpvAKT2UuCmvu3hq+KMe2siVYQ+kqW1XixwmZugkmdoVZ9IRUXmOdOQkLr3KEpPT8ecOXOsbhs3bhx+/PFHm8frdDrodNVLobVa81/cer0eer3tjeSaSzqfvc/bmrSlPmZVBRft/JRoH2wuvHcmr6RRba+srLQkQccGqep8zLCOQYgO9MalogpsO5WHEV3aNbp9B8+bkyajA73hq3T+c9qWXsuW8IR+NqePQd5ydA33x4ncEmw+kYMJvSJhMglkVNW+igms+33vKp7wWgKe0c/m9NHez0erCYBMJhMee+wxDBs2DL169arzuOzsbERERFjdFhERgexs25V5FyxYgJdeeqnW7WvXroWvr2OS/FJTUx1y3takLfTxyBk5ADmyzh6HyBEAvHDiUkGjcsZK9EC50fzP48iOP3Gqnt0LYlVyXIIcX6TuQvHJumuCXG1jlgyAAiHyMpfmsbWF19IePKGfTe1jpFyOE5Dj67R9EJkm5OuASoMX5DKB/elpONRKF7J5wmsJeEY/m9LHsrKm7+dYn1YTAM2aNQuHDh3C5s2b7XreefPmWY0YabVaxMbGYuzYsdBo7DvtoNfrkZqaijFjxkCpdM8deNtSH/9zZitQVILRwwciqX0g3j64AVq9DCOvH9vgUvhdZy8Du/YgUqPGlBvH1nus8UAWtn97EFkiEBMnpjS6fX+uPAycu4iRSZ0x8frOjX6cvbSl17IlPKGfze2j6mguNn21D5cM/pg4cbg5H2jPbnQI8cONk4Y7sMXN4wmvJeAZ/WxOH6UZHHtpFQHQ7Nmz8euvv2LTpk2Iial/FUVkZCRycnKsbsvJyUFkpO3qsmq1Gmp17X2HlEqlw95Yjjx3a9EW+iglQUcH+yFU44sQPxXySytxUVuJxOj6V2VcKDLnRHQI9W2wnyO6RgA4iKPZxdDqTAht5D5Xx3LMFaB7xwS59LlsC6+lPXhCP5vax6FdwiGXAWevlOFymQHnC83/ZhLC/Fv1c+UJryXgGf1sSh/t/Vy4NAlaCIHZs2dj5cqVWL9+PRISEhp8TEpKCtatW2d1W2pqKlJSGv+XN7k/ncGIgjLzfHFEgLkcvFTPpzFbYmRcaXwtlLAANbpHmvfxunpFTV30RhNO5JirSLvrEnhq/QJ9lOjd3lwzJv30FcsigboS/4nciUsDoFmzZuGLL77AV199hYCAAGRnZyM7Oxvl5eWWY6ZPn4558+ZZfn/00UexevVqLFy4EMeOHcP8+fOxa9cuzJ492xVdoFZKqgKtUsgR5Gv+q0FaCt+YWkDSHmBXF0Gsy7DO0pLi2lsL2HImrxSVBhP81V6IbaXbJZBnkJbDbzl1BWer/jhIaMf3JLk/lwZAS5cuRVFREUaNGoWoqCjLz9dff205JjMzE1lZWZbfhw4diq+++goffPABkpKS8N133+HHH3+sN3GaPI+09UJYgNqyTYWlGGIjagFJK2E6NHL/nuFVAdBmG3sr2SIVQOweGQB5K94ygdyfVBAx/fRlFkEkj+LSHCAhRIPHpKWl1brttttuw2233eaAFpG7yCuurgEksUyBNTACJISo3gW+kSNAgxJC4CWX4Xx+OTKvlCGugccdcfMK0NR2DOgQAqVChktFFZC2tGMRRPIE7lmXnjyeNAIUofG23JZg2Q6j/hyggjI9iqt2gW/s9JSf2gv94oIBNG4USBoBcucK0NQ2+KgUSK567wphnjaODuLWDeT+GACRW8qtGgEKD6g5AmQOgPKKdfXu3SWNEAWphNUu8A2R8oC2NBAACSEsW2BwBIhag2Gdqgt4xob4tOqd7InshQEQuSVpBCi8xghQoI8SIX4qAPXnAUn3hXk3PEVbk2VzydOXYTLV/di8Yh2ulFZCLgO6RQQ06RpEjjC06r0LcPqLPAcDIHJL1fuAeVvdLuX0ZNQzDSYFQO286zzEpqTYIPipFCgo01tyfGw5XHVfQju/Jo0wETlKUkwQfJTm9yIToMlTMAAit5Rn2QneuiihZSVYPYnQUo5QU0eAlAo5hlRtMFnfNFh1/k9gk85P5CgqL7llBFOqaUXk7hgAkVuqewTIHACdrW8K7ErzRoCA6jyg+hKhj2aZK0D3iOIXDbUer0zphX9O6YWbk9u7uilETsEAiNxOzSrQdY0AZdQxAiSEsARHYT5NGwECgOFVu8HvPJcPncFo85gjl4oAMAGaWpeoQB/cPaQDvBT8WiDPwHc6uR1bVaAlUg7Q2Tq2w6i5BL5d47b0stIl3B9hAWpU6E3Yk1FY6/7ySqMlwEpkAERE5DIMgMjtVK8Aq64CLZFGgC6X2F4KLwUnkRo1mpOfLJPJMKxT3XlAx3OKYRJAqJ8KYQHNiLCIiMguGACR28nV1q4BJNF4KxFaz1L46s0gm78XUn15QDULIF4dnBERkfMwACK3k1tcuwp0TfVtiSEFRY3dBNUWKQA6cKEQReV6q/tYAJGIqHVgAERup64VYJLqROjaeUBN3QXeluggH3QM84NJANvPXLG6zzICxACIiMilGACR25FGgOrKsUmoZym8NCoUH9KyYnDDbWyLYTIJSwDEESAiItdiAERup6ERoA5SMcSrAqCaS+A7hLZsM8ihnWrnAZ0vKENppREqhRwdw1htl4jIlRgAkdvJ1dquAi2RRoCu3hW+5hL4uJDmT4EBQErHUMhlwOm8UmQVlQOonv7qGukPJWutEBG5FD+Fye1IO8HXPQJkDm4ul+hQXFGdpCyN/kQFesNb2bI9ugJ9legdEwQA2HLKnAdkSYCO5PQXEZGrMQAit1KzCnSExvYIUM2l8DUToauXwNtnemq4tDt81TTYkaotMHpGMwAiInI1BkDkVqTpL5WXHIE+yjqPs7UpqpQTJN3XUjXrAQnBBGgiotaEARC5ldwau8DXV2hQGuWpmQh9tmo0qCVFEGvqFxcMb6UcucU67M4owMVCcy4QAyAiItdjAERuJbeBFWASW3uCWabA7DQC5K1UYGB8CADgwz/PAADaB/nUOzJFRETOwQCI3EpOPdtg1HT1rvA1l8DbKwcIqJ4GW3skBwBHf4iIWgsGQORWGtoGQ2KZAqsKgGougW9JFeirSQURhTD/zgRoIqLWgQEQuZWaO8HXJ96yFL4SxRV6y+hPtB2WwNfUM0qDIF9ljd8D7HZuIiJqPgZA5FakGkDhAfWPAAV4K9HOv3opfPUmqPat0CyXyzCsqio0APSMCrTr+YmIqHkYAJFbkZbB11UDqKYONfYEs3cCdE1SHpC/2gsxwS3bYoOIiOyDARC5lZxGjgAB1kvh7b0EvqZxiRHoGuGPOwfHQS6ve2k+ERE5j5erG0BkLzqDEYUNVIGuKaEqD+jclTKHjgCF+qux9vGRdj8vERE1H0eAyG00tgq0pEONlWBSEnSCAwIgIiJqfTgCRG6jOgG6/irQEinYOXypCBV6E4CW7wJPRERtA0eAyG1UJ0A3nP8DVNf7kYIfey+BJyKi1osBELmNHMs2GA3n/wDWS+EB+y+BJyKi1osBELmNHMtGqI0bAQKst71wRAI0ERG1TgyAyG3kNrIKdE01R32kVWFEROT+mARNrUJZpQGZ+WXIuFKGzCtlOHelFJn5ZSgoq8QzE3tgaI1qynVpbBXommoGPZwCIyLyHAyAyCW0FXq8ufo4jmVrkXGlzLKJqS3/2XC6cQFQE6pAS2pOe3EJPBGR52AARC6xYkcmPt+WYXWbxtsL8e38EBfii/hQPwT5KvHPVUex7cwVaCv00HjXX9tHqgLd2FVggHUOEJfAExF5DgZA5BJpx/MAAPcM6YC/9I9Bh1BfBPmqah23Yud5nMotQdrxPExOiq7zfBX66irQ4QGNHwHqFhmAYZ1DERfiyyXwREQehAEQOV2pzoCd5/IBAPcNi0fHMP86jx3dIwKnckuQeiSn3gAor7hpVaAlSoUcXz4wpNHHExGRe+AqMHK69NNXoDcKxIX4Nph3M6ZnBAAg7VguKg2mOo/LLa6uAdSYKtBEROTZGACR06WdyAUAjOwa1mCwkhwbhHb+ahTrDNhxNr/O43K0Ta8BREREnosBEDmVEMKS/zOya1iDx8vlMozuEQ4ASD2SXedxuU2sAk1ERJ6NARA51dnLpbhQUA6VQo6UTqGNeszoHuZpsNQjORBC2DymOVWgiYjIczEAIqeSRn8GJgTDT924HPzhXdrBR6nApaIKHMnS2jxG2gesKVWgiYjIczEAIqfaeKLx018Sb6UCI7qYCyGmHsmxeYy0CiyCI0BERNQIDIDIaSr0Rmw7cwUAMKpbeJMeO7pn9TSYLRwBIiKipmAARE6z7cwV6AwmRAV6o0t43bV/bLm+ezjkMuDwJS0uFZbXul/aSqMpVaCJiMhzMQAip6k5/dXUWj2h/mr07xAMAPjjqPUoUM0q0JwCIyKixmAARE4jBUCjujU+/6emmqvBaqpZBVrjw+LmRETUMAZA5BTn88twJq8UXnIZhnZueGd3W6Sq0NLmqBJWgSYioqZiAEROkVY1+tOvQ3CDu7rXpWOYPzqF+UFvFNhYtZweqK4CzekvIiJqLAZA5BQbm1D9uT62VoNxBRgRETUVAyByOJ3BiK2nLwNoeQA0tioA2nA8F3qjeXPUXFaBJiKiJmIARA63+1wByiqNCAtQIzFa06Jz9Y0NRjt/FYorqjdH5QgQERE1FQMgcjhp9dc1XZq+/P1qCrkM13WXNkc1T4PlMgeIiIiaiAEQOZxl9/dmLn+/2piekQCqN0etXgXGAIiIiBqHARA5VFZROY7nFEMuA0Y0c/n71YZ3bgdvpRwXC8txNKvYsgqMU2BERNRYDIDIoTZVTX8lxQYh2E9ll3P6qBQY0cU8mvTrgUsoKmcVaCIiahoGQORQaXZa/n61MVVVob/ZdQEAoGYVaCIiagKXBkCbNm3CjTfeiOjoaMhkMvz444/1Hp+WlgaZTFbrJzs72zkNpibRG03YfNK8/L2pu7835Loe4ZDJgMsl1dNfrAJNRESN5dIAqLS0FElJSXjvvfea9Ljjx48jKyvL8hMebt8vV7KPfecLUawzINhXid7tA+167nb+avSPC7b8zukvIiJqCpfOGUyYMAETJkxo8uPCw8MRFBTUqGN1Oh10Op3ld61WCwDQ6/XQ6/V1PaxZpPPZ+7ytSVP6uP6IeWRuWKdQmIwGmIz2bcu13dphV0YBACDMX2XX552vpfvwhH56Qh8B9tOdNKeP9n4+ZEIIYdczNpNMJsPKlSsxZcqUOo9JS0vDtddeiw4dOkCn06FXr16YP38+hg0bVudj5s+fj5deeqnW7V999RV8fX3t0XSqw5sHFLhQKsPdnY0YGGb/t1lOOfDaPnMMf02kCbcmmOx+DSIiah3Kyspw5513oqioCBpNy4rqAi4eAWqqqKgoLFu2DAMGDIBOp8NHH32EUaNGYfv27ejXr5/Nx8ybNw9z5syx/K7VahEbG4uxY8fa5QmsSa/XIzU1FWPGjIFS2bwNP1u7xvbxcokOF9I3AgBm3Xod2vk7Zon6igubceZyGQb17oaJ1yTY7bx8Ld2HJ/TTE/oIsJ/upDl9lGZw7KVNBUDdunVDt27dLL8PHToUp0+fxqJFi/D555/bfIxarYZaXfvLV6lUOuyN5chztxbbMoqw5XQBOoX5o0dUALpFBsBXVf12Sj9rrtLcq70GUcH+DmvHI9d3xb/XncTEPtEOec494bX0hD4CntFPT+gjwH66k6b00d7PRZsKgGwZNGgQNm/e7OpmeBSDCXjs6wPQVhgst8lkQHyoH3pEBaBHpAZbT18BAIzq6tgE9SnJ7TElub1Dr0FERO6nzQdA+/btQ1RUlKub4VGOF8mgrTAgqGp119GsYlwu0eHs5VKcvVyK3w5WlyWw1/YXRERE9uTSAKikpASnTp2y/H727Fns27cPISEhiIuLw7x583Dx4kV89tlnAIDFixcjISEBiYmJqKiowEcffYT169dj7dq1ruqCR9p7xVxvZ0rf9pg/OREAkFesw7FsLY5maXEsqxhHs4sRH+qL5NggF7aUiIjINpcGQLt27cK1115r+V1KVr733nuxfPlyZGVlITMz03J/ZWUlnnjiCVy8eBG+vr7o06cP/vjjD6tzkGPpDCYczDcHQJP6VI+8hQWoERYQZtmigoiIqDVzaQA0atQo1LcKf/ny5Va/P/XUU3jqqacc3Cqqz+aTl1FhlCFCY12IkIiIqC3hXmDUJL8dMq/umpAYAbmcW08QEVHbxACIGq1Cb8S6Y7kAgIm9Il3cGiIiouZjAESNtvFEHkorjQhSCSTF2HdvLyIiImdiAESN9uuBLABAcqjg9BcREbVpDICoUcorjVh31Jz/kxzKPbeIiKhtYwBEjZJ2PBdllUa0D/JGnON2tiAiInIKBkDUKL8eNE9/TegVCRlnv4iIqI1jAEQNKqs0YP1R8+qvSVz9RUREboABEDVo/bFclOuNiAvxRWJ0gKubQ0RE1GIMgKhBq6pWf03qEwUZ57+IiMgNMACiepXqDFhfVfxwUu+oBo4mIiJqGxq9F5hWq230STUaTbMaQ63PH0dzoDOYkNDOD4nRGhgMBlc3iYiIqMUaHQAFBQU1evrDaDQ2u0HUulimv3pz+ouIiNxHowOgDRs2WP7/3LlzePrppzFjxgykpKQAANLT0/Hpp59iwYIF9m8luURxhR5pJ/IAmPN/iIiI3EWjA6CRI0da/v/ll1/G22+/jWnTpllumzx5Mnr37o0PPvgA9957r31bSS7xx9EcVBpM6Bjmh+6RXP1FRETuo1lJ0Onp6RgwYECt2wcMGIAdO3a0uFHUOkjTXzf0ieb0FxERuZVmBUCxsbH48MMPa93+0UcfITY2tsWNItcrKtdj04nLAIAbOP1FRERuptFTYDUtWrQIt956K37//XcMHjwYALBjxw6cPHkS33//vV0bSK7xx5EcVBpN6BLuj64RnP4iIiL30qwRoIkTJ+LkyZOYPHky8vPzkZ+fjxtvvBEnTpzAxIkT7d1GcoFfD1wCwORnIiJyT00eAdLr9Rg/fjyWLVuGV1991RFtIhcrKtPjz5Oc/iIiIvfV5BEgpVKJAwcOOKIt1EqsOZINg0mge2QAOodz+ouIiNxPs6bA7r77bvz3v/+1d1uolahZ/JCIiMgdNSsJ2mAw4OOPP8Yff/yB/v37w8/Pz+r+t99+2y6NI+crKK3EllPm6S/m/xARkbtqVgB06NAh9OvXDwBw4sQJq/tYL6ZtW3PYPP3VM0qDjmH+rm4OERGRQzQrAKq5LQa5lzWHswFw9IeIiNxbs3KAyD0JIbDvfCEAYESXdq5tDBERkQM1awQIAHbt2oVvvvkGmZmZqKystLrvhx9+aHHDyPkuFJSjoEwPpUKGbtz7i4iI3FizRoBWrFiBoUOH4ujRo1i5ciX0ej0OHz6M9evXIzAw0N5tJCc5eLEIANA9UgO1l8LFrSEiInKcZgVAr732GhYtWoRffvkFKpUKS5YswbFjx3D77bcjLi7O3m0kJ9l/oRAA0DuGQSwREbm3ZgVAp0+fxqRJkwAAKpUKpaWlkMlkePzxx/HBBx/YtYHkPAcvmEeAkhgAERGRm2tWABQcHIzi4mIAQPv27XHo0CEAQGFhIcrKyuzXOnIak0lYpsB6tw9ybWOIiIgcrFlJ0Ndccw1SU1PRu3dv3HbbbXj00Uexfv16pKam4vrrr7d3G8kJMvLLUFxhgNpLji4RrP9DRETurVkB0LvvvouKigoAwLPPPgulUomtW7fi1ltvxXPPPWfXBpJzHKjK/+kZrYFSweoIRETk3poVAIWEhFj+Xy6X4+mnn7Zbg8g1Dljyf4Jc2xAiIiInaNaf+tOnT8cnn3yC06dP27s95CJSAnTv9kyAJiIi99esAEilUmHBggXo0qULYmNjcffdd+Ojjz7CyZMn7d0+cgKjSeDQJXMA1IcrwIiIyAM0KwD66KOPcOLECZw/fx5vvPEG/P39sXDhQnTv3h0xMTH2biM52Om8EpRVGuGrUnADVCIi8ggtynYNDg5GaGgogoODERQUBC8vL4SFhdmrbeQkUv5Pr/aBUMhlLm4NERGR4zUrAHrmmWcwdOhQhIaG4umnn0ZFRQWefvppZGdnY+/evfZuIznYwaoVYH2Y/0NERB6iWavAXn/9dYSFheHFF1/ELbfcgq5du9q7XeREB6QCiMz/ISIiD9GsAGjv3r3YuHEj0tLSsHDhQqhUKowcORKjRo3CqFGjGBC1IXqjCUcuaQEAfbgEnoiIPESzAqCkpCQkJSXhkUceAQDs378fixYtwqxZs2AymWA0Gu3aSHKcEznF0BlMCPD2Qnyor6ubQ0RE5BTNCoCEENi7dy/S0tKQlpaGzZs3Q6vVok+fPhg5cqS920gOJNX/6RMTCJmMCdBEROQZml0JuqSkBElJSRg5ciRmzpyJESNGICgoyM7NI0fbf4EboBIRkedpVgD0xRdfYMSIEdBoNPZuDznZwYuFAFgAkYiIPEuzlsFPmjQJGo0Gp06dwpo1a1BeXg7APDVGbUeF3ojj2cUAGAAREZFnaVYAdOXKFVx//fXo2rUrJk6ciKysLADA/fffjyeeeMKuDSTHOZ5dDL1RIMRPhfZBPq5uDhERkdM0KwB6/PHHoVQqkZmZCV/f6pVDU6dOxerVq+3WOHKsA1UFEHu3ZwI0ERF5lmblAK1duxZr1qypte9Xly5dkJGRYZeGkeMduMANUImIyDM1awSotLTUauRHkp+fD7Va3eJGkXMcvCgFQEGubQgREZGTNSsAGjFiBD777DPL7zKZDCaTCW+88QauvfZauzWOHKe80ogTOUyAJiIiz9SsKbA333wT1113HXbt2oXKyko89dRTOHz4MPLz87FlyxZ7t5Ec4PClIpgEEB6gRoTG29XNISIicqomB0B6vR6PPPIIfvnlF6SmpiIgIAAlJSW45ZZbMGvWLERFRTminWRnzP8hIiJP1uQASKlU4sCBAwgODsazzz7riDaREzD/h4iIPFmzcoDuvvtu/Pe//7V3W8iJLEvgOQJEREQeqFk5QAaDAR9//DH++OMP9O/fH35+flb3v/3223ZpHDlGcYUeZy6XAjDXACIiIvI0zQqADh06hH79+gEATpw4YXUfC+q1focuaiEE0D7IB+38WbaAiIg8T7MCoA0bNtjl4ps2bcKbb76J3bt3IysrCytXrsSUKVPqfUxaWhrmzJmDw4cPIzY2Fs899xxmzJhhl/Z4Cm6ASkREnq5ZOUD2UlpaiqSkJLz33nuNOv7s2bOYNGkSrr32Wuzbtw+PPfYYHnjgAaxZs8bBLXUv0gow5v8QEZGnatYIkL1MmDABEyZMaPTxy5YtQ0JCAhYuXAgA6NGjBzZv3oxFixZh3LhxNh+j0+mg0+ksv2u1WgDm5fx6vb4Fra9NOp+9z2tv+88XAgB6Rvo3ua1tpY8t5Qn99IQ+Ap7RT0/oI8B+upPm9NHez4dMCCHsesZmkslkDU6BXXPNNejXrx8WL15sue2TTz7BY489hqKiIpuPmT9/Pl566aVat3/11Vc2t/Nwd6V64Jld5rh3wUADfF0aAhMRETVOWVkZ7rzzThQVFUGj0bT4fG3q6y87OxsRERFWt0VERECr1aK8vBw+Pj61HjNv3jzMmTPH8rtWq0VsbCzGjh1rlyewJr1ej9TUVIwZMwZKpdKu57aXzaeuALt2o0OIL/4yeXiTH98W+mgPntBPT+gj4Bn99IQ+AuynO2lOH6UZHHtpUwFQc6jVapsbtCqVSoe9sRx57pY6kl0CAOgTG9SiNrbmPtqTJ/TTE/oIeEY/PaGPAPvpTprSR3s/Fy5Ngm6qyMhI5OTkWN2Wk5MDjUZjc/SHapMKIPZh/R8iIvJgbSoASklJwbp166xuS01NRUpKiota1PYc5AowIiIi1wZAJSUl2LdvH/bt2wfAvMx93759yMzMBGDO35k+fbrl+AcffBBnzpzBU089hWPHjuE///kPvvnmGzz++OOuaH6bk1esw6WiCshkQC+OABERkQdzaQC0a9cuJCcnIzk5GQAwZ84cJCcn44UXXgAAZGVlWYIhAEhISMCqVauQmpqKpKQkLFy4EB999FGdS+DJ2qGqDVA7hfnDX+326V9ERER1cum34KhRo1DfKvzly5fbfMzevXsd2Cr3tZ/5P0RERADaWA4QtQzzf4iIiMwYAHkIIQQOVE2B9YkJcm1jiIiIXIwBkIc4e7kUecU6eMll6Bll3wKQREREbQ0DIA/xx1Fz/aQhHUPho1K4uDVERESuxQDIQ6QeMQdAY3pGNHAkERGR+2MA5AGulOiwO6MAADCaARAREREDIE+w/lguTALoGaVB+yBuGUJERMQAyANw+ouIiMgaAyA3V6E34s+TlwEwACIiIpIwAHJzW05dRrneiOhAbyRGc/k7ERERwADI7UnL30f3jIBMJnNxa4iIiFoHBkBuzGQS+ONoLgBgdA9OfxEREUkYALmx/RcKkVesg7/aC0M6hrq6OURERK0GAyA3Jq3+GtktDCovvtREREQSfiu6MSkAGsvVX0RERFYYALmpc5dLcTK3BF5yGUZ1DXd1c4iIiFoVBkBuSlr9NSghBIG+She3hoiIqHVhAOSmWP2ZiIiobgyA3FBBaSV2nssHwOXvREREtjAAckPS5qfdIwMQG+Lr6uYQERG1OgyA3JCU/8PVX0RERLYxAHIzFXojNp7IA2De/oKIiIhqYwDkZtLPXEFZpRERGjV6tw90dXOIiIhaJS9XN8BdaCv02J+Rj5NFrt1wVFr9NboHNz8lIiKqC0eA7OTIJS3u+WQXvjnjuqfUZBJYd5TL34mIiBrCAMhOgn1VAIBSg+vacPBiEXK0OvipFEjpxM1PiYiI6sIAyE6CqqotlxnMIzGuUHPzU7WXwiVtICIiagsYANlJoI85ABKQoUTn/GEgIQR+P5QFgNNfREREDWEAZCfeSgV8lOans6Bc7/Trp5+5gtN5pfBVKXA9qz8TERHViwGQHQVV5QEVlTk/APpsawYA4Obk9tB4c/NTIiKi+jAAsqOgqmmwQiePAF0sLMfaI9kAgHuHxjv12kRERG0RAyA7khKhC5w8AvTV9gyYBJDSMRRdIwKcem0iIqK2iAGQHUkjQEVOHAGq0Bvxvx3nAQD3Du3gtOsSERG1ZQyA7CiwagSosKzSaddcdSAL+aWViA70xmgmPxMRETUKAyA7CrbkADlvGfxn6ecAAHcN6QAvBV9OIiKixuA3ph0FOXkEaN/5Quy/UASVQo47BsY65ZpERETugAGQHUnFEAudlAT96dZzAIAbkqIQ6q92yjWJiIjcAQMgO5JGgJyRBJ1XrMOqA+bKz/emxDv8ekRERO6EAZAdSavAnLEM/uudmag0mtA3NghJsUEOvx4REZE7YQBkR5ZK0A4eATIYTfhiWyYALn0nIiJqDgZAdiRNgWkrDDAYTQ67TuqRHGRrKxDqp8LE3lEOuw4REZG7YgBkR4HeXpb/d+Qo0PKq5Odpg+Kg9lI47DpERETuigGQHXkp5PBRCACO2w/sWLYW28/mQyGX4a4hcQ65BhERkbtjAGRnvlWDQI6qBfRZunnX93GJEYgK9HHINYiIiNwdAyA7qw6A7D8CVFSux8o9FwEA07n0nYiIqNkYANmZn5d5CswRS+G/3XUe5XojukcGYHBCiN3PT0RE5CkYANmZo6bATCaBz7eZp7+mp8RDJpPZ9fxERESehAGQnfmZV8LbfQps48k8ZFwpQ4C3F6YkR9v13ERERJ6GAZCdSSNABXYeAfq8Kvn59gGx8FV5NXA0ERER1YcBkJ1JOUD2XAZvMglsPX0ZgDkAIiIiopZhAGRnjsgBulBQjgq9CSovOTqF+dntvERERJ6KAZCd+UlTYKX2GwE6mVsMAOjYzg9eCr5kRERELcVvUzuTpsDsuRXGydwSAECXiAC7nZOIiMiTMQCyM0ckQZ/IMY8AdQ33t9s5iYiIPBkDIDuTlsGXVRqhMxjtcs5TlhEgBkBERET2wADIzrwVgLyqRmGRHWoBmUwCJ3M4BUZERGRPDIDsTC4DAn3Mw0D22A7jYmE5yvVGKBUydAjxbfH5iIiIqJUEQO+99x7i4+Ph7e2NwYMHY8eOHXUeu3z5cshkMqsfb29vJ7a2YUFVAZA9lsJL018d2/lzBRgREZGduPwb9euvv8acOXPw4osvYs+ePUhKSsK4ceOQm5tb52M0Gg2ysrIsPxkZGU5sccMCfe03AiQlQDP/h4iIyH5cHgC9/fbbmDlzJu677z707NkTy5Ytg6+vLz7++OM6HyOTyRAZGWn5iYiIcGKLGyaNABWVt3wEyLIEPpz5P0RERPbi0k2lKisrsXv3bsybN89ym1wux+jRo5Genl7n40pKStChQweYTCb069cPr732GhITE20eq9PpoNPpLL9rtVoAgF6vh15v3w1LpfNpvBUAgMvFFS2+xolsc3sTQr3t3t7mkNrQGtriSJ7QT0/oI+AZ/fSEPgLspztpTh/t/XzIhBDCrmdsgkuXLqF9+/bYunUrUlJSLLc/9dRT2LhxI7Zv317rMenp6Th58iT69OmDoqIivPXWW9i0aRMOHz6MmJiYWsfPnz8fL730Uq3bv/rqK/j6Oiap+IdzcmzMkuP6aBMmdzA1+zxCAE/tUKDSJMO8JAMimQNNREQeqqysDHfeeSeKioqg0WhafL42t614SkqKVbA0dOhQ9OjRA++//z5eeeWVWsfPmzcPc+bMsfyu1WoRGxuLsWPH2uUJrEmv1yM1NRVJ3TphY9ZZhEbFYuJE2yNTjXGxsByV2/6EUiHDPTePh7IVJEFLfRwzZgyUSqWrm+MwntBPT+gj4Bn99IQ+AuynO2lOH6UZHHtxaQDUrl07KBQK5OTkWN2ek5ODyMjIRp1DqVQiOTkZp06dsnm/Wq2GWq22+ThHvbFC/M3XK6owtOgaZ/MLAAAJ7fzg6127D67kyOevNfGEfnpCHwHP6Kcn9BFgP91JU/po7+fCpUMKKpUK/fv3x7p16yy3mUwmrFu3zmqUpz5GoxEHDx5EVFSUo5rZZEG+KgBAYQtXgZ3KYQI0ERGRI7h8CmzOnDm49957MWDAAAwaNAiLFy9GaWkp7rvvPgDA9OnT0b59eyxYsAAA8PLLL2PIkCHo3LkzCgsL8eabbyIjIwMPPPCAK7thJdBSB6iFCdBVS+A7cw8wIiIiu3J5ADR16lTk5eXhhRdeQHZ2Nvr27YvVq1dblrZnZmZCLq8eqCooKMDMmTORnZ2N4OBg9O/fH1u3bkXPnj1d1YVagqvqABW2cBm8tAS+K7fAICIisiuXB0AAMHv2bMyePdvmfWlpaVa/L1q0CIsWLXJCq5ovqEYhRCEEZDJZk88hhOAmqERERA7i+mVFbkiaAqs0mFCub96O8FlFFSjRGeAllyE+1M+ezSMiIvJ4DIAcwE+lgFJhHvVpbh6QNP0V384PKi++TERERPbEb1YHkMlkCPQxrwQraOaGqCelPcCYAE1ERGR3DIAcREqELmruCJC0BJ4J0ERERHbHAMhBgn2lEaDmBUAncjkCRERE5CgMgBwk0LISrOlTYEIISxFELoEnIiKyPwZADmKZAitv+ghQjlaHYp0BCrkM8e24AyoREZG9MQByEGk7jILSpo8ASRWgO4T6Qu2lsGu7iIiIiAGQwwRZqkE3fQTIUgGae4ARERE5BAMgBwm2bIja9BEgyxJ4VoAmIiJyCAZADhLkU70dRlOdzOUSeCIiIkdiAOQgQc0cARJCsAgiERGRgzEAchBLDlATR4Byi3XQVhgglwEJ7bgHGBERkSMwAHIQSw5QuXlH+MaSKkDHh/rBW8kVYERERI7AAMhBpBEgo0mgWGdo9OOkJfCdOf1FRETkMAyAHMRbqYC30vz0FpY2fhrMsgSeCdBEREQOwwDIgaqnwRqfCH0ql0vgiYiIHI0BkAMFNnEpvBACJ6pygDgFRkRE5DgMgByoqcUQ80p0KCrXQy4DOoUxACIiInIUBkAO1NSl8NIKsLgQX64AIyIiciAGQA5k2RC1kSNA1VtgMAGaiIjIkRgAOVBwU0eApC0wmP9DRETkUAyAHKh6CqyxI0DSHmAMgIiIiByJAZADBdWoBt0QIQROSEvgwzkFRkRE5EgMgByoKTvCXy6pRGGZHjKuACMiInI4BkAOFOzX+GXwJ6tGf+JCfOGj4gowIiIiR2IA5EBNSYI+xQRoIiIip2EA5ECBPuYRIG2FHkZT/TvCV2+CyvwfIiIiR2MA5EDSKjAhAG0DidBHLmkBAN0iOQJERETkaAyAHEipkMNf7QWg/mKIOoMRhy6aA6C+scFOaRsREZEnYwDkYNIoUH0rwQ5d1KLSaEKInwrxob7OahoREZHHYgDkYNKGqEXldY8A7c0sAAD0iwuGTCZzSruIiIg8GQMgB7OMAJXWPQK0O8McAPXvwOkvIiIiZ2AA5GANVYMWQmBXhjQCFOSsZhEREXk0BkAOJlWDrqsY4oWCcuQV6+All6FPTJATW0ZEROS5GAA5WLAlCdp2ALSnKv8nMVrDCtBEREROwgDIwSxTYHWsAtsjTX8x/4eIiMhpGAA5WFAD22HszmQCNBERkbMxAHKwYEsSdO0psFKdAUezzFtg9ItjAEREROQsDIAcLLCeZfD7LxTCaBKICvRGdJCPs5tGRETksRgAOVh1IcTaAdDezEIAzP8hIiJyNgZADiatAivRGVBpMFndZymAyOkvIiIip2IA5GAB3kpIu1vUzAMymYRlCTxHgIiIiJyLAZCDKeQyBFYVQyyqsRLszOVSFJbpofaSo2eUxlXNIyIi8kgMgJxAqgZdc0d4afQnKSYIKi++DERERM7Eb14nqC6GWD0FxgKIRERErsMAyAlsFUPczQ1QiYiIXMbL1Q3wBNJSeGk/sKIyPU7mlgDgCBBRSwghYDAYYDQa6zxGr9fDy8sLFRUV9R7XlnlCHwH2053U1UelUgmFwjn7YjIAcgLLCFBVLaC9582jP/Ghvmjnr3ZZu4jassrKSmRlZaGsrKze44QQiIyMxPnz5yGTlmS6GU/oI8B+upO6+iiTyRATEwN/f3+Ht4EBkBME+VjnADH/h6hlTCYTzp49C4VCgejoaKhUqjq/KEwmE0pKSuDv7w+53D1n/T2hjwD76U5s9VEIgby8PFy4cAFdunRx+EgQAyAnCPazzgHiBqhELVNZWQmTyYTY2Fj4+vrWe6zJZEJlZSW8vb3d+svE3fsIsJ/upK4+hoWF4dy5c9Dr9Q4PgNzzmW1lAi3L4CthNAnsk7bAYAVoohZx1y8HIk/lzCk/fno4gWVH+DI9jmcXo7TSCH+1F7pGBLi4ZURERJ6JAZAT1AyApOmv5LggKOTumdxGRETU2jEAcgJpFVhBWWV1AjSnv4iIiFyGAZATSAGQzmDC1tOXAXAFGBF5NplMhh9//LFF55gxYwamTJlil/a4u7S0NMhkMhQWFtZ5zPLlyxEUFOS0NrkaAyAn8Fd7watquitHq4NMBvSNDXJto4jIJWbMmAGZTAaZTAalUomIiAiMGTMGH3/8MUwmU63jt27diokTJyI4OBje3t7o3bs33n777VoF8oKDg+Hr64uMjAyr26dMmYIZM2Y4sks2NRScZGVlYcKECS26xpIlS7B8+XLL76NGjcJjjz1W5/Hnzp2zPPd1/dQ8X2tQV6DojOBv+fLlGDVqlEOv4UqtIgB67733EB8fD29vbwwePBg7duyo9/hvv/0W3bt3t3wY/Pbbb05qafPIZDLLKBAAdA0PsKwMIyL7EEKgrNJg86e80ljnffb4EUI0qa3jx49HVlYWzp07h99//x3XXnstHn30Udxwww0wGAyW41auXImRI0ciJiYGGzZswLFjx/Doo4/in//8J+64445a15XJZHjhhRfs8nw6WmRkJNTqlhWCDQwMbNKIRWxsLLKysiw/TzzxBBITE61umzp1aovaRG2HywOgr7/+GnPmzMGLL76IPXv2ICkpCePGjUNubq7N47du3Ypp06bh/vvvx969ezFlyhRMmTIFhw4dcnLLm0baEBXg9BeRI5Trjej5wppaP73mpyLl7W3oNT/V5v32+CnXN227ArVajcjISLRv3x79+vXDM888g59++gm///67ZQSitLQUM2fOxOTJk/HBBx+gb9++iI+PxwMPPIBPP/0U3333Hb755hur886aNQtffPFFkz8Pv//+eyQmJkKtViM+Ph4LFy60uj8+Ph6vvfYa/vrXvyIgIABxcXH44IMPmnSNq9Uc2ZBGZr755huMGDECPj4+GDhwIE6cOIGdO3diwIAB8Pf3x8SJE3H58mXLOWqOgsyYMQMbN27EkiVLLKM5586ds7qmQqFAZGSk5cff3x9eXl6W38PDw7F48WIkJCTAx8cHSUlJ+O677wCYA+zRo0dj3LhxlsAzPz8fMTExlqDTaDTi/vvvtzy+W7duWLJkiVUb0tLSMGjQIPj5+SEoKAjDhg2rNWrXHDqdDo888gjCw8Ph7e2N4cOHY+fOnfU+Zvny5YiLi4Ovry9uvvlmXLlypcHrfPTRR+jRowe8vb3RvXt3/Oc//7Hc19jXccKECcjLy2txn1vK5QHQ22+/jZkzZ+K+++5Dz549sWzZMvj6+uLjjz+2efySJUswfvx4zJ07Fz169MArr7yCfv364d1333Vyy5smqMaIDzdAJaKrXXfddUhKSsIPP/wAAFi7di2uXLmCJ598staxN954I7p27Yr//e9/VrcPHToUN9xwA55++ulGX3f37t24/fbbcccdd+DgwYOYP38+nn/++VpTQQsXLsSAAQOwd+9ePPzww3jooYdw/Pjxpne0Hi+++CKee+457NmzB15eXrjzzjvx1FNPYcmSJfjzzz9x+vRpvPbaazYfu2TJEqSkpGDmzJmW0ZzY2NgmXX/BggX47LPPsGzZMhw+fBiPP/447r77bmzcuBEymQyffvopdu7ciX//+98AgAcffBDt27e3BEAmkwkxMTH49ttvceTIEbzwwgt45plnLIGqwWDAlClTMHLkSBw4cADp6en429/+ZpfaN0899RS+//57fPrpp9izZw86d+6McePGIT8/3+bx27dvx/3334/Zs2dj3759uPbaa/HPf/6z3mt8+eWXeOGFF/Dqq6/i6NGjeO211/D888/j008/tTquodfx1KlTePHFF1vc55ZyaSXoyspK7N69G/PmzbPcJpfLMXr0aKSnp9t8THp6OubMmWN127hx4+pMptPpdNDpdJbftVotAPNGbHq93uZjmks6n63zBvpUP9VJ7QPsfm1nqa+P7sQT+tmW+6jX6yGEgMlksuTNqBUyHJo/ptaxQgiUFJfAP8DfYUXW1AqZzfwdW4QQlrZfrVu3bjh48CBMJpMluOjWrVudx544cQImk8lqKuzVV19F3759sXHjRowYMaLe6wHmwOa6667Ds88+CwDo3LkzDh8+jDfffBPTp0+3HDdhwgQ8+OCDAIC5c+di0aJFWLduHbp06dLkfkqk1086Zs6cORgzxvwa/t///R/uuusupKamIiUlBQBw3333Yfny5Zbz1rxGQEAAVCoVfHx8EB4ebnWNukjPm8lkgk6nw2uvvYa1a9darhcfH48///wTy5Ytw4gRIxAVFYWlS5dixowZyMrKwm+//Ybdu3dDLpfDZDJBoVBYfbF36NABW7duxddff42//OUvKCwsRFFRESZOnIiEhAQA5tfx6nZK7ZL+O23atFpVkXU6HSZOnAiTyYTS0lIsXboUH3/8McaNGwcAeP/995GamoqPPvoITz75pOX80vO9ePFijBs3zhJgz549G1u2bMGaNWssx06fPh3Tp0+3/P7iiy/izTfftIy6dejQAYcPH8b777+Pe+65p9Gv41//+ldL0HT1e0R6XW1Vgrb3Z5VLA6DLly/DaDQiIiLC6vaIiAgcO3bM5mOys7NtHp+dnW3z+AULFuCll16qdfvatWsbLKHfXKmpqbVuK74iByCHn5fAke0bcbSNlwCy1Ud35An9bIt9lKYtSkpKUFlZ2eDxPioFjLpyh7WnuKLxx+r1ehgMBssfY1ffJ4SAVqtFRYX5pFqt1mbFa4PBAIVCYXWe8vJyxMTE4I477sBTTz2FNWvWwGAwQK/X27weABw+fBgTJ060uj85ORlLlixBQUEBFAoFTCYTunbtanVMWFgYLly4UOd56+tnzfZqtVqUlJQAADp16mQ5PiDAXCg2Pj7ecltgYCDy8vJQXFxs8xoGgwGVlZX1XrMmnU4Ho9EIrVaLo0ePoqyszBJASCorK9GnTx/LOceNG4dJkybhX//6FxYuXIiIiAir63344Yf48ssvceHCBVRUVKCyshK9e/eGVqu1jIZMmDABo0aNwqhRozBlyhRERkbabJ/Uz1dffbVWMvL8+fMtfT906BD0er1VOwHz63jgwAFotVrLpsHFxcWQy+U4fPgwbrjhhlrHr1692ubzV1paitOnT2PmzJn4+9//brndYDBAo9E06XXUaDTIycmx6mPN57u8vBybNm2yyocD0ODGx03l9nuBzZs3z2rESKvVIjY2FmPHjoVGo7HrtfR6PVJTUzFmzBgoldZJzgdWH8eOvAwM7hSOSZOS7XpdZ6qvj+7EE/rZlvtYUVGB8+fPw9/fH97e3vUeK4RAcXExAgICWsXO2kqlEl5eXjY/f06dOoWOHTtCo9GgV69eAIALFy4gLi7O5rFJSUnQaDSWkQIfHx9oNBq8+uqr6N69O9avXw8vLy8olco6P+8UCgXUarXV/T4+PgDMX1QKhQJyuRwBAQFWxzR03vr6WfM6Go3GsvN3UFCQ5Xg/Pz8AQEhIiOU2Hx8fy2iPtIqu5jW8vLygUqka/dmuVquhUCisjv/ll1/Qvn37WsdJx5SVleHgwYNQKBS4cOGC1WNXrFiBF154AW+99RaGDBmCgIAAvPXWW9ixY4fluM8//xxz5szBmjVr8PPPP+PVV1/FmjVrMGTIEMt5ar5nAXPw0LdvX6s2BQcHo7Cw0Or5q+81kv7gl46x9bp7e3tDJpPZfP7Ky81/QLz//vsYPHiw1X3Sc9iU11F6z17977KiogI+Pj645pprav3bbmxg21guDYDatWsHhUJhiQQlOTk5dUbEkZGRTTperVbbXGmgVCod9qFv69xjEqOw5kgupg3u0Oa+bGxx5PPXmnhCP9tiH41GI2QyGeRyeYP7gUnD69LxriYl6F7dlvXr1+PgwYN4/PHHIZfLMWHCBISEhGDRokUYPny41bE///wzTp48icWLF1umXyRyuRwdOnTA7Nmz8dxzz6FTp0719r1Hjx7YunWr1f3p6eno2rWr1fvC1jnqO29d/axJev2kY67+/6tvu/q6V19DpVLBZDI1+nWWvnjlcjl69eoFtVqNCxcu4Nprr63zMXPnzoVcLsfvv/+OiRMn4oYbbsB1110HwPy8DR06FLNmzbIcf+bMGav+AED//v3Rv39/PPPMM0hJScGKFSswdOhQy/0137P1PQdS37t06QKVSoX09HTL1Jper8euXbvw2GOP2XyOe/TogR07dlidd/v27bXaKomKikJ0dDTOnTuHe+65x+Zz09jXseb5r36PSK+rrc8le39OuTQAUqlU6N+/P9atW2eZUzSZTFi3bh1mz55t8zEpKSlYt26dVa2HmnOLrdWQjqHY/I/rXN0MImoFdDodsrOzYTQakZOTg9WrV2PBggW44YYbLHk3fn5+eP/993HHHXfgb3/7G2bPng2NRoN169Zh7ty5mDlzJiZOnFjnNebNm4cPP/wQZ8+erXdp9xNPPIGBAwfilVdewdSpU5Geno53333XanVPcxUVFWHfvn1Wt4WGhjY5Obmx4uPjsX37dpw7dw7+/v4ICQlpdDAUEBCAJ598Eo8//jhMJhOGDx+OoqIibNmyBRqNBvfeey9WrVqFjz/+GOnp6ejXrx/mzp2Le++9FwcOHEBwcDC6dOmCzz77DGvWrEFCQgI+//xz7Ny50xKUnD17Fh988AEmT56M6OhoHD9+HCdPnrTKtWoOPz8/PPTQQ5g7dy5CQkIQFxeHN954A2VlZbj//vttPuaRRx7BsGHD8NZbb+Gmm27CmjVrsHr16nqv89JLL+GRRx5BYGAgxo8fD51Oh127dqGgoKBWbm5b4PI/h+bMmYMPP/wQn376KY4ePYqHHnoIpaWluO+++wCYk7BqJkk/+uijWL16NRYuXIhjx45h/vz52LVrV50BExFRa7N69WpERUUhPj4e48ePx4YNG/Dvf/8bP/30k1Xi51/+8hds2LABmZmZGDFiBBISEvDAAw/g6aefbnAZekhICP7xj39Yconq0q9fP3zzzTdYsWIFevXqhRdeeAEvv/yyXYonpqWlITk52erHVk6mvTz55JNQKBTo2bMnwsLCkJmZ2aTHv/LKK3j++eexYMEC9OjRA+PHj8eqVauQkJCAvLw83H///Zg/fz769esHwBwQREREWJLD//73v+OWW27B1KlTMXjwYFy5cgUPP/yw5fy+vr44duwYbr31VnTt2hV/+9vfMGvWLKucmuZ6/fXXceutt+Kee+5Bv379cOrUKaxZswbBwbbLrgwZMgQffvghlixZgqSkJKxduxbPPfdcvdd44IEH8NFHH+GTTz5B7969MXLkSCxfvtwS4LU5ohV45513RFxcnFCpVGLQoEFi27ZtlvtGjhwp7r33Xqvjv/nmG9G1a1ehUqlEYmKiWLVqVaOvVVRUJACIoqIiezXforKyUvz444+isrLS7uduLTyhj0J4Rj/bch/Ly8vFkSNHRHl5eYPHGo1GUVBQIIxGoxNa5ljl5eVi7NixokePHiI3N9dyuzv1sT7sp/uoq4/1/du29/d3q0iCnj17dp0jOGlpabVuu+2223Dbbbc5uFVERK2Lt7c3fvrpJyxevBibNm3Crbfe6uomEbVZrSIAIiKixvH29m5SoUMiss3lOUBEREREzsYAiIjaLNHETUiJqHVz5r9pBkBE1OZI9UDsXRmWiFxLqux+9TYYjsAcICJqcxQKBYKCgpCbmwvAvLy4rirPJpMJlZWVqKioaBWFEB3BE/oIsJ/uxFYfTSYT8vLy4OvrCy8vx4cnDICIqE2Sqr9LQVBdhBAoLy+Hj49Pq9gKwxE8oY8A++lO6uqjXC5HXFycU/rNAIiI2iSZTIaoqCiEh4fXu0u0Xq/Hpk2bcM0117S5LT8ayxP6CLCf7qSuPqpUKqeNejEAIqI2TaFQ1JsvoFAoYDAY4O3t7bZfJp7QR4D9dCetoY/uOblIREREVA8GQERERORxGAARERGRx/G4HCCpyJJWq7X7ufV6PcrKyqDVat123tYT+gh4Rj89oY+AZ/TTE/oIsJ/upDl9lL637VUs0eMCoOLiYgBAbGysi1tCRERETVVcXIzAwMAWn0cmPKyWvMlkwqVLlxAQEGD3OgNarRaxsbE4f/48NBqNXc/dWnhCHwHP6Kcn9BHwjH56Qh8B9tOdNKePQggUFxcjOjraLkvlPW4ESC6XIyYmxqHX0Gg0bvumlXhCHwHP6Kcn9BHwjH56Qh8B9tOdNLWP9hj5kTAJmoiIiDwOAyAiIiLyOAyA7EitVuPFF1+EWq12dVMcxhP6CHhGPz2hj4Bn9NMT+giwn+6kNfTR45KgiYiIiDgCRERERB6HARARERF5HAZARERE5HEYABEREZHHYQBkJ++99x7i4+Ph7e2NwYMHY8eOHa5uUp0WLFiAgQMHIiAgAOHh4ZgyZQqOHz9udUxFRQVmzZqF0NBQ+Pv749Zbb0VOTo7VMZmZmZg0aRJ8fX0RHh6OuXPnwmAwWB2TlpaGfv36Qa1Wo3Pnzli+fLmju2fT66+/DplMhscee8xym7v08eLFi7j77rsRGhoKHx8f9O7dG7t27bLcL4TACy+8gKioKPj4+GD06NE4efKk1Tny8/Nx1113QaPRICgoCPfffz9KSkqsjjlw4ABGjBgBb29vxMbG4o033nBK/4xGI55//nkkJCTAx8cHnTp1wiuvvGK1H1Bb7OOmTZtw4403Ijo6GjKZDD/++KPV/c7s07fffovu3bvD29sbvXv3xm+//eaUfur1evzjH/9A79694efnh+joaEyfPh2XLl1qU/1s6LWs6cEHH4RMJsPixYutbm/tfQQa18+jR49i8uTJCAwMhJ+fHwYOHIjMzEzL/a3qc1dQi61YsUKoVCrx8ccfi8OHD4uZM2eKoKAgkZOT4+qm2TRu3DjxySefiEOHDol9+/aJiRMniri4OFFSUmI55sEHHxSxsbFi3bp1YteuXWLIkCFi6NChlvsNBoPo1auXGD16tNi7d6/47bffRLt27cS8efMsx5w5c0b4+vqKOXPmiCNHjoh33nlHKBQKsXr1aqf2d8eOHSI+Pl706dNHPProo5bb3aGP+fn5okOHDmLGjBli+/bt4syZM2LNmjXi1KlTlmNef/11ERgYKH788Uexf/9+MXnyZJGQkCDKy8stx4wfP14kJSWJbdu2iT///FN07txZTJs2zXJ/UVGRiIiIEHfddZc4dOiQ+N///id8fHzE+++/7/A+vvrqqyI0NFT8+uuv4uzZs+Lbb78V/v7+YsmSJW26j7/99pt49tlnxQ8//CAAiJUrV1rd76w+bdmyRSgUCvHGG2+II0eOiOeee04olUpx8OBBh/ezsLBQjB49Wnz99dfi2LFjIj09XQwaNEj079/f6hytvZ8NvZaSH374QSQlJYno6GixaNGiNtXHxvTz1KlTIiQkRMydO1fs2bNHnDp1Svz0009W34Wt6XOXAZAdDBo0SMyaNcvyu9FoFNHR0WLBggUubFXj5ebmCgBi48aNQgjzh5JSqRTffvut5ZijR48KACI9PV0IYf6HIJfLRXZ2tuWYpUuXCo1GI3Q6nRBCiKeeekokJiZaXWvq1Kli3Lhxju6SRXFxsejSpYtITU0VI0eOtARA7tLHf/zjH2L48OF13m8ymURkZKR48803LbcVFhYKtVot/ve//wkhhDhy5IgAIHbu3Gk55vfffxcymUxcvHhRCCHEf/7zHxEcHGzpt3Ttbt262btLtUyaNEn89a9/tbrtlltuEXfddZcQwj36ePWXiTP7dPvtt4tJkyZZtWfw4MHi73//u137KETtftqyY8cOAUBkZGQIIdpeP+vq44ULF0T79u3FoUOHRIcOHawCoLbWRyFs93Pq1Kni7rvvrvMxre1zl1NgLVRZWYndu3dj9OjRltvkcjlGjx6N9PR0F7as8YqKigAAISEhAIDdu3dDr9db9al79+6Ii4uz9Ck9PR29e/dGRESE5Zhx48ZBq9Xi8OHDlmNqnkM6xpnPy6xZszBp0qRa7XCXPv78888YMGAAbrvtNoSHhyM5ORkffvih5f6zZ88iOzvbqo2BgYEYPHiwVT+DgoIwYMAAyzGjR4+GXC7H9u3bLcdcc801UKlUlmPGjRuH48ePo6CgwKF9HDp0KNatW4cTJ04AAPbv34/NmzdjwoQJbtPHqzmzT65+D1+tqKgIMpkMQUFBANyjnyaTCffccw/mzp2LxMTEWve7Sx9XrVqFrl27Yty4cQgPD8fgwYOtpsla2+cuA6AWunz5MoxGo9WLBQARERHIzs52Uasaz2Qy4bHHHsOwYcPQq1cvAEB2djZUKpXlA0hSs0/Z2dk2+yzdV98xWq0W5eXljuiOlRUrVmDPnj1YsGBBrfvcpY9nzpzB0qVL0aVLF6xZswYPPfQQHnnkEXz66adW7azv/ZmdnY3w8HCr+728vBASEtKk58JRnn76adxxxx3o3r07lEolkpOT8dhjj+Guu+6yun5b7uPVnNmnuo5xxedXRUUF/vGPf2DatGmWDTLdoZ//+te/4OXlhUceecTm/e7Qx9zcXJSUlOD111/H+PHjsXbtWtx888245ZZbsHHjRkv7WtPnrsftBk/WZs2ahUOHDmHz5s2ubopdnT9/Ho8++ihSU1Ph7e3t6uY4jMlkwoABA/Daa68BAJKTk3Ho0CEsW7YM9957r4tbZx/ffPMNvvzyS3z11VdITEzEvn378NhjjyE6Otpt+kjmhOjbb78dQggsXbrU1c2xm927d2PJkiXYs2cPZDKZq5vjMCaTCQBw00034fHHHwcA9O3bF1u3bsWyZcswcuRIVzbPJo4AtVC7du2gUChqZbHn5OQgMjLSRa1qnNmzZ+PXX3/Fhg0bEBMTY7k9MjISlZWVKCwstDq+Zp8iIyNt9lm6r75jNBoNfHx87N0dK7t370Zubi769esHLy8veHl5YePGjfj3v/8NLy8vREREtPk+AkBUVBR69uxpdVuPHj0sqy6kdtb3/oyMjERubq7V/QaDAfn5+U16Lhxl7ty5llGg3r1745577sHjjz9uGdlzhz5ezZl9qusYZ/ZZCn4yMjKQmppqGf2R2teW+/nnn38iNzcXcXFxls+ijIwMPPHEE4iPj7e0rS33ETB/F3p5eTX4edSaPncZALWQSqVC//79sW7dOsttJpMJ69atQ0pKigtbVjchBGbPno2VK1di/fr1SEhIsLq/f//+UCqVVn06fvw4MjMzLX1KSUnBwYMHrf7RSh9c0j+AlJQUq3NIxzjjebn++utx8OBB7Nu3z/IzYMAA3HXXXZb/b+t9BIBhw4bVKmFw4sQJdOjQAQCQkJCAyMhIqzZqtVps377dqp+FhYXYvXu35Zj169fDZDJh8ODBlmM2bdoEvV5vOSY1NRXdunVDcHCww/oHAGVlZZDLrT+qFAqF5S9Od+jj1ZzZJ1e/h6Xg5+TJk/jjjz8QGhpqdX9b7+c999yDAwcOWH0WRUdHY+7cuVizZo1b9BEwfxcOHDiw3s+jVvfd0qSUabJpxYoVQq1Wi+XLl4sjR46Iv/3tbyIoKMgqi701eeihh0RgYKBIS0sTWVlZlp+ysjLLMQ8++KCIi4sT69evF7t27RIpKSkiJSXFcr+0VHHs2LFi3759YvXq1SIsLMzmUsW5c+eKo0ePivfee88ly+AlNVeBCeEefdyxY4fw8vISr776qjh58qT48ssvha+vr/jiiy8sx7z++usiKChI/PTTT+LAgQPipptusrmcOjk5WWzfvl1s3rxZdOnSxWoJbmFhoYiIiBD33HOPOHTokFixYoXw9fV1yjL4e++9V7Rv396yDP6HH34Q7dq1E0899VSb7mNxcbHYu3ev2Lt3rwAg3n77bbF3717L6idn9WnLli3Cy8tLvPXWW+Lo0aPixRdftOvS6fr6WVlZKSZPnixiYmLEvn37rD6Paq52au39bOi1vNrVq8DaQh8b088ffvhBKJVK8cEHH4iTJ09alqf/+eeflnO0ps9dBkB28s4774i4uDihUqnEoEGDxLZt21zdpDoBsPnzySefWI4pLy8XDz/8sAgODha+vr7i5ptvFllZWVbnOXfunJgwYYLw8fER7dq1E0888YTQ6/VWx2zYsEH07dtXqFQq0bFjR6trONvVAZC79PGXX34RvXr1Emq1WnTv3l188MEHVvebTCbx/PPPi4iICKFWq8X1118vjh8/bnXMlStXxLRp04S/v7/QaDTivvvuE8XFxVbH7N+/XwwfPlyo1WrRvn178frrrzu8b0IIodVqxaOPPiri4uKEt7e36Nixo3j22WetviDbYh83bNhg89/hvffe6/Q+ffPNN6Jr165CpVKJxMREsWrVKqf08+zZs3V+Hm3YsKHN9LOh1/JqtgKg1t5HIRrXz//+97+ic+fOwtvbWyQlJYkff/zR6hyt6XNXJkSNcqpEREREHoA5QERERORxGAARERGRx2EARERERB6HARARERF5HAZARERE5HEYABEREZHHYQBEREREHocBEBEREXkcBkBE1GYsX74cQUFBDr1GfHw8Fi9e7NBrEJHrMQAiojZj6tSpOHHihKubQURuwMvVDSAiaiwfHx/4+Pi4uhlE5AY4AkRETmMymbBgwQIkJCTAx8cHSUlJ+O677wAAaWlpkMlkWLVqFfr06QNvb28MGTIEhw4dsjz+6imw/fv349prr0VAQAA0Gg369++PXbt2We7//vvvkZiYCLVajfj4eCxcuNCqPbm5ubjxxhvh4+ODhIQEfPnll7XaXFhYiAceeABhYWHQaDS47rrrsH//fjs/M0TkbBwBIiKnWbBgAb744gssW7YMXbp0waZNm3D33XcjLCzMcszcuXOxZMkSREZG4plnnsGNN96IEydOQKlU1jrfXXfdheTkZCxduhQKhQL79u2zHLd7927cfvvtmD9/PqZOnYqtW7fi4YcfRmhoKGbMmAEAmDFjBi5duoQNGzZAqVTikUceQW5urtU1brvtNvj4+OD3339HYGAg3n//fVx//fU4ceIEQkJCHPdkEZFjNXn/eCKiZqioqBC+vr5i69atVrfff//9Ytq0aWLDhg0CgFixYoXlvitXrggfHx/x9ddfCyGE+OSTT0RgYKDl/oCAALF8+XKb17vzzjvFmDFjrG6bO3eu6NmzpxBCiOPHjwsAYseOHZb7jx49KgCIRYsWCSGE+PPPP4VGoxEVFRVW5+nUqZN4//33m/YEEFGrwhEgInKKU6dOoaysDGPGjLG6vbKyEsnJyZbfU1JSLP8fEhKCbt264ejRozbPOWfOHDzwwAP4/PPPMXr0aNx2223o1KkTAODo0aO46aabrI4fNmwYFi9eDKPRiKNHj8LLywv9+/e33N+9e/daU2wlJSUIDQ21Ok95eTlOnz7dtCeAiFoVBkBE5BQlJSUAgFWrVqF9+/ZW96nV6mYFFPPnz8edd96JVatW4ffff8eLL76IFStW4Oabb7Zbm6OiopCWllbrPkcvxycix2IARERO0bNnT6jVamRmZmLkyJG17pcCoG3btiEuLg4AUFBQgBMnTqBHjx51nrdr167o2rUrHn/8cUybNg2ffPIJbr75ZvTo0QNbtmyxOnbLli3o2rUrFAoFunfvDoPBgN27d2PgwIEAgOPHj6OwsNByfL9+/ZCdnQ0vLy/Ex8e38BkgotaEARAROUVAQACefPJJPP744zCZTBg+fDiKioqwZcsWaDQadOjQAQDw8ssvIzQ0FBEREXj22WfRrl07TJkypdb5ysvLMXfuXPzlL39BQkICLly4gJ07d+LWW28FADzxxBMYOHAgXnnlFUydOhXp6el499138Z///AcA0K1bN4wfPx5///vfsXTpUnh5eeGxxx6zWmY/evRopKSkYMqUKXjjjTfQtWtXXLp0CatWrcLNN9+MAQMGOP6JIyLHcHUSEhF5DpPJJBYvXiy6desmlEqlCAsLE+PGjRMbN260JEH/8ssvIjExUahUKjFo0CCxf/9+y+NrJkHrdDpxxx13iNjYWKFSqUR0dLSYPXu2KC8vtxz/3XffiZ49ewqlUini4uLEm2++adWerKwsMWnSJKFWq0VcXJz47LPPRIcOHSxJ0EIIodVqxf/93/+J6OhooVQqRWxsrLjrrrtEZmamQ58rInIsmRBCuDoIIyJKS0vDtddei4KCAubXEJHDsRAiEREReRwGQERERORxOAVGREREHocjQERERORxGAARERGRx2EARERERB6HARARERF5HAZARERE5HEYABEREZHHYQBEREREHocBEBEREXmc/wdyfMFTKxf0HAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make the environment with Limit Texas Hold'em\n",
        "env = rlcard.make('limit-holdem')\n",
        "eval_env = rlcard.make('limit-holdem')\n",
        "\n",
        "# Initialize a DQN agent\n",
        "TwoDQNagent = DQNAgent(\n",
        "    num_actions=env.num_actions,\n",
        "    state_shape=env.state_shape[0],\n",
        "    mlp_layers=[64, 64],\n",
        ")\n",
        "\n",
        "# Set the agents in the environment\n",
        "env.set_agents([TwoDQNagent, RandomAgent(num_actions=env.num_actions)])\n",
        "eval_env.set_agents([TwoDQNagent, RandomAgent(num_actions=env.num_actions)])\n",
        "\n",
        "# Initialize the Logger\n",
        "with Logger(\"experiments/limit_holdem_dqn_result/\") as logger:\n",
        "    for episode in range(5000):  # Change the number of episodes based on your computational budget\n",
        "        # Generate data from the environment\n",
        "        trajectories, payoffs = env.run(is_training=True)\n",
        "\n",
        "        # Reorganize the data to be state, action, reward, next_state, done\n",
        "        trajectories = reorganize(trajectories, payoffs)\n",
        "\n",
        "        # Feed transitions into agent memory, and train the agent\n",
        "        for ts in trajectories[0]:  # Only use trajectories of the learning agent\n",
        "            TwoDQNagent.feed(ts)\n",
        "\n",
        "        # Evaluate the performance every 100 episodes\n",
        "        if episode % 100 == 0:\n",
        "            print(f'Episode {episode}')\n",
        "            logger.log_performance(\n",
        "                env.timestep,\n",
        "                tournament(\n",
        "                    eval_env,\n",
        "                    1000  # Reduce the number for quicker evaluations\n",
        "                )[0]\n",
        "            )\n",
        "\n",
        "    # Get the paths for the learning curve\n",
        "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_curve(csv_path, fig_path, 'DQN on Limit Texas Hold\\'em')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40faa708",
      "metadata": {
        "id": "40faa708"
      },
      "source": [
        "\n",
        "### 3.3.5 Conclusion\n",
        "\n",
        "By extending standard Double Q-learning to Double DQN, we leverage the strengths of neural networks to handle complex, high-dimensional state spaces while maintaining reduced bias in Q-value estimation. This approach is particularly well-suited for strategic and stochastic environments like poker, where the agent must learn from a vast range of possible situations and actions. We see clear improvments in performance over the tabluar double-Q-learning algorithm: Rewards coverge at a high level after around 100'000 iterations, and are relatively stable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "899759ef",
      "metadata": {
        "id": "899759ef"
      },
      "source": [
        "## 3.4 Deep Fitted Q-Iteration: Combining DQN with Fitted Q-Iteration <a class=\"anchor\" id=\"3.4\"></a>\n",
        "\n",
        "Next, we propose a Deep Fitted Q-Iteration (DFQI) reinforcement learning approach that combines the strengths of Deep Q-Networks (DQN) with the batch learning capabilities of Fitted Q-Iteration (FQI). This hybrid approach is designed to leverage the deep learning capabilities to approximate complex functions while utilizing batch updates to improve stability and efficiency in learning. While the conceptual and formal background of DQN have already been covered, we briefly outline the Fitted Q-Iteration algorithm and discuss its general advantages, e.g. over a standard DQN approach. We then outline the combined method in more detail.\n",
        "\n",
        "### 3.4.1 Formal and Conceptual Outline of Fitted Q-Iteration\n",
        "\n",
        "1. **Initialization**:\n",
        "   - Begin with an initial Q-function $ Q_0(s, a) $, typically set to zero for all state-action pairs.\n",
        "\n",
        "2. **Offline Batch Collection**:\n",
        "   - Collect a dataset $ \\mathcal{D} $ of experience tuples $ (s, a, r, s') $. This can be done by running a random policy or a predefined policy to interact with the environment and store the resulting transitions.\n",
        "\n",
        "3. **Iteration Process**:\n",
        "   - For each iteration $ k = 1, 2, \\ldots, K $:\n",
        "     - **Compute Target Values**:\n",
        "       - For each experience tuple $ (s, a, r, s') $ in the dataset $ \\mathcal{D} $:\n",
        "         $\n",
        "         y = r + \\gamma \\max_{a'} Q_{k-1}(s', a')\n",
        "         $\n",
        "       - These target values represent the estimated future rewards given the current Q-function approximation.\n",
        "     - **Fit Q-Function**:\n",
        "       - Use a regression model (e.g., linear regression, neural networks) to fit the Q-function to these target values:\n",
        "         $\n",
        "         Q_k = \\arg \\min_Q \\sum_{(s, a, r, s') \\in \\mathcal{D}} \\left( y - Q(s, a) \\right)^2\n",
        "         $\n",
        "       - The goal is to find the Q-function $ Q_k $ that minimizes the mean squared error between the predicted Q-values and the target values.\n",
        "\n",
        "4. **Output**:\n",
        "   - After $ K $ iterations, the final Q-function $ Q_K(s, a) $ is obtained. This function approximates the optimal action-value function based on the experiences in the dataset $ \\mathcal{D} $.\n",
        "\n",
        "Fitted Q-Iteration leverages offline batches of experiences to iteratively refine the action-value function. This approach is particularly useful in scenarios where collecting real-time data is expensive or slow, and it benefits from the stability and efficiency provided by regression-based updates.\n",
        "\n",
        "\n",
        "### 3.4.2 Advantages of Fitted Q-Iteration\n",
        "\n",
        "1. **Batch Learning Efficiency**:\n",
        "   - FQI utilizes batch updates, which means it can efficiently process and learn from large datasets in a single update step.\n",
        "   - This batch nature allows for more stable updates because the Q-function is fitted using a large set of transitions, reducing the variance that comes from the incremental updates of DQN.\n",
        "\n",
        "2. **Reduced Overfitting**:\n",
        "   - By using batch updates FQI can reduce the risk of overfitting compared to e.g. DQN, which continuously updates a deep neural network based on individual transitions or small batches.\n",
        "\n",
        "3. **Simplicity and Flexibility**:\n",
        "   - FQI is conceptually simpler and more flexible in terms of the function approximator used. While DQN typically uses neural networks, FQI can leverage a variety of regression models, making it adaptable to the specifics of the problem domain.\n",
        "   - This flexibility allows for easier integration of domain knowledge and expert features into the learning process.\n",
        "\n",
        "4. **Data Reuse**:\n",
        "   - FQI can efficiently reuse the same batch of data for multiple updates, which is beneficial in scenarios where data collection is costly or slow. This is contrasted with DQN, which typically requires ongoing data collection and more complex mechanisms to reuse past data effectively.\n",
        "\n",
        "### 3.4.3 Applying Deep Fitted Q-Iteration to Poker\n",
        "\n",
        "In the context of Limit Texas Hold'em, DFQI can be an effective strategy:\n",
        "\n",
        "1. **Comprehensive State Representation**:\n",
        "   - In poker, the state includes not only the private and community cards but also the betting history, pot size, player positions, and other strategic information. DFQI uses deep neural networks to encode these high-dimensional states into meaningful representations.\n",
        "\n",
        "2. **Learning from Rich Experience Batches**:\n",
        "   - DFQI updates the neural network-based Q-function using large batches of experience data. For poker, this means that the agent can learn effective strategies from extensive sets of past hands, including rare but informative situations like significant bluffs or rare hands.\n",
        "   - This batch approach allows the agent to refine its strategy based on comprehensive data from various game phases and opponent behaviors.\n",
        "\n",
        "3. **Strategy Optimization**:\n",
        "   - By fitting the Q-function across a batch of data, DFQI helps the agent develop a more balanced and robust strategy that considers a wide range of potential actions and outcomes. This is particularly useful in poker, where the effectiveness of a decision (like folding, calling, or raising) often depends on complex and subtle interactions between players.\n",
        "\n",
        "4. **Adaptation to Opponents**:\n",
        "   - DFQI’s ability to update from batches of experiences means it can adapt to changes in opponents' strategies by periodically refitting the Q-function using new data reflecting these changes.\n",
        "\n",
        "5. **Reducing Bias and Variance**:\n",
        "   - The double Q-learning aspect of DFQI helps reduce the bias in the Q-value estimates, leading to more reliable strategy decisions. Meanwhile, the batch learning aspect helps smooth out the learning process and reduce variance by ensuring that each update is grounded in a comprehensive set of experiences.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c598ff6a",
      "metadata": {
        "id": "c598ff6a"
      },
      "source": [
        "### 3.4.4 Implementing Deep Fitted Q-Iteration for Poker\n",
        "\n",
        "The code builds on the `DQNAgent` implementation from the RLCard library, which leverages Double Deep Q-Network (DDQN) algorithms for training an agent to play Limit Texas Hold'em poker as outlined above. We have extended this implementation by integrating a Fitted Q Iteration component. Specifically, we introduced a `FittedQAgent` that uses `GradientBoostingRegressor` models to approximate Q-values, enhancing the value function approximation. This agent is integrated within the `DQNAgentWithFittedQ` class. The key modifications include the addition of the `FittedQAgent` to perform function approximation and adjustments in the training loop to ensure the models are trained and used correctly. The goal is to combine the stability and learning efficiency of Double DQN with the advanced function approximation capabilities of Fitted Q Iteration, aiming to improve the agent's performance in the complex environment of poker.\n",
        "\n",
        "The following provides a break down of the algorithm and how the components interact with eachother:\n",
        "\n",
        "#### Algorithm Overview\n",
        "\n",
        "The algorithm we've developed combines Double DQN (Deep Q-Network) with Fitted Q Iteration (FQI) for value function approximation. Here's a detailed breakdown:\n",
        "\n",
        "1. **Double DQN (Deep Q-Network):**\n",
        "    - **Role:** The Double DQN is responsible for learning the optimal action-value function Q(s, a) using a neural network. It helps the agent make decisions by approximating the expected future rewards for each action in a given state.\n",
        "    - **Mechanism:**\n",
        "        - **Q-Network and Target Network:** The agent maintains two neural networks: the Q-Network for predicting Q-values and the Target Network for providing stable target Q-values.\n",
        "        - **Experience Replay:** Experiences (state, action, reward, next state, done) are stored in a replay memory. The agent samples mini-batches from this memory to update the Q-Network, which helps break the correlation between consecutive experiences.\n",
        "        - **Double Q-Learning:** To reduce overestimation bias, the Double DQN updates the Q-values using the actions chosen by the Q-Network but evaluates them using the Target Network.\n",
        "\n",
        "2. **Fitted Q Iteration (FQI):**\n",
        "    - **Role:** The FQI component approximates the Q-values using supervised learning methods (Gradient Boosting Regressors). It provides a non-parametric way to approximate the Q-values, which can be beneficial for environments with complex dynamics.\n",
        "    - **Mechanism:**\n",
        "        - **Gradient Boosting Regressors:** Separate models are trained for each action. These models are used to predict Q-values based on the current state.\n",
        "        - **Batch Training:** During training, the agent fits these regressors using a batch of experiences. The targets for the regressors are computed using the Bellman equation, incorporating the Q-values predicted by the regressors for the next states.\n",
        "\n",
        "#### Interaction Between Double DQN and FQI\n",
        "\n",
        "1. **Experience Collection:**\n",
        "    - The agent interacts with the Limit Texas Hold'em environment, taking actions based on an epsilon-greedy policy derived from the sum of Q-values from the Double DQN and the Fitted Q models.\n",
        "    - Experiences (state, action, reward, next state, done) are collected and stored in the replay memory.\n",
        "\n",
        "2. **Training Process:**\n",
        "    - **Sampling:** A mini-batch of experiences is sampled from the replay memory.\n",
        "    - **Fitted Q Iteration:**\n",
        "        - The `FittedQAgent` uses the batch of experiences to train its Gradient Boosting Regressors. It fits these models by computing targets using the rewards and the discounted Q-values for the next states, as predicted by the regressors.\n",
        "    - **Double DQN Update:**\n",
        "        - The Q-values for the next states are predicted using the Fitted Q models.\n",
        "        - The targets for the Double DQN update are computed using these predicted Q-values, combining the benefits of both approaches.\n",
        "        - The Q-Network of the Double DQN is updated using these targets, and periodically, the Target Network is updated with the Q-Network's weights.\n",
        "\n",
        "3. **Action Selection:**\n",
        "    - During training, actions are selected using an epsilon-greedy policy based on the Q-values predicted by the Double DQN combined with the Q-values from the Fitted Q models.\n",
        "    - During evaluation, actions are selected greedily based on the combined Q-values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ef75998c",
      "metadata": {
        "id": "ef75998c"
      },
      "outputs": [],
      "source": [
        "class FittedQAgent:\n",
        "    def __init__(self, state_size, action_size, n_estimators=100, max_depth=3, learning_rate=0.1, gamma=0.99):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.gamma = gamma  # Discount factor for future rewards\n",
        "        self.models = [GradientBoostingRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n",
        "                       for _ in range(action_size)]\n",
        "        self.is_fitted = [False] * action_size\n",
        "\n",
        "    def fit(self, states, actions, rewards, next_states, dones):\n",
        "        next_action_values = self.predict(next_states)\n",
        "        targets = rewards + self.gamma * np.max(next_action_values, axis=1) * (1 - dones)\n",
        "\n",
        "        for action in range(self.action_size):\n",
        "            action_mask = (actions == action)\n",
        "            if np.any(action_mask):\n",
        "                # Ensuring the targets for the fitting are 1D\n",
        "                action_targets = targets[action_mask]\n",
        "                self.models[action].fit(states[action_mask], action_targets)\n",
        "                self.is_fitted[action] = True\n",
        "\n",
        "    def predict(self, states):\n",
        "        action_values = np.zeros((states.shape[0], self.action_size))\n",
        "        for action in range(self.action_size):\n",
        "            if self.is_fitted[action]:\n",
        "                action_values[:, action] = self.models[action].predict(states)\n",
        "            else:\n",
        "                # If not fitted, predict zeros\n",
        "                action_values[:, action] = np.zeros(states.shape[0])\n",
        "        return action_values\n",
        "\n",
        "    def act(self, state, epsilon=0.1):\n",
        "        if np.random.rand() < epsilon:\n",
        "            return np.random.randint(self.action_size)\n",
        "        else:\n",
        "            q_values = self.predict(state.reshape(1, -1))[0]\n",
        "            return np.argmax(q_values)\n",
        "\n",
        "Transition = namedtuple('Transition', ['state', 'action', 'reward', 'next_state', 'done', 'legal_actions'])\n",
        "\n",
        "class DQNAgentWithFittedQ:\n",
        "    def __init__(self,\n",
        "                 replay_memory_size=20000,\n",
        "                 replay_memory_init_size=100,\n",
        "                 update_target_estimator_every=1000,\n",
        "                 discount_factor=0.99,\n",
        "                 epsilon_start=1.0,\n",
        "                 epsilon_end=0.1,\n",
        "                 epsilon_decay_steps=20000,\n",
        "                 batch_size=32,\n",
        "                 num_actions=2,\n",
        "                 state_shape=None,\n",
        "                 train_every=1,\n",
        "                 mlp_layers=None,\n",
        "                 learning_rate=0.00005,\n",
        "                 device=None,\n",
        "                 save_path=None,\n",
        "                 save_every=float('inf'),\n",
        "                 fitted_q_iterations=100,  # Number of iterations for fitting Q\n",
        "                 max_depth=3,  # Max depth for Gradient Boosting\n",
        "                 estimator_lr=0.1):  # Learning rate for Gradient Boosting\n",
        "\n",
        "        # Initialization code...\n",
        "        self.use_raw = False\n",
        "        self.replay_memory_init_size = replay_memory_init_size\n",
        "        self.update_target_estimator_every = update_target_estimator_every\n",
        "        self.discount_factor = discount_factor\n",
        "        self.epsilon_decay_steps = epsilon_decay_steps\n",
        "        self.batch_size = batch_size\n",
        "        self.num_actions = num_actions\n",
        "        self.train_every = train_every\n",
        "\n",
        "        # Torch device\n",
        "        if device is None:\n",
        "            self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        # Total timesteps\n",
        "        self.total_t = 0\n",
        "\n",
        "        # Total training step\n",
        "        self.train_t = 0\n",
        "\n",
        "        # The epsilon decay scheduler\n",
        "        self.epsilons = np.linspace(epsilon_start, epsilon_end, epsilon_decay_steps)\n",
        "\n",
        "        # Create estimators\n",
        "        self.q_estimator = Estimator(num_actions=num_actions, learning_rate=learning_rate, state_shape=state_shape, mlp_layers=mlp_layers, device=self.device)\n",
        "        self.target_estimator = Estimator(num_actions=num_actions, learning_rate=learning_rate, state_shape=state_shape, mlp_layers=mlp_layers, device=self.device)\n",
        "\n",
        "        # Fitted Q agent\n",
        "        self.fitted_q_agent = FittedQAgent(state_size=np.prod(state_shape), action_size=num_actions, n_estimators=fitted_q_iterations, max_depth=max_depth, learning_rate=estimator_lr)\n",
        "\n",
        "        # Create replay memory\n",
        "        self.memory = Memory(replay_memory_size, batch_size)\n",
        "\n",
        "        # Checkpoint saving parameters\n",
        "        self.save_path = save_path\n",
        "        self.save_every = save_every\n",
        "\n",
        "    def feed(self, ts):\n",
        "        (state, action, reward, next_state, done) = tuple(ts)\n",
        "\n",
        "\n",
        "        self.feed_memory(state['obs'], action, reward, next_state['obs'], list(next_state['legal_actions'].keys()), done)\n",
        "        self.total_t += 1\n",
        "        tmp = self.total_t - self.replay_memory_init_size\n",
        "        if tmp >= 0 and tmp % self.train_every == 0:\n",
        "            if len(self.memory.memory) >= self.batch_size:  # Ensure there's enough data\n",
        "                self.train()\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        if len(self.memory.memory) < self.batch_size:\n",
        "            return  # Not enough data to train\n",
        "\n",
        "        state_batch, action_batch, reward_batch, next_state_batch, done_batch, _ = self.memory.sample()\n",
        "\n",
        "        states = np.vstack(state_batch)\n",
        "        next_states = np.vstack(next_state_batch)\n",
        "\n",
        "        # Training the Fitted Q model\n",
        "        self.fitted_q_agent.fit(states, action_batch, reward_batch, next_states, done_batch)\n",
        "\n",
        "        # Prepare the batch for DQN update\n",
        "        q_values_next = self.fitted_q_agent.predict(next_states)\n",
        "        q_values_next_target = self.target_estimator.predict_nograd(next_state_batch)\n",
        "        target_batch = reward_batch + (1 - done_batch.astype(np.float32)) * self.discount_factor * np.max(q_values_next_target, axis=1)\n",
        "\n",
        "        # Update the DQN\n",
        "        loss = self.q_estimator.update(state_batch, action_batch, target_batch)\n",
        "        print(f'\\rINFO - Step {self.total_t}, rl-loss: {loss}', end='')\n",
        "\n",
        "        if self.train_t % self.update_target_estimator_every == 0:\n",
        "            self.target_estimator = deepcopy(self.q_estimator)\n",
        "            print(\"\\nINFO - Copied model parameters to target network.\")\n",
        "\n",
        "        self.train_t += 1\n",
        "\n",
        "        if self.save_path and self.train_t % self.save_every == 0:\n",
        "            self.save_checkpoint(self.save_path)\n",
        "            print(\"\\nINFO - Saved model checkpoint.\")\n",
        "\n",
        "\n",
        "\n",
        "    def step(self, state):\n",
        "        q_values = self.predict(state)\n",
        "        epsilon = self.epsilons[min(self.total_t, self.epsilon_decay_steps-1)]\n",
        "        legal_actions = list(state['legal_actions'].keys())\n",
        "        probs = np.ones(len(legal_actions), dtype=float) * epsilon / len(legal_actions)\n",
        "        best_action_idx = legal_actions.index(np.argmax(q_values))\n",
        "        probs[best_action_idx] += (1.0 - epsilon)\n",
        "        action_idx = np.random.choice(np.arange(len(probs)), p=probs)\n",
        "        return legal_actions[action_idx]\n",
        "\n",
        "    def eval_step(self, state):\n",
        "        q_values = self.predict(state)\n",
        "        best_action = np.argmax(q_values)\n",
        "        info = {}\n",
        "        info['values'] = {state['raw_legal_actions'][i]: float(q_values[list(state['legal_actions'].keys())[i]]) for i in range(len(state['legal_actions']))}\n",
        "        return best_action, info\n",
        "\n",
        "    def predict(self, state):\n",
        "        q_values = self.q_estimator.predict_nograd(np.expand_dims(state['obs'], 0))[0]\n",
        "        masked_q_values = -np.inf * np.ones(self.num_actions, dtype=float)\n",
        "        legal_actions = list(state['legal_actions'].keys())\n",
        "        masked_q_values[legal_actions] = q_values[legal_actions]\n",
        "        return masked_q_values\n",
        "\n",
        "    def feed_memory(self, state, action, reward, next_state, legal_actions, done):\n",
        "        self.memory.save(state, action, reward, next_state, legal_actions, done)\n",
        "\n",
        "    def set_device(self, device):\n",
        "        self.device = device\n",
        "        self.q_estimator.device = device\n",
        "        self.target_estimator.device = device\n",
        "\n",
        "    def checkpoint_attributes(self):\n",
        "        return {\n",
        "            'agent_type': 'DQNAgentWithFittedQ',\n",
        "            'q_estimator': self.q_estimator.checkpoint_attributes(),\n",
        "            'memory': self.memory.checkpoint_attributes(),\n",
        "            'total_t': self.total_t,\n",
        "            'train_t': self.train_t,\n",
        "            'replay_memory_init_size': self.replay_memory_init_size,\n",
        "            'update_target_estimator_every': self.update_target_estimator_every,\n",
        "            'discount_factor': self.discount_factor,\n",
        "            'epsilon_start': self.epsilons.min(),\n",
        "            'epsilon_end': self.epsilons.max(),\n",
        "            'epsilon_decay_steps': self.epsilon_decay_steps,\n",
        "            'batch_size': self.batch_size,\n",
        "            'num_actions': self.num_actions,\n",
        "            'train_every': self.train_every,\n",
        "            'device': self.device,\n",
        "            'save_path': self.save_path,\n",
        "            'save_every': self.save_every\n",
        "        }\n",
        "\n",
        "    @classmethod\n",
        "    def from_checkpoint(cls, checkpoint):\n",
        "        print(\"\\nINFO - Restoring model from checkpoint...\")\n",
        "        agent_instance = cls(\n",
        "            replay_memory_size=checkpoint['memory']['memory_size'],\n",
        "            replay_memory_init_size=checkpoint['replay_memory_init_size'],\n",
        "            update_target_estimator_every=checkpoint['update_target_estimator_every'],\n",
        "            discount_factor=checkpoint['discount_factor'],\n",
        "            epsilon_start=checkpoint['epsilon_start'],\n",
        "            epsilon_end=checkpoint['epsilon_end'],\n",
        "            epsilon_decay_steps=checkpoint['epsilon_decay_steps'],\n",
        "            batch_size=checkpoint['batch_size'],\n",
        "            num_actions=checkpoint['num_actions'],\n",
        "            state_shape=checkpoint['q_estimator']['state_shape'],\n",
        "            train_every=checkpoint['train_every'],\n",
        "            mlp_layers=checkpoint['q_estimator']['mlp_layers'],\n",
        "            learning_rate=checkpoint['q_estimator']['learning_rate'],\n",
        "            device=checkpoint['device'],\n",
        "            save_path=checkpoint['save_path'],\n",
        "            save_every=checkpoint['save_every'],\n",
        "        )\n",
        "\n",
        "        agent_instance.total_t = checkpoint['total_t']\n",
        "        agent_instance.train_t = checkpoint['train_t']\n",
        "\n",
        "        agent_instance.q_estimator = Estimator.from_checkpoint(checkpoint['q_estimator'])\n",
        "        agent_instance.target_estimator = deepcopy(agent_instance.q_estimator)\n",
        "        agent_instance.memory = Memory.from_checkpoint(checkpoint['memory'])\n",
        "\n",
        "        return agent_instance\n",
        "\n",
        "    def save_checkpoint(self, path, filename='checkpoint_dqn_with_fittedq.pt'):\n",
        "        torch.save(self.checkpoint_attributes(), os.path.join(path, filename))\n",
        "\n",
        "\n",
        "class Estimator(object):\n",
        "    def __init__(self, num_actions=2, learning_rate=0.001, state_shape=None, mlp_layers=None, device=None):\n",
        "        self.num_actions = num_actions\n",
        "        self.learning_rate = learning_rate\n",
        "        self.state_shape = state_shape\n",
        "        self.mlp_layers = mlp_layers\n",
        "        self.device = device\n",
        "\n",
        "        qnet = EstimatorNetwork(num_actions, state_shape, mlp_layers)\n",
        "        qnet = qnet.to(self.device)\n",
        "        self.qnet = qnet\n",
        "        self.qnet.eval()\n",
        "\n",
        "        for p in self.qnet.parameters():\n",
        "            if len(p.data.shape) > 1:\n",
        "                nn.init.xavier_uniform_(p.data)\n",
        "\n",
        "        self.mse_loss = nn.MSELoss(reduction='mean')\n",
        "        self.optimizer = torch.optim.Adam(self.qnet.parameters(), lr=self.learning_rate)\n",
        "\n",
        "    def predict_nograd(self, s):\n",
        "        with torch.no_grad():\n",
        "            s = torch.from_numpy(s).float().to(self.device)\n",
        "            q_as = self.qnet(s).cpu().numpy()\n",
        "        return q_as\n",
        "\n",
        "    def update(self, s, a, y):\n",
        "        self.optimizer.zero_grad()\n",
        "        self.qnet.train()\n",
        "        s = torch.from_numpy(s).float().to(self.device)\n",
        "        a = torch.from_numpy(a).long().to(self.device)\n",
        "        y = torch.from_numpy(y).float().to(self.device)\n",
        "\n",
        "        q_as = self.qnet(s)\n",
        "        Q = torch.gather(q_as, dim=-1, index=a.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        batch_loss = self.mse_loss(Q, y)\n",
        "        batch_loss.backward()\n",
        "        self.optimizer.step()\n",
        "        batch_loss = batch_loss.item()\n",
        "\n",
        "        self.qnet.eval()\n",
        "        return batch_loss\n",
        "\n",
        "    def checkpoint_attributes(self):\n",
        "        return {\n",
        "            'qnet': self.qnet.state_dict(),\n",
        "            'optimizer': self.optimizer.state_dict(),\n",
        "            'num_actions': self.num_actions,\n",
        "            'learning_rate': self.learning_rate,\n",
        "            'state_shape': self.state_shape,\n",
        "            'mlp_layers': self.mlp_layers,\n",
        "            'device': self.device\n",
        "        }\n",
        "\n",
        "    @classmethod\n",
        "    def from_checkpoint(cls, checkpoint):\n",
        "        estimator = cls(\n",
        "            num_actions=checkpoint['num_actions'],\n",
        "            learning_rate=checkpoint['learning_rate'],\n",
        "            state_shape=checkpoint['state_shape'],\n",
        "            mlp_layers=checkpoint['mlp_layers'],\n",
        "            device=checkpoint['device']\n",
        "        )\n",
        "\n",
        "        estimator.qnet.load_state_dict(checkpoint['qnet'])\n",
        "        estimator.optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        return estimator\n",
        "\n",
        "\n",
        "class EstimatorNetwork(nn.Module):\n",
        "    def __init__(self, num_actions=2, state_shape=None, mlp_layers=None):\n",
        "        super(EstimatorNetwork, self).__init__()\n",
        "        self.num_actions = num_actions\n",
        "        self.state_shape = state_shape\n",
        "        self.mlp_layers = mlp_layers\n",
        "\n",
        "        layer_dims = [np.prod(self.state_shape)] + self.mlp_layers\n",
        "        fc = [nn.Flatten()]\n",
        "        fc.append(nn.BatchNorm1d(layer_dims[0]))\n",
        "        for i in range(len(layer_dims) - 1):\n",
        "            fc.append(nn.Linear(layer_dims[i], layer_dims[i + 1], bias=True))\n",
        "            fc.append(nn.Tanh())\n",
        "        fc.append(nn.Linear(layer_dims[-1], self.num_actions, bias=True))\n",
        "        self.fc_layers = nn.Sequential(*fc)\n",
        "\n",
        "    def forward(self, s):\n",
        "        return self.fc_layers(s)\n",
        "\n",
        "class Memory(object):\n",
        "    def __init__(self, memory_size, batch_size):\n",
        "        self.memory_size = memory_size\n",
        "        self.batch_size = batch_size\n",
        "        self.memory = []\n",
        "\n",
        "    def save(self, state, action, reward, next_state, legal_actions, done):\n",
        "        if len(self.memory) == self.memory_size:\n",
        "            self.memory.pop(0)\n",
        "        transition = Transition(state, action, reward, next_state, done, legal_actions)\n",
        "        self.memory.append(transition)\n",
        "\n",
        "    def sample(self):\n",
        "        samples = random.sample(self.memory, self.batch_size)\n",
        "        samples = tuple(zip(*samples))\n",
        "        return tuple(map(np.array, samples[:-1])) + (samples[-1],)\n",
        "\n",
        "    def checkpoint_attributes(self):\n",
        "        return {\n",
        "            'memory_size': self.memory_size,\n",
        "            'batch_size': self.batch_size,\n",
        "            'memory': self.memory\n",
        "        }\n",
        "\n",
        "    @classmethod\n",
        "    def from_checkpoint(cls, checkpoint):\n",
        "        instance = cls(checkpoint['memory_size'], checkpoint['batch_size'])\n",
        "        instance.memory = checkpoint['memory']\n",
        "        return instance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "LbYAI7_OKj33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LbYAI7_OKj33",
        "outputId": "0a5b5168-73b4-4564-ba87-eedfadbd8a7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4\n",
            "  reward       |  -0.1035\n",
            "----------------------------------------\n",
            "INFO - Step 100, rl-loss: 9.582218170166016\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 147, rl-loss: 6.417984962463379Episode 100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  294\n",
            "  reward       |  0.867\n",
            "----------------------------------------\n",
            "INFO - Step 292, rl-loss: 2.869814157485962Episode 200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  592\n",
            "  reward       |  0.7535\n",
            "----------------------------------------\n",
            "INFO - Step 442, rl-loss: 0.7012593746185303Episode 300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  895\n",
            "  reward       |  1.1255\n",
            "----------------------------------------\n",
            "INFO - Step 569, rl-loss: 2.6689705848693848Episode 400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1162\n",
            "  reward       |  1.173\n",
            "----------------------------------------\n",
            "INFO - Step 728, rl-loss: 3.4426138401031494Episode 500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1476\n",
            "  reward       |  1.23\n",
            "----------------------------------------\n",
            "INFO - Step 862, rl-loss: 1.115605354309082Episode 600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1747\n",
            "  reward       |  1.684\n",
            "----------------------------------------\n",
            "INFO - Step 1024, rl-loss: 0.8754088282585144Episode 700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2063\n",
            "  reward       |  1.7115\n",
            "----------------------------------------\n",
            "INFO - Step 1100, rl-loss: 2.9621758460998535\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 1136, rl-loss: 1.8428690433502197Episode 800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2307\n",
            "  reward       |  1.701\n",
            "----------------------------------------\n",
            "INFO - Step 1272, rl-loss: 4.237231731414795Episode 900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2581\n",
            "  reward       |  1.855\n",
            "----------------------------------------\n",
            "INFO - Step 1436, rl-loss: 1.7307984828948975Episode 1000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2903\n",
            "  reward       |  1.677\n",
            "----------------------------------------\n",
            "INFO - Step 1576, rl-loss: 0.93177330493927Episode 1100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3186\n",
            "  reward       |  1.9325\n",
            "----------------------------------------\n",
            "INFO - Step 1738, rl-loss: 1.4392991065979004Episode 1200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3506\n",
            "  reward       |  1.8515\n",
            "----------------------------------------\n",
            "INFO - Step 1885, rl-loss: 0.7186375856399536Episode 1300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3804\n",
            "  reward       |  1.7915\n",
            "----------------------------------------\n",
            "INFO - Step 2035, rl-loss: 2.9475443363189697Episode 1400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4112\n",
            "  reward       |  1.7385\n",
            "----------------------------------------\n",
            "INFO - Step 2100, rl-loss: 0.7740249633789062\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 2201, rl-loss: 3.940661907196045Episode 1500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4443\n",
            "  reward       |  2.017\n",
            "----------------------------------------\n",
            "INFO - Step 2356, rl-loss: 0.8296369314193726Episode 1600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4757\n",
            "  reward       |  1.792\n",
            "----------------------------------------\n",
            "INFO - Step 2508, rl-loss: 1.0240634679794312Episode 1700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5073\n",
            "  reward       |  2.0645\n",
            "----------------------------------------\n",
            "INFO - Step 2683, rl-loss: 3.2125308513641357Episode 1800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5427\n",
            "  reward       |  1.798\n",
            "----------------------------------------\n",
            "INFO - Step 2823, rl-loss: 0.6204053163528442Episode 1900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5708\n",
            "  reward       |  2.22\n",
            "----------------------------------------\n",
            "INFO - Step 2986, rl-loss: 0.9012929201126099Episode 2000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6025\n",
            "  reward       |  1.9105\n",
            "----------------------------------------\n",
            "INFO - Step 3100, rl-loss: 1.3963284492492676\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 3132, rl-loss: 0.46673479676246643Episode 2100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6322\n",
            "  reward       |  1.941\n",
            "----------------------------------------\n",
            "INFO - Step 3277, rl-loss: 0.830318033695221Episode 2200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6619\n",
            "  reward       |  2.12\n",
            "----------------------------------------\n",
            "INFO - Step 3425, rl-loss: 0.7482326030731201Episode 2300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6914\n",
            "  reward       |  2.068\n",
            "----------------------------------------\n",
            "INFO - Step 3560, rl-loss: 0.641281008720398Episode 2400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7194\n",
            "  reward       |  2.257\n",
            "----------------------------------------\n",
            "INFO - Step 3742, rl-loss: 2.625837802886963Episode 2500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7574\n",
            "  reward       |  1.855\n",
            "----------------------------------------\n",
            "INFO - Step 3893, rl-loss: 0.5089488625526428Episode 2600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7877\n",
            "  reward       |  2.0015\n",
            "----------------------------------------\n",
            "INFO - Step 4039, rl-loss: 2.7201995849609375Episode 2700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8183\n",
            "  reward       |  2.1115\n",
            "----------------------------------------\n",
            "INFO - Step 4100, rl-loss: 0.6085601449012756\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 4188, rl-loss: 1.1999448537826538Episode 2800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8483\n",
            "  reward       |  2.1375\n",
            "----------------------------------------\n",
            "INFO - Step 4349, rl-loss: 0.8329945802688599Episode 2900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8813\n",
            "  reward       |  2.3075\n",
            "----------------------------------------\n",
            "INFO - Step 4510, rl-loss: 0.851134181022644Episode 3000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9148\n",
            "  reward       |  1.906\n",
            "----------------------------------------\n",
            "INFO - Step 4688, rl-loss: 1.379343032836914Episode 3100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9502\n",
            "  reward       |  1.883\n",
            "----------------------------------------\n",
            "INFO - Step 4830, rl-loss: 2.392312526702881Episode 3200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9794\n",
            "  reward       |  1.689\n",
            "----------------------------------------\n",
            "INFO - Step 4991, rl-loss: 0.38510584831237793Episode 3300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10123\n",
            "  reward       |  2.3235\n",
            "----------------------------------------\n",
            "INFO - Step 5100, rl-loss: 0.42079415917396545\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 5148, rl-loss: 0.5281276702880859Episode 3400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10452\n",
            "  reward       |  1.9675\n",
            "----------------------------------------\n",
            "INFO - Step 5313, rl-loss: 3.3246614933013916Episode 3500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10807\n",
            "  reward       |  2.026\n",
            "----------------------------------------\n",
            "INFO - Step 5476, rl-loss: 1.682581901550293Episode 3600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11147\n",
            "  reward       |  2.208\n",
            "----------------------------------------\n",
            "INFO - Step 5608, rl-loss: 0.4346545338630676Episode 3700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11418\n",
            "  reward       |  1.9185\n",
            "----------------------------------------\n",
            "INFO - Step 5779, rl-loss: 0.46798378229141235Episode 3800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11766\n",
            "  reward       |  1.9305\n",
            "----------------------------------------\n",
            "INFO - Step 5925, rl-loss: 0.5178142786026001Episode 3900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12059\n",
            "  reward       |  1.7605\n",
            "----------------------------------------\n",
            "INFO - Step 6076, rl-loss: 0.956672191619873Episode 4000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12362\n",
            "  reward       |  1.9225\n",
            "----------------------------------------\n",
            "INFO - Step 6100, rl-loss: 0.5825209617614746\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 6257, rl-loss: 1.4761797189712524Episode 4100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12745\n",
            "  reward       |  1.9775\n",
            "----------------------------------------\n",
            "INFO - Step 6423, rl-loss: 1.334265112876892Episode 4200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13085\n",
            "  reward       |  2.1945\n",
            "----------------------------------------\n",
            "INFO - Step 6578, rl-loss: 0.5923542976379395Episode 4300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13404\n",
            "  reward       |  2.087\n",
            "----------------------------------------\n",
            "INFO - Step 6741, rl-loss: 0.6647729277610779Episode 4400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13745\n",
            "  reward       |  2.449\n",
            "----------------------------------------\n",
            "INFO - Step 6895, rl-loss: 0.38577765226364136Episode 4500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14054\n",
            "  reward       |  1.966\n",
            "----------------------------------------\n",
            "INFO - Step 7041, rl-loss: 0.6325111389160156Episode 4600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14360\n",
            "  reward       |  2.0575\n",
            "----------------------------------------\n",
            "INFO - Step 7100, rl-loss: 1.732988715171814\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 7215, rl-loss: 0.6102179288864136Episode 4700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14729\n",
            "  reward       |  2.2705\n",
            "----------------------------------------\n",
            "INFO - Step 7383, rl-loss: 1.2028346061706543Episode 4800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15079\n",
            "  reward       |  2.238\n",
            "----------------------------------------\n",
            "INFO - Step 7558, rl-loss: 0.4944385886192322Episode 4900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15434\n",
            "  reward       |  2.2795\n",
            "----------------------------------------\n",
            "INFO - Step 7711, rl-loss: 4.036870002746582\n",
            "Logs saved in experiments/limit_holdem_dqn_with_fittedq_result/\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make the environment with Limit Texas Hold'em\n",
        "env = rlcard.make('limit-holdem')\n",
        "eval_env = rlcard.make('limit-holdem')\n",
        "\n",
        "# Initialize the Double DQN + Fitted Q Iteration agent\n",
        "FittedDQagent = DQNAgentWithFittedQ(\n",
        "    num_actions=env.num_actions,\n",
        "    state_shape=env.state_shape[0],\n",
        "    mlp_layers=[64, 64],\n",
        ")\n",
        "\n",
        "# Set the agents in the environment\n",
        "env.set_agents([FittedDQagent, RandomAgent(num_actions=env.num_actions)])\n",
        "eval_env.set_agents([FittedDQagent, RandomAgent(num_actions=env.num_actions)])\n",
        "\n",
        "# Initialize the Logger\n",
        "with Logger(\"experiments/limit_holdem_dqn_with_fittedq_result/\") as logger:\n",
        "    for episode in range(5000): \n",
        "        # Generate data from the environment\n",
        "        trajectories, payoffs = env.run(is_training=True)\n",
        "\n",
        "        # Reorganize the data to be state, action, reward, next_state, done\n",
        "        trajectories = reorganize(trajectories, payoffs)\n",
        "\n",
        "        # Feed transitions into agent memory, and train the agent\n",
        "        for ts in trajectories[0]:  # Only use trajectories of the learning agent\n",
        "            FittedDQagent.feed(ts)\n",
        "\n",
        "        # Evaluate the performance every 100 episodes\n",
        "        if episode % 100 == 0:\n",
        "            print(f'Episode {episode}')\n",
        "            logger.log_performance(\n",
        "                env.timestep,\n",
        "                tournament(\n",
        "                    eval_env,\n",
        "                    1000  \n",
        "                )[0]\n",
        "            )\n",
        "\n",
        "    # Get the paths for the learning curve\n",
        "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_curve(csv_path, fig_path, 'Double DQN with Fitted Q Iteration on Limit Texas Hold\\'em')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67ca5168",
      "metadata": {
        "id": "67ca5168"
      },
      "source": [
        "### 3.4.5 Conclusion\n",
        "\n",
        "Deep Fitted Q-Iteration for poker combines the depth and flexibility of neural network-based function approximation with the stability and efficiency of batch learning from FQI. This approach is well-suited to the strategic and probabilistic aspects of poker. The implementation performs well against the RandomAgent and reaches reward levels of up to 2.50. However, it is important to note that training is quite slow and more computationally expensive than for the methods we have encoutered before."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81d5dba9",
      "metadata": {
        "id": "81d5dba9"
      },
      "source": [
        "## 3.5 Policy-Based Learning in Poker <a class=\"anchor\" id=\"3.5\"></a>\n",
        "\n",
        " Policy-Based Learning focuses on directly optimizing the policy — a mapping from states to actions — which is more natural and often more effective for decision-making problems where the optimal strategy involves randomness and deception, such as in poker.\n",
        "\n",
        "### 3.5.1 Key Points of Policy-Based Learning:\n",
        "\n",
        "1. **Direct Policy Optimization**: Policy-based methods optimize the policy directly without requiring a separate step of value function estimation. This is particularly useful in poker, where directly learning the best action (like whether to fold, call, or raise) is more intuitive and can be more efficient than learning a value function first.\n",
        "\n",
        "2. **Handling Stochastic Policies**: Poker often requires mixed strategies for optimal play, where actions are chosen with specific probabilities. Policy-based methods can naturally learn these stochastic policies, potentially enabling the agent to bluff or change tactics in ways that are harder to exploit.\n",
        "\n",
        "3. **Applicability to Continuous and High-Dimensional Actions**: Policy-based learning can handle high-dimensional action spaces more gracefully than value-based methods.\n",
        "\n",
        "4. **Gradient Ascent Optimization**: Using gradient ascent to improve the policy allows these methods to efficiently navigate the high-dimensional policy space, which is important in poker where the decision space can be vast due to the combination of betting rounds and possible opponent strategies.\n",
        "\n",
        "5. **Robustness to Model Misspecification**: Poker is a game of incomplete information and dynamic changes. Policy-based methods, by focusing on the policy itself, tend to be more robust to changes in the environment and opponent behavior, adapting more fluidly than methods that require a fixed model of rewards.\n",
        "\n",
        "### 3.5.2 Introducing Advantage Actor-Critic (A2C) for Texas Hold'em\n",
        "\n",
        "Advantage Actor-Critic (A2C) is an enhanced policy-based method that introduces a more stable and efficient way to train the policy by using the advantage function. The advantage function $ A(s, a) = Q(s, a) - V(s) $ measures how much better taking action $ a $ is compared to the average value of the state $ s $. This approach helps focus the learning on the most promising actions, reducing variance and improving the convergence speed.\n",
        "\n",
        "### 3.5.3 A2C in Poker:\n",
        "\n",
        "In Texas Hold'em and other poker variants, A2C can help the agent develop strategies that balance the potential rewards of different actions more effectively than simpler methods:\n",
        "\n",
        "1. **Balanced Strategy Development**: By using the advantage function, A2C helps the agent learn when to take actions that are significantly better than the average, aiding in the development of balanced bluffing and betting strategies.\n",
        "\n",
        "2. **Efficient Use of Experience**: A2C uses experiences more efficiently by focusing updates on actions that have the most to teach the agent — those with the highest advantage. This is key in poker, where many situations recur with slight variations.\n",
        "\n",
        "3. **Faster Learning**: The separation of the policy (actor) and value estimates (critic) allows A2C to learn more effectively, with the critic providing a stable baseline that reduces the variance of updates to the actor.\n",
        "\n",
        "4. **Handling Sparse Rewards**: In poker, rewards (like winning a hand) are sparse and delayed until the end of a hand. A2C’s approach, which balances immediate feedback (rewards) with longer-term value estimates, helps attribute rewards to actions more accurately throughout a hand.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "coLEaMwzRV8l",
      "metadata": {
        "id": "coLEaMwzRV8l"
      },
      "source": [
        "### 3.5.4 Implementing Advantage Actor-Critic (A2C) with Fitted Q Iteration for Poker\n",
        "\n",
        "In our implementation of the Advantage Actor-Critic (A2C) framework, we introduce an adaptation by replacing the typical neural network-based critic with a suite of Gradient Boosting Regressors, forming the core of our Fitted Q Iteration method. This approach aims to leverage the strengths of ensemble methods for more precise Q-value approximations.\n",
        "\n",
        "#### Detailed Breakdown of the Implementation:\n",
        "\n",
        "1. **Data Collection:**\n",
        "   - **Process:** We accumulate transitions in the form $(s, a, r, s', \\text{done})$ within a deque-based memory buffer. This setup helps in managing experience replay, essential for learning from a richer history of past actions.\n",
        "   - **Utility:** By storing these transitions, we enable batch learning from diverse past experiences, reducing temporal correlations and enhancing the robustness of our learning updates.\n",
        "\n",
        "2. **Learning:**\n",
        "   - **Critic Training:**\n",
        "     - **Role and Structure:** Each action in the poker game has a corresponding Gradient Boosting Regressor in the critic. These models are independently updated using their respective experiences.\n",
        "     - **Mechanism:** For each action $a$, its regressor is trained on states where $a$ was taken, using targets formed by the Bellman equation:\n",
        "       $\n",
        "       y = r + \\gamma \\max_{a'} Q(s', a')\n",
        "       $\n",
        "       where $s'$ is the subsequent state and $\\max_{a'} Q(s', a')$ is derived from the critic's current predictions, providing a lookahead to enhance current decision-making.\n",
        "   - **Actor Training:**\n",
        "     - **Gradient Update:** The Actor network updates its policy parameters $\\theta$ by ascending the gradient of the expected reward, which is estimated using:\n",
        "       $\n",
        "       \\nabla_{\\theta} J(\\theta) = \\mathbb{E}[\\log \\pi(a|s) A(s, a)]\n",
        "       $\n",
        "       Here, $A(s, a) = Q(s, a) - V(s)$ is approximated as:\n",
        "       $\n",
        "       A(s, a) = r + \\gamma \\max_{a'} Q(s', a') (1 - \\text{done}) - Q(s, a)\n",
        "       $\n",
        "       with $Q(s, a)$ directly provided by the critic’s prediction for action $a$ at state $s$. This forms the advantage, guiding the policy toward more rewarding actions.\n",
        "   - **Synchronization:** The updates to both the Actor and the Critic are conducted in lockstep, with the Actor improving its policy based on the current state-value assessments from the Critic, ensuring a cohesive advancement toward optimal strategies.\n",
        "\n",
        "3. **Policy Execution:**\n",
        "   - **Exploration vs. Exploitation:** During training, actions are chosen based on a probabilistic policy derived from the Actor’s outputs, ensuring exploration through stochastic behavior. For evaluation, the policy becomes deterministic, selecting actions with the highest probability to assess performance without exploratory noise.\n",
        "   - **Execution Dynamics:** The agent's interaction with the poker environment during these phases helps in fine-tuning its strategy, balancing immediate rewards with long-term strategic planning.\n",
        "\n",
        "#### Note on Gradient Boosting Regressors for the Critic:\n",
        "\n",
        "By using Gradient Boosting Regressors, the critic may be able to more accurately handle the dependencies and variability in poker states and actions. This ensemble approach allows each model to focus on predicting outcomes for a specific action, potentially enhancing the overall precision in Q-value approximation. In summary, we try to blend policy gradient techniques with ensemble value function estimation.\n",
        "\n",
        "Again, our code implementation follows to strucutre of an RLcard agent, to allow for smooth interaction with the provided environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "CtOzFEHxBE9M",
      "metadata": {
        "id": "CtOzFEHxBE9M"
      },
      "outputs": [],
      "source": [
        "# Actor instance\n",
        "class Actor(nn.Module):\n",
        "    # Create the actor network based on pytorch\n",
        "    def __init__(self, state_size, action_size, hidden_size=128):\n",
        "        super(Actor, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
        "        self.dropout1 = nn.Dropout(p=0.2)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.dropout2 = nn.Dropout(p=0.2)\n",
        "        self.fc3 = nn.Linear(hidden_size, action_size)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return self.softmax(x)\n",
        "\n",
        "# Fitted-Q-Agent based on previous method\n",
        "class FittedQAgent:\n",
        "    def __init__(self, state_size, action_size, estimator_learning_rate=0.01, gamma=0.99):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.gamma = gamma\n",
        "        self.models = [GradientBoostingRegressor(learning_rate=estimator_learning_rate) for _ in range(action_size)]\n",
        "        self.is_fitted = [False] * action_size\n",
        "\n",
        "    def fit(self, states, actions, rewards, next_states, dones):\n",
        "        next_action_values = np.zeros((len(next_states), self.action_size))\n",
        "        for action in range(self.action_size):\n",
        "            if self.is_fitted[action]:\n",
        "                next_action_values[:, action] = self.models[action].predict(next_states)\n",
        "\n",
        "        targets = rewards + self.gamma * np.max(next_action_values, axis=1) * (1 - dones)\n",
        "\n",
        "        for action in range(self.action_size):\n",
        "            action_mask = (actions == action)\n",
        "            if np.any(action_mask):\n",
        "                self.models[action].fit(states[action_mask], targets[action_mask])\n",
        "                self.is_fitted[action] = True\n",
        "\n",
        "    def predict(self, states):\n",
        "        action_values = np.zeros((len(states), self.action_size))\n",
        "        for action in range(self.action_size):\n",
        "            if self.is_fitted[action]:\n",
        "                action_values[:, action] = self.models[action].predict(states)\n",
        "            else:\n",
        "                action_values[:, action] = 0\n",
        "        return action_values\n",
        "\n",
        "# Building the agent using the standard functions for an RLcard agent\n",
        "class A2CAgentWithFittedQ:\n",
        "    def __init__(self, num_actions, state_size, hidden_size=128, gamma=0.99, lr=1e-4, batch_size=64):\n",
        "        self.actor = Actor(state_size, num_actions, hidden_size)\n",
        "        self.critic = FittedQAgent(state_size, num_actions, estimator_learning_rate=0.01, gamma=gamma)\n",
        "        self.optimizer = optim.Adam(self.actor.parameters(), lr=lr)\n",
        "        self.gamma = gamma\n",
        "        self.batch_size = batch_size\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.num_actions = num_actions\n",
        "        self.use_raw = False\n",
        "\n",
        "    def feed(self, ts):\n",
        "        (state, action, reward, next_state, done) = ts\n",
        "\n",
        "        # Ensure only the numeric observation part is used, not the full dictionary\n",
        "        state_obs = state['obs']\n",
        "        next_state_obs = next_state['obs']\n",
        "\n",
        "        # Append transition to memory\n",
        "        self.memory.append((state_obs, action, reward, next_state_obs, done))\n",
        "\n",
        "        if len(self.memory) >= self.batch_size:\n",
        "            self.learn()\n",
        "\n",
        "\n",
        "    def learn(self):\n",
        "        # Check if we have enough samples to form a batch\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        # Randomly sample a batch of experiences from memory\n",
        "        experiences = random.sample(self.memory, self.batch_size)\n",
        "\n",
        "        # Unzip the experiences into separate lists\n",
        "        states, actions, rewards, next_states, dones = zip(*experiences)\n",
        "\n",
        "        # Convert these lists into numpy arrays\n",
        "        states = np.vstack(states)\n",
        "        actions = np.array(actions)\n",
        "        rewards = np.array(rewards)\n",
        "        next_states = np.vstack(next_states)\n",
        "        dones = np.array(dones)\n",
        "\n",
        "        # Fit the critic model\n",
        "        self.critic.fit(states, actions, rewards, next_states, dones)\n",
        "\n",
        "        # Update the actor model by policy gradient\n",
        "        states = torch.tensor(states, dtype=torch.float32)\n",
        "        actions = torch.tensor(actions, dtype=torch.long)\n",
        "        probs = self.actor(states)\n",
        "        dist = torch.distributions.Categorical(probs)\n",
        "        log_probs = dist.log_prob(actions)\n",
        "\n",
        "        # Use critic to calculate the value function Q\n",
        "        q_values = torch.tensor(self.critic.predict(states), dtype=torch.float32)\n",
        "        q_values = q_values.gather(1, actions.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        advantages = torch.tensor(rewards, dtype=torch.float32) + self.gamma * torch.tensor(np.max(self.critic.predict(next_states), axis=1), dtype=torch.float32) * (1 - torch.tensor(dones, dtype=torch.float32)) - q_values\n",
        "\n",
        "        actor_loss = -(log_probs * advantages.detach()).mean()\n",
        "        self.optimizer.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Clear the memory after learning\n",
        "        self.memory.clear()\n",
        "\n",
        "\n",
        "    def step(self, state):\n",
        "        state_tensor = torch.tensor(state['obs'], dtype=torch.float32)\n",
        "        probs = self.actor(state_tensor).detach().numpy()\n",
        "        action = np.random.choice(self.num_actions, p=probs)\n",
        "        return action\n",
        "\n",
        "    def eval_step(self, state):\n",
        "        state_tensor = torch.tensor(state['obs'], dtype=torch.float32)\n",
        "        probs = self.actor(state_tensor).detach().numpy()\n",
        "        action = np.argmax(probs)\n",
        "        return action, {}\n",
        "\n",
        "    def save(self, path):\n",
        "        torch.save(self.actor.state_dict(), path + '_actor.pth')\n",
        "        # Save the Fitted Q models\n",
        "        for idx, model in enumerate(self.critic.models):\n",
        "            model_path = path + f'_critic_model_{idx}.joblib'\n",
        "            joblib.dump(model, model_path)\n",
        "\n",
        "    def load(self, path):\n",
        "        self.actor.load_state_dict(torch.load(path + '_actor.pth'))\n",
        "        for idx, model in enumerate(self.critic.models):\n",
        "            model_path = path + f'_critic_model_{idx}.joblib'\n",
        "            self.critic.models[idx] = joblib.load(model_path)\n",
        "            self.critic.is_fitted[idx] = True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "t70kd4OkBNJY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t70kd4OkBNJY",
        "outputId": "691f566c-c74b-4a20-ca6d-dc4c7185d73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1\n",
            "  reward       |  -0.156\n",
            "----------------------------------------\n",
            "Episode 100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  220\n",
            "  reward       |  -0.053\n",
            "----------------------------------------\n",
            "Episode 200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  495\n",
            "  reward       |  0.101\n",
            "----------------------------------------\n",
            "Episode 300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  723\n",
            "  reward       |  0.2265\n",
            "----------------------------------------\n",
            "Episode 400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1030\n",
            "  reward       |  0.252\n",
            "----------------------------------------\n",
            "Episode 500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1262\n",
            "  reward       |  0.3285\n",
            "----------------------------------------\n",
            "Episode 600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1506\n",
            "  reward       |  0.1775\n",
            "----------------------------------------\n",
            "Episode 700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1760\n",
            "  reward       |  0.2795\n",
            "----------------------------------------\n",
            "Episode 800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2020\n",
            "  reward       |  0.358\n",
            "----------------------------------------\n",
            "Episode 900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2277\n",
            "  reward       |  0.4395\n",
            "----------------------------------------\n",
            "Episode 1000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2540\n",
            "  reward       |  0.543\n",
            "----------------------------------------\n",
            "Episode 1100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2773\n",
            "  reward       |  0.4095\n",
            "----------------------------------------\n",
            "Episode 1200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3064\n",
            "  reward       |  0.3795\n",
            "----------------------------------------\n",
            "Episode 1300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3303\n",
            "  reward       |  0.36\n",
            "----------------------------------------\n",
            "Episode 1400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3593\n",
            "  reward       |  0.7435\n",
            "----------------------------------------\n",
            "Episode 1500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3836\n",
            "  reward       |  0.683\n",
            "----------------------------------------\n",
            "Episode 1600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4084\n",
            "  reward       |  0.4775\n",
            "----------------------------------------\n",
            "Episode 1700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4352\n",
            "  reward       |  0.7925\n",
            "----------------------------------------\n",
            "Episode 1800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4645\n",
            "  reward       |  0.699\n",
            "----------------------------------------\n",
            "Episode 1900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4940\n",
            "  reward       |  0.7765\n",
            "----------------------------------------\n",
            "Episode 2000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5212\n",
            "  reward       |  0.684\n",
            "----------------------------------------\n",
            "Episode 2100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5484\n",
            "  reward       |  0.639\n",
            "----------------------------------------\n",
            "Episode 2200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5748\n",
            "  reward       |  0.696\n",
            "----------------------------------------\n",
            "Episode 2300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5990\n",
            "  reward       |  0.662\n",
            "----------------------------------------\n",
            "Episode 2400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6249\n",
            "  reward       |  0.9305\n",
            "----------------------------------------\n",
            "Episode 2500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6511\n",
            "  reward       |  0.854\n",
            "----------------------------------------\n",
            "Episode 2600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6741\n",
            "  reward       |  0.9115\n",
            "----------------------------------------\n",
            "Episode 2700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7025\n",
            "  reward       |  1.0805\n",
            "----------------------------------------\n",
            "Episode 2800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7257\n",
            "  reward       |  0.9375\n",
            "----------------------------------------\n",
            "Episode 2900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7509\n",
            "  reward       |  1.175\n",
            "----------------------------------------\n",
            "Episode 3000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7789\n",
            "  reward       |  0.8075\n",
            "----------------------------------------\n",
            "Episode 3100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8066\n",
            "  reward       |  1.0955\n",
            "----------------------------------------\n",
            "Episode 3200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8356\n",
            "  reward       |  1.1465\n",
            "----------------------------------------\n",
            "Episode 3300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8635\n",
            "  reward       |  0.975\n",
            "----------------------------------------\n",
            "Episode 3400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8887\n",
            "  reward       |  1.0125\n",
            "----------------------------------------\n",
            "Episode 3500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9142\n",
            "  reward       |  0.8925\n",
            "----------------------------------------\n",
            "Episode 3600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9383\n",
            "  reward       |  1.034\n",
            "----------------------------------------\n",
            "Episode 3700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9627\n",
            "  reward       |  1.211\n",
            "----------------------------------------\n",
            "Episode 3800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9873\n",
            "  reward       |  0.756\n",
            "----------------------------------------\n",
            "Episode 3900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10161\n",
            "  reward       |  1.072\n",
            "----------------------------------------\n",
            "Episode 4000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10388\n",
            "  reward       |  1.232\n",
            "----------------------------------------\n",
            "Episode 4100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10629\n",
            "  reward       |  0.97\n",
            "----------------------------------------\n",
            "Episode 4200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10844\n",
            "  reward       |  1.0545\n",
            "----------------------------------------\n",
            "Episode 4300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11126\n",
            "  reward       |  1.201\n",
            "----------------------------------------\n",
            "Episode 4400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11390\n",
            "  reward       |  1.337\n",
            "----------------------------------------\n",
            "Episode 4500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11661\n",
            "  reward       |  0.985\n",
            "----------------------------------------\n",
            "Episode 4600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11896\n",
            "  reward       |  0.8575\n",
            "----------------------------------------\n",
            "Episode 4700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12186\n",
            "  reward       |  1.267\n",
            "----------------------------------------\n",
            "Episode 4800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12432\n",
            "  reward       |  1.0975\n",
            "----------------------------------------\n",
            "Episode 4900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12695\n",
            "  reward       |  1.1545\n",
            "----------------------------------------\n",
            "Episode 5000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12983\n",
            "  reward       |  1.105\n",
            "----------------------------------------\n",
            "Episode 5100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13245\n",
            "  reward       |  1.2025\n",
            "----------------------------------------\n",
            "Episode 5200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13552\n",
            "  reward       |  1.2555\n",
            "----------------------------------------\n",
            "Episode 5300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13790\n",
            "  reward       |  1.135\n",
            "----------------------------------------\n",
            "Episode 5400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14077\n",
            "  reward       |  0.991\n",
            "----------------------------------------\n",
            "Episode 5500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14340\n",
            "  reward       |  1.1065\n",
            "----------------------------------------\n",
            "Episode 5600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14606\n",
            "  reward       |  0.992\n",
            "----------------------------------------\n",
            "Episode 5700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14854\n",
            "  reward       |  1.028\n",
            "----------------------------------------\n",
            "Episode 5800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15130\n",
            "  reward       |  1.0945\n",
            "----------------------------------------\n",
            "Episode 5900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15430\n",
            "  reward       |  0.834\n",
            "----------------------------------------\n",
            "Episode 6000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15714\n",
            "  reward       |  1.0845\n",
            "----------------------------------------\n",
            "Episode 6100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15984\n",
            "  reward       |  1.2895\n",
            "----------------------------------------\n",
            "Episode 6200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  16253\n",
            "  reward       |  1.0455\n",
            "----------------------------------------\n",
            "Episode 6300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  16541\n",
            "  reward       |  0.9615\n",
            "----------------------------------------\n",
            "Episode 6400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  16802\n",
            "  reward       |  1.016\n",
            "----------------------------------------\n",
            "Episode 6500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  17036\n",
            "  reward       |  1.0205\n",
            "----------------------------------------\n",
            "Episode 6600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  17330\n",
            "  reward       |  1.162\n",
            "----------------------------------------\n",
            "Episode 6700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  17583\n",
            "  reward       |  1.091\n",
            "----------------------------------------\n",
            "Episode 6800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  17861\n",
            "  reward       |  1.2805\n",
            "----------------------------------------\n",
            "Episode 6900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  18131\n",
            "  reward       |  1.3825\n",
            "----------------------------------------\n",
            "Episode 7000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  18428\n",
            "  reward       |  1.1805\n",
            "----------------------------------------\n",
            "Episode 7100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  18696\n",
            "  reward       |  1.3445\n",
            "----------------------------------------\n",
            "Episode 7200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  18980\n",
            "  reward       |  1.0315\n",
            "----------------------------------------\n",
            "Episode 7300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  19248\n",
            "  reward       |  0.7235\n",
            "----------------------------------------\n",
            "Episode 7400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  19493\n",
            "  reward       |  0.9355\n",
            "----------------------------------------\n",
            "Episode 7500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  19779\n",
            "  reward       |  1.142\n",
            "----------------------------------------\n",
            "Episode 7600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  20072\n",
            "  reward       |  0.8235\n",
            "----------------------------------------\n",
            "Episode 7700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  20313\n",
            "  reward       |  1.2745\n",
            "----------------------------------------\n",
            "Episode 7800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  20558\n",
            "  reward       |  1.246\n",
            "----------------------------------------\n",
            "Episode 7900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  20851\n",
            "  reward       |  1.403\n",
            "----------------------------------------\n",
            "Episode 8000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  21081\n",
            "  reward       |  1.0885\n",
            "----------------------------------------\n",
            "Episode 8100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  21369\n",
            "  reward       |  1.0825\n",
            "----------------------------------------\n",
            "Episode 8200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  21601\n",
            "  reward       |  1.329\n",
            "----------------------------------------\n",
            "Episode 8300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  21885\n",
            "  reward       |  0.945\n",
            "----------------------------------------\n",
            "Episode 8400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  22166\n",
            "  reward       |  1.088\n",
            "----------------------------------------\n",
            "Episode 8500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  22413\n",
            "  reward       |  1.072\n",
            "----------------------------------------\n",
            "Episode 8600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  22709\n",
            "  reward       |  1.0535\n",
            "----------------------------------------\n",
            "Episode 8700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  23009\n",
            "  reward       |  0.866\n",
            "----------------------------------------\n",
            "Episode 8800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  23275\n",
            "  reward       |  1.2505\n",
            "----------------------------------------\n",
            "Episode 8900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  23560\n",
            "  reward       |  1.1085\n",
            "----------------------------------------\n",
            "Episode 9000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  23866\n",
            "  reward       |  1.0055\n",
            "----------------------------------------\n",
            "Episode 9100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  24110\n",
            "  reward       |  1.046\n",
            "----------------------------------------\n",
            "Episode 9200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  24369\n",
            "  reward       |  1.134\n",
            "----------------------------------------\n",
            "Episode 9300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  24623\n",
            "  reward       |  1.077\n",
            "----------------------------------------\n",
            "Episode 9400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  24898\n",
            "  reward       |  1.191\n",
            "----------------------------------------\n",
            "Episode 9500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  25184\n",
            "  reward       |  1.2925\n",
            "----------------------------------------\n",
            "Episode 9600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  25432\n",
            "  reward       |  1.254\n",
            "----------------------------------------\n",
            "Episode 9700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  25715\n",
            "  reward       |  1.085\n",
            "----------------------------------------\n",
            "Episode 9800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  26005\n",
            "  reward       |  1.3195\n",
            "----------------------------------------\n",
            "Episode 9900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  26293\n",
            "  reward       |  1.136\n",
            "----------------------------------------\n",
            "\n",
            "Logs saved in experiments/limit_holdem_a2c_with_fittedq_result/\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environments\n",
        "env = rlcard.make('limit-holdem')\n",
        "eval_env = rlcard.make('limit-holdem')\n",
        "\n",
        "# Use the agent created above\n",
        "A2Cagent = A2CAgentWithFittedQ(num_actions=env.num_actions, state_size=env.state_shape[0][0], hidden_size=128, gamma=0.99, lr=0.0001, batch_size=64)\n",
        "env.set_agents([A2Cagent, RandomAgent(num_actions=env.num_actions)])\n",
        "eval_env.set_agents([A2Cagent, RandomAgent(num_actions=env.num_actions)])\n",
        "\n",
        "\n",
        "# Initialize the Logger\n",
        "with Logger(\"experiments/limit_holdem_a2c_with_fittedq_result/\") as logger:\n",
        "    for episode in range(10000):\n",
        "        # Generate data from the environment\n",
        "        trajectories, payoffs = env.run(is_training=True)\n",
        "\n",
        "        # Reorganize the data to be state, action, reward, next_state, done\n",
        "        trajectories = reorganize(trajectories, payoffs)\n",
        "\n",
        "        # Feed transitions into agent memory, and train the agent\n",
        "        for ts in trajectories[0]:  # Only use trajectories of the learning agent\n",
        "            A2Cagent.feed(ts)\n",
        "\n",
        "        # Evaluate the performance every 100 episodes\n",
        "        if episode % 100 == 0:\n",
        "            print(f'Episode {episode}')\n",
        "            logger.log_performance(\n",
        "                env.timestep,\n",
        "                tournament(\n",
        "                    eval_env,\n",
        "                    1000  \n",
        "                )[0]\n",
        "            )\n",
        "\n",
        "    # Get the paths for the learning curve\n",
        "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_curve(csv_path, fig_path, 'A2C with Fitted Q Iteration on Limit Texas Hold\\'em')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RMFyoXyPLNgi",
      "metadata": {
        "id": "RMFyoXyPLNgi"
      },
      "source": [
        "### 3.5.4 Conclusion\n",
        "\n",
        "While the A2C agent does exhibit some learning behaviour, it performs worse than some of the methods we have seen perviously. Selecting a range of different paramter setups did not aid the results. There are a few potential reasons why an A2C agent might perform worse on Limit Hold'em compared to e.g. the DQN agent. A2C, which combines policy gradients with value function estimation, may struggle with the high variance in reward signals inherent in poker, leading to unstable updates. Nonetheless, the A2C agent clearly outperforms the random agent, reaching reward levels of up to 1.4."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kb5s5-165a-k",
      "metadata": {
        "id": "kb5s5-165a-k"
      },
      "source": [
        "## 3.6 Neural Fictitious Self-Play <a class=\"anchor\" id=\"3.6\"></a>\n",
        "Heinrich, J., & Silver, D. (2016). Deep Reinforcement Learning from Self-Play in Imperfect-Information Games. arXiv preprint arXiv:1603.01121."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OD-wN43y5bSk",
      "metadata": {
        "id": "OD-wN43y5bSk"
      },
      "source": [
        "The Neural Fictitious Self-Play (NFSP) agent represents a hybrid approach within the reinforcement learning framework, combining both policy-based and value-based methods in a model-free setting. Developed by Heinrich and Silver (2016), NFSP aims to approximate Nash equilibria in imperfect-information games without relying on prior domain knowledge. The agent employs two neural networks: one trained via supervised learning to approximate the agent's average strategy (policy-based) and another trained via off-policy Q-learning to predict action values (value-based). By learning directly from self-play experiences, NFSP effectively integrates these components, making it a robust solution for complex, real-world scenarios such as poker, where strategic decision-making is crucial.\n",
        "\n",
        "\n",
        "### 3.6.1 Explanation of Key Points of NFSP:\n",
        "\n",
        "Neural Fictitious Self-Play (NFSP) uniquely combines elements of fictitious self-play with deep learning techniques to achieve scalable, domain-independent learning. The following outlines the algorithm:\n",
        "\n",
        "1. **Dual Neural Networks:**\n",
        "   NFSP employs two neural networks: an action-value network $ Q(s, a | \\theta^Q) $ and an average-policy network $ \\Pi(s, a | \\theta^\\Pi) $.\n",
        "\n",
        "   - **Action-Value Network (Q-Network):**\n",
        "     This network is trained using reinforcement learning to predict the expected return of taking action $ a $ in state $ s $. It approximates the Q-function:\n",
        "     $\n",
        "     Q(s, a) = \\mathbb{E}_{\\pi} [G_t | S_t = s, A_t = a]\n",
        "     $\n",
        "     where $ G_t $ is the cumulative future reward.\n",
        "\n",
        "   - **Average-Policy Network (Policy Network):**\n",
        "     This network is trained using supervised learning to predict the agent's average strategy based on historical behavior:\n",
        "     $\n",
        "     \\Pi(s, a) \\approx \\pi(s, a)\n",
        "     $\n",
        "     where $ \\pi(s, a) $ is the probability of taking action $ a $ in state $ s $ according to the agent’s average strategy.\n",
        "\n",
        "2. **Reinforcement Learning Memory (MRL):**\n",
        "   The agent stores its experiences of state transitions, actions, and rewards in a memory buffer $ M_{RL} $. These experiences are used to train the Q-network using Q-learning:\n",
        "   $\n",
        "   L(\\theta^Q) = \\mathbb{E}_{(s, a, r, s') \\sim M_{RL}} \\left[ (r + \\gamma \\max_{a'} Q(s', a' | \\theta^{Q'}) - Q(s, a | \\theta^Q))^2 \\right]\n",
        "   $\n",
        "   where $ \\gamma $ is the discount factor and $ \\theta^{Q'} $ are the parameters of a target network periodically updated to stabilize training.\n",
        "\n",
        "3. **Supervised Learning Memory (MSL):**\n",
        "   The agent also stores its own actions and states in another memory buffer $ M_{SL} $. This data is used to train the policy network using supervised learning:\n",
        "   $\n",
        "   L(\\theta^\\Pi) = \\mathbb{E}_{(s, a) \\sim M_{SL}} \\left[ -\\log \\Pi(a | s, \\theta^\\Pi) \\right]\n",
        "   $\n",
        "\n",
        "4. **Anticipatory Dynamics:**\n",
        "   To ensure that the agent can learn an effective strategy while adapting to opponents, NFSP uses anticipatory dynamics with an anticipatory parameter $ \\eta $. The agent’s behavior policy is a mixture of its average policy and its best response:\n",
        "   $\n",
        "   \\sigma(s) = \\begin{cases}\n",
        "   \\epsilon\\text{-greedy}(Q) & \\text{with probability } \\eta \\\\\n",
        "   \\Pi(s) & \\text{with probability } 1 - \\eta\n",
        "   \\end{cases}\n",
        "   $\n",
        "   where $ \\epsilon $-greedy(Q) is a policy that selects a random action with probability $ \\epsilon $ and the action with the highest Q-value otherwise.\n",
        "\n",
        "5. **Reservoir Sampling:**\n",
        "   NFSP uses reservoir sampling to maintain a representative sample of historical data in $ M_{SL} $. This technique ensures that the supervised learning memory contains a diverse set of experiences, which helps in stabilizing the training process.\n",
        "\n",
        "6. **Training Process:**\n",
        "   During training, the agent alternates between using the Q-network to learn an approximate best response and using the policy network to update its average strategy. The training process can be summarized as follows:\n",
        "   - Generate self-play experiences and store them in $ M_{RL} $ and $ M_{SL} $.\n",
        "   - Update the Q-network parameters $ \\theta^Q $ by minimizing the Q-learning loss.\n",
        "   - Update the policy network parameters $ \\theta^\\Pi $ by minimizing the supervised learning loss.\n",
        "   - Periodically evaluate and update the target network parameters $ \\theta^{Q'} $.\n",
        "\n",
        "#### Mathematical Formulation:\n",
        "\n",
        "The loss functions for the two neural networks are given by:\n",
        "1. **Q-Network Loss (Reinforcement Learning):**\n",
        "   $\n",
        "   L(\\theta^Q) = \\mathbb{E}_{(s, a, r, s') \\sim M_{RL}} \\left[ (r + \\gamma \\max_{a'} Q(s', a' | \\theta^{Q'}) - Q(s, a | \\theta^Q))^2 \\right]\n",
        "   $\n",
        "\n",
        "2. **Policy Network Loss (Supervised Learning):**\n",
        "   $\n",
        "   L(\\theta^\\Pi) = \\mathbb{E}_{(s, a) \\sim M_{SL}} \\left[ -\\log \\Pi(a | s, \\theta^\\Pi) \\right]\n",
        "   $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mdlwv1ARbUZ7",
      "metadata": {
        "id": "Mdlwv1ARbUZ7"
      },
      "source": [
        "### 3.6.2 Code Implementation\n",
        "\n",
        "RLcard offers a NSFP agent through the API. Hence, we created the environment and initialized the NFSP agent with optimal parameters from the paper. The agent's neural networks were configured with four hidden layers of 1024, 512, 1024, and 512 neurons using ReLU activations. We set the reinforcement learning memory size to 600,000 and the supervised learning memory to 30 million, using exponentially-averaged reservoir sampling. The Q-network and policy network learning rates were set to 0.1 and 0.01 respectively, with mini-batch sizes of 256. The exploration rate (epsilon) started at 0.08, decaying to 0, and the anticipatory parameter was set to 0.1. During training, the agent performed two gradient updates every 256 steps, periodically evaluated against a stronger opponent to monitor performance. This setup ensured the agent's training followed the best practices identified in the NFSP paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "sU1_yEmeSLLZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sU1_yEmeSLLZ",
        "outputId": "99c4200a-b4f6-4a72-81be-de2fccfaf8cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------\n",
            "  episode      |  1\n",
            "  reward       |  0.1995\n",
            "----------------------------------------\n",
            "Episode 0, Reward: 0.1995\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  306\n",
            "  reward       |  0.0455\n",
            "----------------------------------------\n",
            "Episode 100, Reward: 0.0455\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  663\n",
            "  reward       |  0.0135\n",
            "----------------------------------------\n",
            "Episode 200, Reward: 0.0135\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  977\n",
            "  reward       |  0.1035\n",
            "----------------------------------------\n",
            "Episode 300, Reward: 0.1035\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1265\n",
            "  reward       |  0.205\n",
            "----------------------------------------\n",
            "Episode 400, Reward: 0.205\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1559\n",
            "  reward       |  -0.023\n",
            "----------------------------------------\n",
            "Episode 500, Reward: -0.023\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1885\n",
            "  reward       |  0.074\n",
            "----------------------------------------\n",
            "Episode 600, Reward: 0.074\n",
            "INFO - Step 1000, rl-loss: 3.5502524375915527\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 1099, rl-loss: 71.63680267333984\n",
            "----------------------------------------\n",
            "  episode      |  2198\n",
            "  reward       |  0.0615\n",
            "----------------------------------------\n",
            "Episode 700, Reward: 0.0615\n",
            "INFO - Step 1248, rl-loss: 241.18186950683594\n",
            "----------------------------------------\n",
            "  episode      |  2504\n",
            "  reward       |  0.0895\n",
            "----------------------------------------\n",
            "Episode 800, Reward: 0.0895\n",
            "INFO - Step 1388, rl-loss: 145.06854248046875\n",
            "----------------------------------------\n",
            "  episode      |  2777\n",
            "  reward       |  0.0125\n",
            "----------------------------------------\n",
            "Episode 900, Reward: 0.0125\n",
            "INFO - Step 1537, rl-loss: 338.3768005371094\n",
            "----------------------------------------\n",
            "  episode      |  3082\n",
            "  reward       |  0.02\n",
            "----------------------------------------\n",
            "Episode 1000, Reward: 0.02\n",
            "INFO - Step 1698, rl-loss: 155.30210876464844\n",
            "----------------------------------------\n",
            "  episode      |  3410\n",
            "  reward       |  0.0245\n",
            "----------------------------------------\n",
            "Episode 1100, Reward: 0.0245\n",
            "INFO - Step 1869, rl-loss: 100.26498413085938\n",
            "----------------------------------------\n",
            "  episode      |  3755\n",
            "  reward       |  0.0395\n",
            "----------------------------------------\n",
            "Episode 1200, Reward: 0.0395\n",
            "INFO - Step 2000, rl-loss: 362.8182067871094\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 2017, rl-loss: 388.12420654296875\n",
            "----------------------------------------\n",
            "  episode      |  4056\n",
            "  reward       |  0.014\n",
            "----------------------------------------\n",
            "Episode 1300, Reward: 0.014\n",
            "INFO - Step 2141, rl-loss: 926.6622314453125\n",
            "----------------------------------------\n",
            "  episode      |  4307\n",
            "  reward       |  -0.0515\n",
            "----------------------------------------\n",
            "Episode 1400, Reward: -0.0515\n",
            "INFO - Step 2292, rl-loss: 100.5313949584961\n",
            "----------------------------------------\n",
            "  episode      |  4626\n",
            "  reward       |  0.0885\n",
            "----------------------------------------\n",
            "Episode 1500, Reward: 0.0885\n",
            "INFO - Step 2420, rl-loss: 1020.9063720703125\n",
            "----------------------------------------\n",
            "  episode      |  4895\n",
            "  reward       |  0.039\n",
            "----------------------------------------\n",
            "Episode 1600, Reward: 0.039\n",
            "INFO - Step 2573, rl-loss: 554.1060180664062\n",
            "----------------------------------------\n",
            "  episode      |  5205\n",
            "  reward       |  0.1725\n",
            "----------------------------------------\n",
            "Episode 1700, Reward: 0.1725\n",
            "INFO - Step 2738, rl-loss: 106.12440490722656\n",
            "----------------------------------------\n",
            "  episode      |  5539\n",
            "  reward       |  -0.001\n",
            "----------------------------------------\n",
            "Episode 1800, Reward: -0.001\n",
            "INFO - Step 2904, rl-loss: 51.599891662597656\n",
            "----------------------------------------\n",
            "  episode      |  5863\n",
            "  reward       |  0.1\n",
            "----------------------------------------\n",
            "Episode 1900, Reward: 0.1\n",
            "INFO - Step 3000, rl-loss: 691.7843017578125\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 3076, rl-loss: 8.746009826660156\n",
            "----------------------------------------\n",
            "  episode      |  6200\n",
            "  reward       |  0.121\n",
            "----------------------------------------\n",
            "Episode 2000, Reward: 0.121\n",
            "INFO - Step 3224, rl-loss: 28.334640502929688\n",
            "----------------------------------------\n",
            "  episode      |  6492\n",
            "  reward       |  0.062\n",
            "----------------------------------------\n",
            "Episode 2100, Reward: 0.062\n",
            "INFO - Step 3388, rl-loss: 8.3162841796875\n",
            "----------------------------------------\n",
            "  episode      |  6813\n",
            "  reward       |  0.102\n",
            "----------------------------------------\n",
            "Episode 2200, Reward: 0.102\n",
            "INFO - Step 3533, rl-loss: 52.25996398925781\n",
            "----------------------------------------\n",
            "  episode      |  7115\n",
            "  reward       |  0.044\n",
            "----------------------------------------\n",
            "Episode 2300, Reward: 0.044\n",
            "INFO - Step 3692, rl-loss: 45.85809326171875\n",
            "----------------------------------------\n",
            "  episode      |  7433\n",
            "  reward       |  0.1265\n",
            "----------------------------------------\n",
            "Episode 2400, Reward: 0.1265\n",
            "INFO - Step 3863, rl-loss: 147.0717010498047\n",
            "----------------------------------------\n",
            "  episode      |  7779\n",
            "  reward       |  0.2465\n",
            "----------------------------------------\n",
            "Episode 2500, Reward: 0.2465\n",
            "INFO - Step 4000, rl-loss: 40.44963073730469\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 4019, rl-loss: 11.29604434967041\n",
            "----------------------------------------\n",
            "  episode      |  8096\n",
            "  reward       |  0.0605\n",
            "----------------------------------------\n",
            "Episode 2600, Reward: 0.0605\n",
            "INFO - Step 4174, rl-loss: 11.813675880432129\n",
            "----------------------------------------\n",
            "  episode      |  8405\n",
            "  reward       |  0.044\n",
            "----------------------------------------\n",
            "Episode 2700, Reward: 0.044\n",
            "INFO - Step 4320, rl-loss: 8.870588302612305\n",
            "----------------------------------------\n",
            "  episode      |  8707\n",
            "  reward       |  0.115\n",
            "----------------------------------------\n",
            "Episode 2800, Reward: 0.115\n",
            "INFO - Step 4472, rl-loss: 9.969011306762695\n",
            "----------------------------------------\n",
            "  episode      |  9025\n",
            "  reward       |  0.043\n",
            "----------------------------------------\n",
            "Episode 2900, Reward: 0.043\n",
            "INFO - Step 4623, rl-loss: 7.671510219573975\n",
            "----------------------------------------\n",
            "  episode      |  9331\n",
            "  reward       |  -0.0185\n",
            "----------------------------------------\n",
            "Episode 3000, Reward: -0.0185\n",
            "INFO - Step 4760, rl-loss: 4.542877674102783\n",
            "----------------------------------------\n",
            "  episode      |  9616\n",
            "  reward       |  0.047\n",
            "----------------------------------------\n",
            "Episode 3100, Reward: 0.047\n",
            "INFO - Step 4902, rl-loss: 11.111870765686035\n",
            "----------------------------------------\n",
            "  episode      |  9901\n",
            "  reward       |  0.0665\n",
            "----------------------------------------\n",
            "Episode 3200, Reward: 0.0665\n",
            "INFO - Step 5000, rl-loss: 8.379980087280273\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 5057, rl-loss: 6.431397914886475\n",
            "----------------------------------------\n",
            "  episode      |  10209\n",
            "  reward       |  0.075\n",
            "----------------------------------------\n",
            "Episode 3300, Reward: 0.075\n",
            "INFO - Step 5209, rl-loss: 4.297928810119629\n",
            "----------------------------------------\n",
            "  episode      |  10507\n",
            "  reward       |  0.097\n",
            "----------------------------------------\n",
            "Episode 3400, Reward: 0.097\n",
            "INFO - Step 5360, rl-loss: 7.208958625793457\n",
            "----------------------------------------\n",
            "  episode      |  10820\n",
            "  reward       |  0.12\n",
            "----------------------------------------\n",
            "Episode 3500, Reward: 0.12\n",
            "INFO - Step 5499, rl-loss: 4.697381496429443\n",
            "----------------------------------------\n",
            "  episode      |  11103\n",
            "  reward       |  0.19\n",
            "----------------------------------------\n",
            "Episode 3600, Reward: 0.19\n",
            "INFO - Step 5662, rl-loss: 12.650815963745117\n",
            "----------------------------------------\n",
            "  episode      |  11424\n",
            "  reward       |  0.0265\n",
            "----------------------------------------\n",
            "Episode 3700, Reward: 0.0265\n",
            "INFO - Step 5826, rl-loss: 3.962441921234131\n",
            "----------------------------------------\n",
            "  episode      |  11755\n",
            "  reward       |  0.065\n",
            "----------------------------------------\n",
            "Episode 3800, Reward: 0.065\n",
            "INFO - Step 5980, rl-loss: 7.194438934326172\n",
            "----------------------------------------\n",
            "  episode      |  12065\n",
            "  reward       |  0.05\n",
            "----------------------------------------\n",
            "Episode 3900, Reward: 0.05\n",
            "INFO - Step 6000, rl-loss: 5.890892028808594\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 6141, rl-loss: 3.832357406616211\n",
            "----------------------------------------\n",
            "  episode      |  12374\n",
            "  reward       |  -0.057\n",
            "----------------------------------------\n",
            "Episode 4000, Reward: -0.057\n",
            "INFO - Step 6291, rl-loss: 3.171738624572754\n",
            "----------------------------------------\n",
            "  episode      |  12676\n",
            "  reward       |  0.0495\n",
            "----------------------------------------\n",
            "Episode 4100, Reward: 0.0495\n",
            "INFO - Step 6450, rl-loss: 11.972241401672363\n",
            "----------------------------------------\n",
            "  episode      |  12986\n",
            "  reward       |  0.0385\n",
            "----------------------------------------\n",
            "Episode 4200, Reward: 0.0385\n",
            "INFO - Step 6625, rl-loss: 18.847036361694336\n",
            "----------------------------------------\n",
            "  episode      |  13339\n",
            "  reward       |  0.11\n",
            "----------------------------------------\n",
            "Episode 4300, Reward: 0.11\n",
            "INFO - Step 6760, rl-loss: 3.090121030807495\n",
            "----------------------------------------\n",
            "  episode      |  13624\n",
            "  reward       |  0.0065\n",
            "----------------------------------------\n",
            "Episode 4400, Reward: 0.0065\n",
            "INFO - Step 6885, rl-loss: 6.0680742263793945\n",
            "----------------------------------------\n",
            "  episode      |  13875\n",
            "  reward       |  -0.0665\n",
            "----------------------------------------\n",
            "Episode 4500, Reward: -0.0665\n",
            "INFO - Step 7000, rl-loss: 11.82131576538086\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 7036, rl-loss: 26.12302589416504\n",
            "----------------------------------------\n",
            "  episode      |  14180\n",
            "  reward       |  0.109\n",
            "----------------------------------------\n",
            "Episode 4600, Reward: 0.109\n",
            "INFO - Step 7214, rl-loss: 3.799595832824707\n",
            "----------------------------------------\n",
            "  episode      |  14542\n",
            "  reward       |  0.059\n",
            "----------------------------------------\n",
            "Episode 4700, Reward: 0.059\n",
            "INFO - Step 7370, rl-loss: 10.634475708007812\n",
            "----------------------------------------\n",
            "  episode      |  14849\n",
            "  reward       |  0.032\n",
            "----------------------------------------\n",
            "Episode 4800, Reward: 0.032\n",
            "INFO - Step 7488, rl-loss: 7.559328079223633\n",
            "----------------------------------------\n",
            "  episode      |  15086\n",
            "  reward       |  0.0335\n",
            "----------------------------------------\n",
            "Episode 4900, Reward: 0.0335\n",
            "INFO - Step 7642, rl-loss: 5.8248491287231445\n",
            "Logs saved in experiments/limit_holdem_nfsp_result/\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make the environment with Limit Texas Hold'em\n",
        "env = rlcard.make('limit-holdem')\n",
        "eval_env = rlcard.make('limit-holdem')\n",
        "\n",
        "# Initialize the NFSP Agent with optimal parameters from the paper\n",
        "NFSPagent = NFSPAgent(\n",
        "    num_actions=env.num_actions,\n",
        "    state_shape=env.state_shape[0],\n",
        "    hidden_layers_sizes=[1024, 512, 1024, 512],  # Sizes of the hidden layers for the MLP in the average network\n",
        "    reservoir_buffer_capacity=30000000,  # Capacity of the reservoir buffer\n",
        "    anticipatory_param=0.1,  # Anticipatory parameter\n",
        "    batch_size=256,  # Batch size for supervised learning\n",
        "    train_every=1,  # Train the network every X steps\n",
        "    rl_learning_rate=0.1,  # Learning rate for the RL component\n",
        "    sl_learning_rate=0.01,  # Learning rate for the SL component\n",
        "    min_buffer_size_to_learn=1000,  # Minimum replay buffer size before learning starts\n",
        "    q_replay_memory_size=600000,  # Size of the replay memory\n",
        "    q_replay_memory_init_size=1000,  # Initial size of replay memory\n",
        "    q_update_target_estimator_every=1000,  # Update the target estimator every X steps\n",
        "    q_discount_factor=0.99,  # Discount factor (gamma)\n",
        "    q_epsilon_start=0.08,  # Starting epsilon for exploration\n",
        "    q_epsilon_end=0,  # Final epsilon for exploration\n",
        "    q_epsilon_decay_steps=10000,  # Number of steps to decay epsilon\n",
        "    q_batch_size=256,  # Batch size for Q-learning\n",
        "    q_train_every=1,  # Train Q every X steps\n",
        "    q_mlp_layers=[1024, 512, 1024, 512],  # Sizes of the hidden layers for the MLP in the Q network\n",
        "    evaluate_with='average_policy'  # Evaluate with average policy\n",
        ")\n",
        "\n",
        "# Initialize a stronger DQN Agent for training\n",
        "#dqn_agent = DQNAgent(\n",
        "#    num_actions=env.num_actions,\n",
        "#    state_shape=env.state_shape[0],\n",
        "#    mlp_layers=[512, 512],\n",
        "#    replay_memory_size=50000,\n",
        "#    replay_memory_init_size=1000,\n",
        "#    update_target_estimator_every=1000,\n",
        "#    discount_factor=0.99,\n",
        "#    epsilon_start=1.0,\n",
        "#    epsilon_end=0.1,\n",
        "#    epsilon_decay_steps=20000,\n",
        "#    batch_size=32,\n",
        "#    learning_rate=0.0001\n",
        "#)\n",
        "\n",
        "# Set the agents in the environment (RandomAgent)\n",
        "env.set_agents([NFSPagent, RandomAgent(num_actions=env.num_actions)])\n",
        "eval_env.set_agents([NFSPagent, RandomAgent(num_actions=env.num_actions)])\n",
        "\n",
        "\n",
        "# Initialize the Logger\n",
        "with Logger(\"experiments/limit_holdem_nfsp_result/\") as logger:\n",
        "    for episode in range(5000):  # Increase the number of episodes\n",
        "        # Generate data from the environment\n",
        "        trajectories, payoffs = env.run(is_training=True)\n",
        "\n",
        "        # Reorganize the data to be state, action, reward, next_state, done\n",
        "        trajectories = reorganize(trajectories, payoffs)\n",
        "\n",
        "        # Feed transitions into agent memory, and train the agent\n",
        "        for ts in trajectories[0]:  # Only use trajectories of the learning agent\n",
        "            NFSPagent.feed(ts)\n",
        "\n",
        "        # Evaluate the performance every 100 episodes\n",
        "        if episode % 100 == 0:\n",
        "            reward = tournament(\n",
        "                eval_env,\n",
        "                1000  # Number of games to play when evaluating\n",
        "            )[0]\n",
        "            logger.log_performance(env.timestep, reward)\n",
        "            print(f'Episode {episode}, Reward: {reward}')\n",
        "\n",
        "    # Get the paths for the learning curve\n",
        "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_curve(csv_path, fig_path, 'NFSP on Limit Texas Hold\\'em')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bnP6GIbAWxrc",
      "metadata": {
        "id": "bnP6GIbAWxrc"
      },
      "source": [
        "### 3.6.3 Parameter Grid Search\n",
        "\n",
        "Despite using the optimal setup from the paper, our NFSP agent implemented through the RLCard API performs poorly against both a random agent and a more advanced DQN agent. This suggests that we are unable to reproduce the paper's setup with the given information and API. To address this, we conduct a grid search to explore whether finding parameters suitable for our specific setting might enhance performance. Due to computational limitations, each parameter combination is only used for a limited number of episodes. The optimal set-up is then chosen based on the highest average rewards and applied to the agent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Z20_kZU2WwVU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z20_kZU2WwVU",
        "outputId": "d9678b72-1d41-4ba8-d4e3-e787ab5fb522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.06520000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0484\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.039599999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.08719999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.2668\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.16840000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.026400000000000007\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1292\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.04959999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1084\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0408\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.018799999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.14120000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.18400000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0944\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.30200000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.03359999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.045599999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.04039999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.10559999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0316\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1936\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1764\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.19840000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.132\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.028800000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.10399999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0444\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1984\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.18280000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.022399999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0188\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.009600000000000008\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.04\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1464\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.04120000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.05959999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.07519999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1176\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.09639999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0404\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.09960000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0628\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.033600000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.2284\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.14240000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.018399999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1244\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.09480000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.08120000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0047999999999999935\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.055600000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.2176\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.006800000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0452\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.17600000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.003999999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.08839999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0984\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0596\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.15000000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.144\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.19079999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.18239999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1716\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.021999999999999992\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1188\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.09400000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0208\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.22880000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.138\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1916\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.17720000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.010400000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0504\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0916\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0864\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.07640000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.016399999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0444\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.004000000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.022399999999999993\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.068\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0012000000000000034\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1296\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.134\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0512\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0272\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.008000000000000014\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.005200000000000015\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.048400000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0392\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.024800000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.03519999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.38280000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.005199999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.07840000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1024\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.02\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.08120000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.09400000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.048799999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0676\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.039199999999999985\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.03559999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0032000000000000028\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.06840000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0012000000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0956\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.17759999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.052800000000000014\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.2152\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.016799999999999992\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0027999999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.055999999999999994\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.045999999999999985\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.08439999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1648\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.014000000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1048\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0068000000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.07279999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1168\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0816\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.20759999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.2852\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.01960000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0956\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.005600000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.016799999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0132\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0027999999999999982\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0304\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.04519999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.184\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0756\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.014400000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.056400000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.11920000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1504\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.2224\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.09759999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.062\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1072\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0472\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.11560000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.06280000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.016\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1508\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.04479999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.05399999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.29359999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.019199999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.10679999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0608\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0376\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0924\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.096\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1844\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.094\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.044399999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.017199999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0768\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0724\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.19640000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.096\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1612\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.04680000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.032\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0692\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.022799999999999994\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0632\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.015600000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.114\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1468\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.31120000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1128\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.054000000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0636\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.022000000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.06\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.23120000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.032\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.04840000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0404\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.15\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0576\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.014400000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.15039999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.3036\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0308\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.029999999999999992\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.039599999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.047599999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.025199999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.007599999999999993\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.264\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.021199999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.048\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.08520000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.05039999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1444\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.001199999999999992\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.07640000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.013599999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1844\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.132\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1144\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0644\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.017199999999999993\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.03559999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0072000000000000015\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1408\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.06720000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.05919999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.12880000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0464\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.07639999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0412\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.07720000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.07279999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0204\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.10880000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0416\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.06880000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0664\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1428\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1192\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.23240000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.12\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0912\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.18760000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.156\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.06080000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.028000000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0672\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.07480000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.16599999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.126\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1632\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.07200000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1024\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.012400000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.06799999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0024000000000000046\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.05199999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.017599999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.018799999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.06160000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.006799999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.019200000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.31359999999999993\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.18600000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.154\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.05559999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0212\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.007600000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0632\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.05399999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.14800000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.06720000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.04\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.17200000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.11040000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.08200000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.04239999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.055600000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.32880000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.02760000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.08120000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1476\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.03160000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.025999999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1116\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.002000000000000007\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.07800000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0572\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0864\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.20160000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.006\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0007999999999999952\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.02839999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.022400000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.196\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0072\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.2668\n",
            "Testing combination: {'rl_learning_rate': 0.1, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.034799999999999984\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0864\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0472\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.02800000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.014800000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1484\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.19519999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.012399999999999991\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.08319999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1436\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1444\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.11440000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.030400000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.023199999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.3224\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.08999999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.016799999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.053200000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.007599999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.046\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.013200000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.031200000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.054000000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.03920000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.2616\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.11800000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.10600000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0384\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0364\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.25520000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.02\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.010000000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.08440000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.019199999999999984\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.07520000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.11\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.018799999999999994\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.14639999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1484\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.47120000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1316\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.08239999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.09600000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.09839999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0712\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.3272\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.11479999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.20439999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.08199999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.07800000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.2632\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.12919999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.04280000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.048400000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.12560000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.042800000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.09399999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.00959999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0704\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0424\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.055999999999999994\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0048\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.3712\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.007600000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.3072\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0063999999999999925\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.06559999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.024399999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0316\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.20879999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0968\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.07079999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0384\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.05960000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.008800000000000016\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0444\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.003200000000000007\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.04040000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.05039999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.034\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.206\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.021599999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0164\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.08800000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.05199999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.23800000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.014400000000000013\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.10799999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.16759999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.005200000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1112\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.004000000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.05879999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.14\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.18119999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.2348\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0916\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.044399999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0512\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.032799999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0288\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.038400000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.10640000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1296\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0632\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.10239999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.08079999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0056000000000000025\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.06679999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0192\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.09239999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.044799999999999986\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.008000000000000007\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.10559999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1052\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1216\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.04120000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.005200000000000013\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.18000000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.008000000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.11639999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.022400000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.03439999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.09519999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.08199999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1284\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1404\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1444\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0432\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0424\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.009600000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.05840000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.024400000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.05840000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.2732\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1684\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1424\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1044\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.001600000000000007\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.09239999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.08359999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.28119999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1252\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0328\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.078\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.06679999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.05960000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.06199999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.008399999999999989\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1288\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1744\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.21479999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.132\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.05040000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.011999999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.09759999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.12480000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.039999999999999994\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.168\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.16440000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.23479999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0212\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.044\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0376\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0924\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1496\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1932\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0604\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.12959999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0172\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.04279999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.005199999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.03840000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.008399999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.06559999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.05\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1732\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.004800000000000009\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1336\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0048\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.011199999999999993\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.19560000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.019200000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.16\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1312\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1048\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.037599999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.056399999999999985\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.11239999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.20519999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.08719999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1936\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.053999999999999986\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0516\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0216\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.007600000000000007\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.04400000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.04880000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0872\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1284\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0288\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.02759999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.092\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0228\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0116\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.11719999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.08600000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.011600000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.011600000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.07200000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.09359999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.003999999999999992\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.038\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0047999999999999935\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.126\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.09480000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.015999999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.005600000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1208\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0832\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.04039999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.14439999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.04159999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.053200000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.029599999999999994\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.032400000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.037599999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0332\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1268\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.11959999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.10919999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.2444\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.2192\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.06000000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1532\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.053599999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.148\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0544\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.09\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1636\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0048\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.004000000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.002000000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0372\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.006000000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.064\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.31920000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.011199999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.007200000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.003600000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.22400000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.2116\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.092\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.11159999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0556\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.12439999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.021599999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0632\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.09440000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.08520000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.04279999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.018800000000000008\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0644\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.021199999999999993\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.13\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.023200000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.008000000000000007\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.047599999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.07479999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1632\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.10240000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.21439999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.05960000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0996\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.054400000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.12840000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.012000000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1364\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.12240000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.12319999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1928\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.007600000000000011\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.040000000000000015\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0992\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.023999999999999994\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1108\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.2468\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0832\n",
            "Testing combination: {'rl_learning_rate': 0.01, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0288\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.12480000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.016399999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.016399999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1744\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.08719999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.09360000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.12999999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.2664\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1492\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0584\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0736\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 1.1102230246251566e-18\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1532\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1076\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.04720000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.272\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.026000000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.019999999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.057600000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0852\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0208\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.09280000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.12919999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.11359999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.009999999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0027999999999999956\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0256\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0672\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.12199999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.18080000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.002000000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1272\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.044399999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.02959999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.028000000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.01399999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.066\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.358\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.06200000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.106\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.08960000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.08760000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.18439999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1816\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.010800000000000011\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.12279999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.05399999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.07919999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.01479999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.005600000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.008399999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.09919999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.18119999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.17200000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.3208\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.11079999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0416\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.023199999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.2544\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0035999999999999964\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1108\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.09079999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.07039999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0644\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.056400000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1164\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.10800000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.019600000000000017\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.08479999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.12\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1324\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1332\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.03759999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0984\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.036\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.011200000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0876\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.052000000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.192\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0328\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.08559999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.08959999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1012\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.08960000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0664\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.09720000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.3036\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.05720000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1484\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.10640000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.19720000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.029200000000000018\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0908\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.2444\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.12960000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.08839999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0968\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0028000000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.00040000000000001146\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.043600000000000014\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.08639999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.015199999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.14320000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1404\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.09519999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.09760000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.08839999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.01840000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.20079999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.17159999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.07919999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1284\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.03559999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.14559999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0288\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.07400000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1416\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1552\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0916\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.05800000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0308\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.10600000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.025600000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.023600000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.032400000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.011600000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0796\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.14919999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1252\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.027199999999999988\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.02039999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.047599999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.13440000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.16240000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.19360000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.05600000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0408\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.04839999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0788\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.11920000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.02040000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.008400000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.013599999999999994\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0336\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.03560000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0676\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.012000000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0036\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.038000000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.096\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.09160000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.084\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.188\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.047599999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1876\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.021999999999999992\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1268\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.019599999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1324\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.012800000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.098\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0003999999999999981\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.013200000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.08120000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1464\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.03440000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0031999999999999984\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.18880000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.027599999999999993\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.10640000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0384\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.04039999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1628\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.15600000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.004399999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0588\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0404\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0004000000000000048\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0064000000000000055\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.19880000000000003\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.12560000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0684\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0968\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1752\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.04640000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0616\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.010400000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.054400000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.2176\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.13240000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.2916\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.005, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.007599999999999992\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.044800000000000006\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1736\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.043199999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1532\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.04200000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1312\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0768\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.184\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.04240000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0020000000000000018\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.07920000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0548\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0572\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.05399999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.023200000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0348\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0728\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.07919999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.05440000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0516\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.024000000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.30319999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1384\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.054799999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0464\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.026400000000000007\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.026399999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.2464\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.07640000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.06879999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.08, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0044\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.09879999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.11280000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.029999999999999995\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1564\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0168\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.03320000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1968\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.05319999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.1184\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.11359999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0964\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0672\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0408\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1388\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.3340000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.2412\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.04600000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0732\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.028000000000000014\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.00039999999999998923\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1708\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.1152\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0152\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0848\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.13079999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0576\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.05840000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.2296\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.26880000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.026799999999999997\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.00039999999999999145\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1732\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.07440000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.061600000000000016\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.01560000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0716\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.032799999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.172\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.0212\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.10399999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.019200000000000005\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0288\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.02279999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.0696\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.118\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.01440000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.2532\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1752\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.056799999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.010399999999999996\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.06559999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.0412\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.09159999999999999\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.4144\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0676\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.99, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.05800000000000001\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.1008\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.18880000000000002\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.030800000000000004\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [1024, 512, 1024, 512], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.1632\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: 0.0456\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: -0.2292\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 600000}\n",
            "Average Reward: -0.19879999999999998\n",
            "Testing combination: {'rl_learning_rate': 0.005, 'sl_learning_rate': 0.001, 'q_epsilon_start': 0.3, 'q_epsilon_end': 0.05, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 1000000, 'q_replay_memory_size': 50000}\n",
            "Average Reward: 0.04800000000000001\n",
            "Best parameters found:\n",
            "{'rl_learning_rate': 0.01, 'sl_learning_rate': 0.01, 'q_epsilon_start': 0.6, 'q_epsilon_end': 0.0, 'q_discount_factor': 0.95, 'hidden_layers_sizes': [128, 128], 'reservoir_buffer_capacity': 30000000, 'q_replay_memory_size': 600000}\n",
            "Best average reward: 0.3272\n"
          ]
        }
      ],
      "source": [
        "# Define the environment\n",
        "env = rlcard.make('limit-holdem')\n",
        "eval_env = rlcard.make('limit-holdem')\n",
        "\n",
        "# Define the grid of parameters for grid search\n",
        "param_grid = {\n",
        "    'rl_learning_rate': [0.1, 0.01, 0.005],\n",
        "    'sl_learning_rate': [0.01, 0.005, 0.001],\n",
        "    'q_epsilon_start': [0.08, 0.6, 0.3],\n",
        "    'q_epsilon_end': [0.0, 0.05],\n",
        "    'q_discount_factor': [0.99, 0.95],\n",
        "    'hidden_layers_sizes': [[1024, 512, 1024, 512], [128, 128]],\n",
        "    'reservoir_buffer_capacity': [30000000, 1000000],\n",
        "    'q_replay_memory_size': [600000, 50000]\n",
        "}\n",
        "\n",
        "# Generate all combinations of parameters\n",
        "keys, values = zip(*param_grid.items())\n",
        "param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
        "\n",
        "# Function to run the simulation and return the average reward\n",
        "def run_simulation(params):\n",
        "    print(f\"Testing combination: {params}\")\n",
        "\n",
        "    # Initialize the NFSP Agent with given parameters\n",
        "    agent = NFSPAgent(\n",
        "        num_actions=env.num_actions,\n",
        "        state_shape=env.state_shape[0],\n",
        "        hidden_layers_sizes=params['hidden_layers_sizes'],\n",
        "        q_mlp_layers=params['hidden_layers_sizes'],\n",
        "        reservoir_buffer_capacity=params['reservoir_buffer_capacity'],\n",
        "        anticipatory_param=0.1,\n",
        "        batch_size=256,\n",
        "        train_every=1,\n",
        "        rl_learning_rate=params['rl_learning_rate'],\n",
        "        sl_learning_rate=params['sl_learning_rate'],\n",
        "        min_buffer_size_to_learn=1000,\n",
        "        q_replay_memory_size=params['q_replay_memory_size'],\n",
        "        q_replay_memory_init_size=1000,\n",
        "        q_update_target_estimator_every=1000,\n",
        "        q_discount_factor=params['q_discount_factor'],\n",
        "        q_epsilon_start=params['q_epsilon_start'],\n",
        "        q_epsilon_end=params['q_epsilon_end'],\n",
        "        q_epsilon_decay_steps=10000,\n",
        "        q_batch_size=256,\n",
        "        q_train_every=1,\n",
        "        evaluate_with='average_policy'\n",
        "    )\n",
        "\n",
        "    # Set the agents in the environment\n",
        "    env.set_agents([agent, RandomAgent(num_actions=env.num_actions)])\n",
        "    eval_env.set_agents([agent, RandomAgent(num_actions=env.num_actions)])\n",
        "\n",
        "    # Run for a small number of episodes to estimate average reward\n",
        "    rewards = []\n",
        "    for _ in range(25):  # Number of tournaments to average over\n",
        "        _, payoffs = tournament(eval_env, 50)  # Run 50 games per tournament\n",
        "        rewards.append(np.mean(payoffs))\n",
        "\n",
        "    # Return the average reward\n",
        "    average_reward = np.mean(rewards)\n",
        "    print(f\"Average Reward: {average_reward}\")\n",
        "    return average_reward\n",
        "\n",
        "# Grid search over the parameter combinations\n",
        "best_reward = -float('inf')\n",
        "best_params = None\n",
        "\n",
        "for params in param_combinations:\n",
        "    average_reward = run_simulation(params)\n",
        "    if average_reward > best_reward:\n",
        "        best_reward = average_reward\n",
        "        best_params = params\n",
        "\n",
        "# Output the best parameters and their corresponding reward\n",
        "print(\"Best parameters found:\")\n",
        "print(best_params)\n",
        "print(f\"Best average reward: {best_reward}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1mBRcnCzB_9T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1mBRcnCzB_9T",
        "outputId": "0a0206de-caa1-4039-df1e-8a728deb5243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------\n",
            "  episode      |  1\n",
            "  reward       |  0.021\n",
            "----------------------------------------\n",
            "Episode 0, Reward: 0.021\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  317\n",
            "  reward       |  0.112\n",
            "----------------------------------------\n",
            "Episode 100, Reward: 0.112\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  670\n",
            "  reward       |  0.0625\n",
            "----------------------------------------\n",
            "Episode 200, Reward: 0.0625\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1054\n",
            "  reward       |  0.0225\n",
            "----------------------------------------\n",
            "Episode 300, Reward: 0.0225\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1398\n",
            "  reward       |  0.018\n",
            "----------------------------------------\n",
            "Episode 400, Reward: 0.018\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1782\n",
            "  reward       |  0.0655\n",
            "----------------------------------------\n",
            "Episode 500, Reward: 0.0655\n",
            "INFO - Step 1000, rl-loss: 2.961560010910034\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 1027, sl-loss: 0.7170925140380859\n",
            "----------------------------------------\n",
            "  episode      |  2142\n",
            "  reward       |  0.477\n",
            "----------------------------------------\n",
            "Episode 600, Reward: 0.477\n",
            "INFO - Step 1225, sl-loss: 0.10334484279155731\n",
            "----------------------------------------\n",
            "  episode      |  2554\n",
            "  reward       |  0.426\n",
            "----------------------------------------\n",
            "Episode 700, Reward: 0.426\n",
            "INFO - Step 1410, sl-loss: 0.09922565519809723\n",
            "----------------------------------------\n",
            "  episode      |  2947\n",
            "  reward       |  0.535\n",
            "----------------------------------------\n",
            "Episode 800, Reward: 0.535\n",
            "INFO - Step 1588, sl-loss: 0.07438492774963379\n",
            "----------------------------------------\n",
            "  episode      |  3317\n",
            "  reward       |  0.375\n",
            "----------------------------------------\n",
            "Episode 900, Reward: 0.375\n",
            "INFO - Step 1769, sl-loss: 0.17143157124519348\n",
            "----------------------------------------\n",
            "  episode      |  3700\n",
            "  reward       |  0.645\n",
            "----------------------------------------\n",
            "Episode 1000, Reward: 0.645\n",
            "INFO - Step 1935, sl-loss: 0.15947137773036957\n",
            "----------------------------------------\n",
            "  episode      |  4046\n",
            "  reward       |  0.542\n",
            "----------------------------------------\n",
            "Episode 1100, Reward: 0.542\n",
            "INFO - Step 2000, rl-loss: 0.42232802510261536\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 2128, sl-loss: 0.2054225206375122\n",
            "----------------------------------------\n",
            "  episode      |  4457\n",
            "  reward       |  0.3985\n",
            "----------------------------------------\n",
            "Episode 1200, Reward: 0.3985\n",
            "INFO - Step 2308, sl-loss: 0.2366548776626587\n",
            "----------------------------------------\n",
            "  episode      |  4846\n",
            "  reward       |  0.782\n",
            "----------------------------------------\n",
            "Episode 1300, Reward: 0.782\n",
            "INFO - Step 2483, sl-loss: 0.1359393149614334\n",
            "----------------------------------------\n",
            "  episode      |  5212\n",
            "  reward       |  0.5745\n",
            "----------------------------------------\n",
            "Episode 1400, Reward: 0.5745\n",
            "INFO - Step 2669, sl-loss: 0.09677422046661377\n",
            "----------------------------------------\n",
            "  episode      |  5615\n",
            "  reward       |  0.6695\n",
            "----------------------------------------\n",
            "Episode 1500, Reward: 0.6695\n",
            "INFO - Step 2842, sl-loss: 0.18429777026176453\n",
            "----------------------------------------\n",
            "  episode      |  5981\n",
            "  reward       |  0.601\n",
            "----------------------------------------\n",
            "Episode 1600, Reward: 0.601\n",
            "INFO - Step 3000, rl-loss: 0.46604347229003906\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 3044, sl-loss: 0.13579410314559937\n",
            "----------------------------------------\n",
            "  episode      |  6402\n",
            "  reward       |  0.6645\n",
            "----------------------------------------\n",
            "Episode 1700, Reward: 0.6645\n",
            "INFO - Step 3273, sl-loss: 0.14313960075378418\n",
            "----------------------------------------\n",
            "  episode      |  6875\n",
            "  reward       |  0.6505\n",
            "----------------------------------------\n",
            "Episode 1800, Reward: 0.6505\n",
            "INFO - Step 3438, sl-loss: 0.184793621301651\n",
            "----------------------------------------\n",
            "  episode      |  7229\n",
            "  reward       |  0.69\n",
            "----------------------------------------\n",
            "Episode 1900, Reward: 0.69\n",
            "INFO - Step 3626, sl-loss: 0.15939271450042725\n",
            "----------------------------------------\n",
            "  episode      |  7626\n",
            "  reward       |  0.611\n",
            "----------------------------------------\n",
            "Episode 2000, Reward: 0.611\n",
            "INFO - Step 3797, sl-loss: 0.22315248847007751\n",
            "----------------------------------------\n",
            "  episode      |  7985\n",
            "  reward       |  0.873\n",
            "----------------------------------------\n",
            "Episode 2100, Reward: 0.873\n",
            "INFO - Step 3998, sl-loss: 0.1877719759941101\n",
            "----------------------------------------\n",
            "  episode      |  8406\n",
            "  reward       |  1.0005\n",
            "----------------------------------------\n",
            "Episode 2200, Reward: 1.0005\n",
            "INFO - Step 4000, rl-loss: 0.35206881165504456\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 4184, sl-loss: 0.2571537494659424\n",
            "----------------------------------------\n",
            "  episode      |  8794\n",
            "  reward       |  1.0325\n",
            "----------------------------------------\n",
            "Episode 2300, Reward: 1.0325\n",
            "INFO - Step 4381, sl-loss: 0.2251947671175003\n",
            "----------------------------------------\n",
            "  episode      |  9210\n",
            "  reward       |  0.7545\n",
            "----------------------------------------\n",
            "Episode 2400, Reward: 0.7545\n",
            "INFO - Step 4585, sl-loss: 0.2589542269706726\n",
            "----------------------------------------\n",
            "  episode      |  9636\n",
            "  reward       |  0.8975\n",
            "----------------------------------------\n",
            "Episode 2500, Reward: 0.8975\n",
            "INFO - Step 4794, sl-loss: 0.2924037277698517\n",
            "----------------------------------------\n",
            "  episode      |  10076\n",
            "  reward       |  0.7605\n",
            "----------------------------------------\n",
            "Episode 2600, Reward: 0.7605\n",
            "INFO - Step 4978, sl-loss: 0.2386261224746704\n",
            "----------------------------------------\n",
            "  episode      |  10473\n",
            "  reward       |  0.844\n",
            "----------------------------------------\n",
            "Episode 2700, Reward: 0.844\n",
            "INFO - Step 5000, rl-loss: 0.46162959933280945\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 5197, sl-loss: 0.262177973985672\n",
            "----------------------------------------\n",
            "  episode      |  10934\n",
            "  reward       |  0.742\n",
            "----------------------------------------\n",
            "Episode 2800, Reward: 0.742\n",
            "INFO - Step 5371, sl-loss: 0.25770431756973267\n",
            "----------------------------------------\n",
            "  episode      |  11327\n",
            "  reward       |  0.768\n",
            "----------------------------------------\n",
            "Episode 2900, Reward: 0.768\n",
            "INFO - Step 5589, sl-loss: 0.17016121745109558\n",
            "----------------------------------------\n",
            "  episode      |  11794\n",
            "  reward       |  0.8405\n",
            "----------------------------------------\n",
            "Episode 3000, Reward: 0.8405\n",
            "INFO - Step 5808, sl-loss: 0.19938300549983978\n",
            "----------------------------------------\n",
            "  episode      |  12258\n",
            "  reward       |  0.987\n",
            "----------------------------------------\n",
            "Episode 3100, Reward: 0.987\n",
            "INFO - Step 6000, rl-loss: 0.7958985567092896\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 6005, sl-loss: 0.3462919592857361\n",
            "----------------------------------------\n",
            "  episode      |  12690\n",
            "  reward       |  0.976\n",
            "----------------------------------------\n",
            "Episode 3200, Reward: 0.976\n",
            "INFO - Step 6202, sl-loss: 0.2628672420978546\n",
            "----------------------------------------\n",
            "  episode      |  13123\n",
            "  reward       |  1.0745\n",
            "----------------------------------------\n",
            "Episode 3300, Reward: 1.0745\n",
            "INFO - Step 6406, sl-loss: 0.3062742352485657\n",
            "----------------------------------------\n",
            "  episode      |  13557\n",
            "  reward       |  1.1455\n",
            "----------------------------------------\n",
            "Episode 3400, Reward: 1.1455\n",
            "INFO - Step 6618, sl-loss: 0.2076745331287384\n",
            "----------------------------------------\n",
            "  episode      |  14007\n",
            "  reward       |  0.895\n",
            "----------------------------------------\n",
            "Episode 3500, Reward: 0.895\n",
            "INFO - Step 6814, sl-loss: 0.3412051200866699\n",
            "----------------------------------------\n",
            "  episode      |  14424\n",
            "  reward       |  0.8525\n",
            "----------------------------------------\n",
            "Episode 3600, Reward: 0.8525\n",
            "INFO - Step 7000, rl-loss: 1.0581954717636108\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 7032, sl-loss: 0.17650772631168365\n",
            "----------------------------------------\n",
            "  episode      |  14891\n",
            "  reward       |  0.9645\n",
            "----------------------------------------\n",
            "Episode 3700, Reward: 0.9645\n",
            "INFO - Step 7265, sl-loss: 0.35341641306877136\n",
            "----------------------------------------\n",
            "  episode      |  15374\n",
            "  reward       |  1.009\n",
            "----------------------------------------\n",
            "Episode 3800, Reward: 1.009\n",
            "INFO - Step 7463, sl-loss: 0.22051775455474854\n",
            "----------------------------------------\n",
            "  episode      |  15798\n",
            "  reward       |  0.9635\n",
            "----------------------------------------\n",
            "Episode 3900, Reward: 0.9635\n",
            "INFO - Step 7680, sl-loss: 0.3387278914451599\n",
            "----------------------------------------\n",
            "  episode      |  16277\n",
            "  reward       |  1.0285\n",
            "----------------------------------------\n",
            "Episode 4000, Reward: 1.0285\n",
            "INFO - Step 7911, sl-loss: 0.36457881331443787\n",
            "----------------------------------------\n",
            "  episode      |  16768\n",
            "  reward       |  1.081\n",
            "----------------------------------------\n",
            "Episode 4100, Reward: 1.081\n",
            "INFO - Step 8000, rl-loss: 2.246941328048706\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 8094, sl-loss: 0.23145437240600586\n",
            "----------------------------------------\n",
            "  episode      |  17176\n",
            "  reward       |  0.9525\n",
            "----------------------------------------\n",
            "Episode 4200, Reward: 0.9525\n",
            "INFO - Step 8330, sl-loss: 0.30916503071784973\n",
            "----------------------------------------\n",
            "  episode      |  17678\n",
            "  reward       |  0.9585\n",
            "----------------------------------------\n",
            "Episode 4300, Reward: 0.9585\n",
            "INFO - Step 8556, sl-loss: 0.2695890963077545\n",
            "----------------------------------------\n",
            "  episode      |  18169\n",
            "  reward       |  1.0645\n",
            "----------------------------------------\n",
            "Episode 4400, Reward: 1.0645\n",
            "INFO - Step 8741, sl-loss: 0.3661711513996124\n",
            "----------------------------------------\n",
            "  episode      |  18577\n",
            "  reward       |  1.0505\n",
            "----------------------------------------\n",
            "Episode 4500, Reward: 1.0505\n",
            "INFO - Step 8981, sl-loss: 0.31455373764038086\n",
            "----------------------------------------\n",
            "  episode      |  19101\n",
            "  reward       |  1.001\n",
            "----------------------------------------\n",
            "Episode 4600, Reward: 1.001\n",
            "INFO - Step 9000, rl-loss: 1.267897367477417\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 9183, sl-loss: 0.32396814227104187\n",
            "----------------------------------------\n",
            "  episode      |  19540\n",
            "  reward       |  1.124\n",
            "----------------------------------------\n",
            "Episode 4700, Reward: 1.124\n",
            "INFO - Step 9401, sl-loss: 0.23785850405693054\n",
            "----------------------------------------\n",
            "  episode      |  20023\n",
            "  reward       |  0.8885\n",
            "----------------------------------------\n",
            "Episode 4800, Reward: 0.8885\n",
            "INFO - Step 9650, sl-loss: 0.2970340847969055\n",
            "----------------------------------------\n",
            "  episode      |  20558\n",
            "  reward       |  1.2135\n",
            "----------------------------------------\n",
            "Episode 4900, Reward: 1.2135\n",
            "INFO - Step 9879, sl-loss: 0.32686108350753784\n",
            "----------------------------------------\n",
            "  episode      |  21056\n",
            "  reward       |  1.0955\n",
            "----------------------------------------\n",
            "Episode 5000, Reward: 1.0955\n",
            "INFO - Step 10000, rl-loss: 1.4375144243240356\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 10108, sl-loss: 0.2966602146625519\n",
            "----------------------------------------\n",
            "  episode      |  21553\n",
            "  reward       |  1.3285\n",
            "----------------------------------------\n",
            "Episode 5100, Reward: 1.3285\n",
            "INFO - Step 10340, sl-loss: 0.2602272033691406\n",
            "----------------------------------------\n",
            "  episode      |  22057\n",
            "  reward       |  0.9675\n",
            "----------------------------------------\n",
            "Episode 5200, Reward: 0.9675\n",
            "INFO - Step 10560, sl-loss: 0.23893418908119202\n",
            "----------------------------------------\n",
            "  episode      |  22550\n",
            "  reward       |  1.2645\n",
            "----------------------------------------\n",
            "Episode 5300, Reward: 1.2645\n",
            "INFO - Step 10776, sl-loss: 0.31204429268836975\n",
            "----------------------------------------\n",
            "  episode      |  23022\n",
            "  reward       |  1.402\n",
            "----------------------------------------\n",
            "Episode 5400, Reward: 1.402\n",
            "INFO - Step 11000, rl-loss: 1.6152145862579346\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 11008, sl-loss: 0.25559762120246887\n",
            "----------------------------------------\n",
            "  episode      |  23527\n",
            "  reward       |  1.17\n",
            "----------------------------------------\n",
            "Episode 5500, Reward: 1.17\n",
            "INFO - Step 11212, sl-loss: 0.3226199448108673\n",
            "----------------------------------------\n",
            "  episode      |  23987\n",
            "  reward       |  1.096\n",
            "----------------------------------------\n",
            "Episode 5600, Reward: 1.096\n",
            "INFO - Step 11429, sl-loss: 0.34143200516700745\n",
            "----------------------------------------\n",
            "  episode      |  24468\n",
            "  reward       |  1.1565\n",
            "----------------------------------------\n",
            "Episode 5700, Reward: 1.1565\n",
            "INFO - Step 11627, sl-loss: 0.3400138318538666\n",
            "----------------------------------------\n",
            "  episode      |  24916\n",
            "  reward       |  1.263\n",
            "----------------------------------------\n",
            "Episode 5800, Reward: 1.263\n",
            "INFO - Step 11839, sl-loss: 0.34727466106414795\n",
            "----------------------------------------\n",
            "  episode      |  25391\n",
            "  reward       |  1.516\n",
            "----------------------------------------\n",
            "Episode 5900, Reward: 1.516\n",
            "INFO - Step 12000, rl-loss: 1.814576506614685\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 12053, sl-loss: 0.39359167218208313\n",
            "----------------------------------------\n",
            "  episode      |  25857\n",
            "  reward       |  1.423\n",
            "----------------------------------------\n",
            "Episode 6000, Reward: 1.423\n",
            "INFO - Step 12277, sl-loss: 0.33917105197906494\n",
            "----------------------------------------\n",
            "  episode      |  26353\n",
            "  reward       |  1.2805\n",
            "----------------------------------------\n",
            "Episode 6100, Reward: 1.2805\n",
            "INFO - Step 12480, sl-loss: 0.33239248394966125\n",
            "----------------------------------------\n",
            "  episode      |  26803\n",
            "  reward       |  1.2955\n",
            "----------------------------------------\n",
            "Episode 6200, Reward: 1.2955\n",
            "INFO - Step 12722, sl-loss: 0.28484290838241577\n",
            "----------------------------------------\n",
            "  episode      |  27329\n",
            "  reward       |  1.6025\n",
            "----------------------------------------\n",
            "Episode 6300, Reward: 1.6025\n",
            "INFO - Step 12937, sl-loss: 0.29785284399986267\n",
            "----------------------------------------\n",
            "  episode      |  27806\n",
            "  reward       |  1.3825\n",
            "----------------------------------------\n",
            "Episode 6400, Reward: 1.3825\n",
            "INFO - Step 13000, rl-loss: 2.100695848464966\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 13165, sl-loss: 0.30792340636253357\n",
            "----------------------------------------\n",
            "  episode      |  28299\n",
            "  reward       |  1.3015\n",
            "----------------------------------------\n",
            "Episode 6500, Reward: 1.3015\n",
            "INFO - Step 13398, sl-loss: 0.4350065588951111\n",
            "----------------------------------------\n",
            "  episode      |  28801\n",
            "  reward       |  1.531\n",
            "----------------------------------------\n",
            "Episode 6600, Reward: 1.531\n",
            "INFO - Step 13623, sl-loss: 0.38796478509902954\n",
            "----------------------------------------\n",
            "  episode      |  29292\n",
            "  reward       |  1.232\n",
            "----------------------------------------\n",
            "Episode 6700, Reward: 1.232\n",
            "INFO - Step 13857, sl-loss: 0.4546266198158264\n",
            "----------------------------------------\n",
            "  episode      |  29803\n",
            "  reward       |  1.504\n",
            "----------------------------------------\n",
            "Episode 6800, Reward: 1.504\n",
            "INFO - Step 14000, rl-loss: 2.49436616897583\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 14099, sl-loss: 0.35723617672920227\n",
            "----------------------------------------\n",
            "  episode      |  30323\n",
            "  reward       |  1.319\n",
            "----------------------------------------\n",
            "Episode 6900, Reward: 1.319\n",
            "INFO - Step 14330, sl-loss: 0.3859819173812866\n",
            "----------------------------------------\n",
            "  episode      |  30835\n",
            "  reward       |  1.515\n",
            "----------------------------------------\n",
            "Episode 7000, Reward: 1.515\n",
            "INFO - Step 14554, sl-loss: 0.33618688583374023\n",
            "----------------------------------------\n",
            "  episode      |  31326\n",
            "  reward       |  1.2875\n",
            "----------------------------------------\n",
            "Episode 7100, Reward: 1.2875\n",
            "INFO - Step 14769, sl-loss: 0.318748414516449\n",
            "----------------------------------------\n",
            "  episode      |  31802\n",
            "  reward       |  1.4925\n",
            "----------------------------------------\n",
            "Episode 7200, Reward: 1.4925\n",
            "INFO - Step 14999, sl-loss: 0.4621480405330658\n",
            "----------------------------------------\n",
            "  episode      |  32308\n",
            "  reward       |  1.4435\n",
            "----------------------------------------\n",
            "Episode 7300, Reward: 1.4435\n",
            "INFO - Step 15000, rl-loss: 3.425959587097168\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 15231, sl-loss: 0.334386944770813\n",
            "----------------------------------------\n",
            "  episode      |  32809\n",
            "  reward       |  1.715\n",
            "----------------------------------------\n",
            "Episode 7400, Reward: 1.715\n",
            "INFO - Step 15466, sl-loss: 0.45595014095306396\n",
            "----------------------------------------\n",
            "  episode      |  33324\n",
            "  reward       |  1.722\n",
            "----------------------------------------\n",
            "Episode 7500, Reward: 1.722\n",
            "INFO - Step 15655, sl-loss: 0.4231453835964203\n",
            "----------------------------------------\n",
            "  episode      |  33753\n",
            "  reward       |  1.6055\n",
            "----------------------------------------\n",
            "Episode 7600, Reward: 1.6055\n",
            "INFO - Step 15861, sl-loss: 0.44139230251312256\n",
            "----------------------------------------\n",
            "  episode      |  34211\n",
            "  reward       |  1.438\n",
            "----------------------------------------\n",
            "Episode 7700, Reward: 1.438\n",
            "INFO - Step 16000, rl-loss: 3.022521734237671\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 16072, sl-loss: 0.3643049895763397\n",
            "----------------------------------------\n",
            "  episode      |  34676\n",
            "  reward       |  1.67\n",
            "----------------------------------------\n",
            "Episode 7800, Reward: 1.67\n",
            "INFO - Step 16305, sl-loss: 0.3258359432220459\n",
            "----------------------------------------\n",
            "  episode      |  35186\n",
            "  reward       |  1.484\n",
            "----------------------------------------\n",
            "Episode 7900, Reward: 1.484\n",
            "INFO - Step 16542, sl-loss: 0.3707536458969116\n",
            "----------------------------------------\n",
            "  episode      |  35705\n",
            "  reward       |  1.5865\n",
            "----------------------------------------\n",
            "Episode 8000, Reward: 1.5865\n",
            "INFO - Step 16772, sl-loss: 0.42578989267349243\n",
            "----------------------------------------\n",
            "  episode      |  36210\n",
            "  reward       |  1.532\n",
            "----------------------------------------\n",
            "Episode 8100, Reward: 1.532\n",
            "INFO - Step 17000, rl-loss: 2.164170980453491\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 17020, sl-loss: 0.36199086904525757\n",
            "----------------------------------------\n",
            "  episode      |  36754\n",
            "  reward       |  1.672\n",
            "----------------------------------------\n",
            "Episode 8200, Reward: 1.672\n",
            "INFO - Step 17235, sl-loss: 0.5535086393356323\n",
            "----------------------------------------\n",
            "  episode      |  37228\n",
            "  reward       |  1.3095\n",
            "----------------------------------------\n",
            "Episode 8300, Reward: 1.3095\n",
            "INFO - Step 17433, sl-loss: 0.38409629464149475\n",
            "----------------------------------------\n",
            "  episode      |  37675\n",
            "  reward       |  1.7005\n",
            "----------------------------------------\n",
            "Episode 8400, Reward: 1.7005\n",
            "INFO - Step 17638, sl-loss: 0.4277227818965912\n",
            "----------------------------------------\n",
            "  episode      |  38135\n",
            "  reward       |  1.53\n",
            "----------------------------------------\n",
            "Episode 8500, Reward: 1.53\n",
            "INFO - Step 17892, sl-loss: 0.34260037541389465\n",
            "----------------------------------------\n",
            "  episode      |  38677\n",
            "  reward       |  1.454\n",
            "----------------------------------------\n",
            "Episode 8600, Reward: 1.454\n",
            "INFO - Step 18000, rl-loss: 3.1226377487182617\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 18138, sl-loss: 0.3996970057487488\n",
            "----------------------------------------\n",
            "  episode      |  39211\n",
            "  reward       |  1.669\n",
            "----------------------------------------\n",
            "Episode 8700, Reward: 1.669\n",
            "INFO - Step 18388, sl-loss: 0.4477671980857849\n",
            "----------------------------------------\n",
            "  episode      |  39747\n",
            "  reward       |  1.8735\n",
            "----------------------------------------\n",
            "Episode 8800, Reward: 1.8735\n",
            "INFO - Step 18627, sl-loss: 0.4144229590892792\n",
            "----------------------------------------\n",
            "  episode      |  40268\n",
            "  reward       |  1.49\n",
            "----------------------------------------\n",
            "Episode 8900, Reward: 1.49\n",
            "INFO - Step 18873, sl-loss: 0.43266457319259644\n",
            "----------------------------------------\n",
            "  episode      |  40804\n",
            "  reward       |  1.5255\n",
            "----------------------------------------\n",
            "Episode 9000, Reward: 1.5255\n",
            "INFO - Step 19000, rl-loss: 3.408677339553833\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 19084, sl-loss: 0.4030951261520386\n",
            "----------------------------------------\n",
            "  episode      |  41272\n",
            "  reward       |  1.626\n",
            "----------------------------------------\n",
            "Episode 9100, Reward: 1.626\n",
            "INFO - Step 19295, sl-loss: 0.45651936531066895\n",
            "----------------------------------------\n",
            "  episode      |  41738\n",
            "  reward       |  1.719\n",
            "----------------------------------------\n",
            "Episode 9200, Reward: 1.719\n",
            "INFO - Step 19524, sl-loss: 0.3335205316543579\n",
            "----------------------------------------\n",
            "  episode      |  42247\n",
            "  reward       |  1.6835\n",
            "----------------------------------------\n",
            "Episode 9300, Reward: 1.6835\n",
            "INFO - Step 19746, sl-loss: 0.4423869252204895\n",
            "----------------------------------------\n",
            "  episode      |  42737\n",
            "  reward       |  1.705\n",
            "----------------------------------------\n",
            "Episode 9400, Reward: 1.705\n",
            "INFO - Step 19953, sl-loss: 0.4274628758430481\n",
            "----------------------------------------\n",
            "  episode      |  43196\n",
            "  reward       |  1.726\n",
            "----------------------------------------\n",
            "Episode 9500, Reward: 1.726\n",
            "INFO - Step 20000, rl-loss: 3.214139699935913\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 20204, sl-loss: 0.48014652729034424\n",
            "----------------------------------------\n",
            "  episode      |  43740\n",
            "  reward       |  1.8845\n",
            "----------------------------------------\n",
            "Episode 9600, Reward: 1.8845\n",
            "INFO - Step 20415, sl-loss: 0.45513802766799927\n",
            "----------------------------------------\n",
            "  episode      |  44200\n",
            "  reward       |  1.69\n",
            "----------------------------------------\n",
            "Episode 9700, Reward: 1.69\n",
            "INFO - Step 20651, sl-loss: 0.4312483072280884\n",
            "----------------------------------------\n",
            "  episode      |  44716\n",
            "  reward       |  1.8175\n",
            "----------------------------------------\n",
            "Episode 9800, Reward: 1.8175\n",
            "INFO - Step 20852, sl-loss: 0.4329226613044739\n",
            "----------------------------------------\n",
            "  episode      |  45175\n",
            "  reward       |  1.672\n",
            "----------------------------------------\n",
            "Episode 9900, Reward: 1.672\n",
            "INFO - Step 21000, rl-loss: 2.972421884536743\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 21098, sl-loss: 0.4314647316932678\n",
            "----------------------------------------\n",
            "  episode      |  45705\n",
            "  reward       |  1.638\n",
            "----------------------------------------\n",
            "Episode 10000, Reward: 1.638\n",
            "INFO - Step 21332, sl-loss: 0.451474666595459\n",
            "----------------------------------------\n",
            "  episode      |  46214\n",
            "  reward       |  1.7495\n",
            "----------------------------------------\n",
            "Episode 10100, Reward: 1.7495\n",
            "INFO - Step 21558, sl-loss: 0.4357922673225403\n",
            "----------------------------------------\n",
            "  episode      |  46717\n",
            "  reward       |  1.6995\n",
            "----------------------------------------\n",
            "Episode 10200, Reward: 1.6995\n",
            "INFO - Step 21796, sl-loss: 0.37998420000076294\n",
            "----------------------------------------\n",
            "  episode      |  47236\n",
            "  reward       |  1.639\n",
            "----------------------------------------\n",
            "Episode 10300, Reward: 1.639\n",
            "INFO - Step 22000, rl-loss: 2.4621853828430176\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 22011, sl-loss: 0.5521049499511719\n",
            "----------------------------------------\n",
            "  episode      |  47716\n",
            "  reward       |  1.837\n",
            "----------------------------------------\n",
            "Episode 10400, Reward: 1.837\n",
            "INFO - Step 22231, sl-loss: 0.36837202310562134\n",
            "----------------------------------------\n",
            "  episode      |  48207\n",
            "  reward       |  1.6985\n",
            "----------------------------------------\n",
            "Episode 10500, Reward: 1.6985\n",
            "INFO - Step 22462, sl-loss: 0.4210783839225769\n",
            "----------------------------------------\n",
            "  episode      |  48716\n",
            "  reward       |  1.719\n",
            "----------------------------------------\n",
            "Episode 10600, Reward: 1.719\n",
            "INFO - Step 22681, sl-loss: 0.40218716859817505\n",
            "----------------------------------------\n",
            "  episode      |  49204\n",
            "  reward       |  1.8745\n",
            "----------------------------------------\n",
            "Episode 10700, Reward: 1.8745\n",
            "INFO - Step 22895, sl-loss: 0.43077126145362854\n",
            "----------------------------------------\n",
            "  episode      |  49685\n",
            "  reward       |  1.9675\n",
            "----------------------------------------\n",
            "Episode 10800, Reward: 1.9675\n",
            "INFO - Step 23000, rl-loss: 2.733433485031128\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 23075, sl-loss: 0.44314560294151306\n",
            "----------------------------------------\n",
            "  episode      |  50101\n",
            "  reward       |  1.826\n",
            "----------------------------------------\n",
            "Episode 10900, Reward: 1.826\n",
            "INFO - Step 23307, sl-loss: 0.5283083915710449\n",
            "----------------------------------------\n",
            "  episode      |  50614\n",
            "  reward       |  1.686\n",
            "----------------------------------------\n",
            "Episode 11000, Reward: 1.686\n",
            "INFO - Step 23539, sl-loss: 0.48671460151672363\n",
            "----------------------------------------\n",
            "  episode      |  51130\n",
            "  reward       |  1.807\n",
            "----------------------------------------\n",
            "Episode 11100, Reward: 1.807\n",
            "INFO - Step 23774, sl-loss: 0.4686122536659241\n",
            "----------------------------------------\n",
            "  episode      |  51644\n",
            "  reward       |  1.875\n",
            "----------------------------------------\n",
            "Episode 11200, Reward: 1.875\n",
            "INFO - Step 23974, sl-loss: 0.5019806027412415\n",
            "----------------------------------------\n",
            "  episode      |  52092\n",
            "  reward       |  1.8475\n",
            "----------------------------------------\n",
            "Episode 11300, Reward: 1.8475\n",
            "INFO - Step 24000, rl-loss: 3.127784252166748\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 24185, sl-loss: 0.41007253527641296\n",
            "----------------------------------------\n",
            "  episode      |  52563\n",
            "  reward       |  1.9265\n",
            "----------------------------------------\n",
            "Episode 11400, Reward: 1.9265\n",
            "INFO - Step 24412, sl-loss: 0.4816747307777405\n",
            "----------------------------------------\n",
            "  episode      |  53065\n",
            "  reward       |  1.6585\n",
            "----------------------------------------\n",
            "Episode 11500, Reward: 1.6585\n",
            "INFO - Step 24616, sl-loss: 0.4425995945930481\n",
            "----------------------------------------\n",
            "  episode      |  53524\n",
            "  reward       |  1.6575\n",
            "----------------------------------------\n",
            "Episode 11600, Reward: 1.6575\n",
            "INFO - Step 24849, sl-loss: 0.526003897190094\n",
            "----------------------------------------\n",
            "  episode      |  54034\n",
            "  reward       |  1.778\n",
            "----------------------------------------\n",
            "Episode 11700, Reward: 1.778\n",
            "INFO - Step 25000, rl-loss: 3.8937790393829346\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 25068, sl-loss: 0.3814733028411865\n",
            "----------------------------------------\n",
            "  episode      |  54519\n",
            "  reward       |  1.8305\n",
            "----------------------------------------\n",
            "Episode 11800, Reward: 1.8305\n",
            "INFO - Step 25297, sl-loss: 0.36866286396980286\n",
            "----------------------------------------\n",
            "  episode      |  55022\n",
            "  reward       |  1.815\n",
            "----------------------------------------\n",
            "Episode 11900, Reward: 1.815\n",
            "INFO - Step 25524, sl-loss: 0.496010422706604\n",
            "----------------------------------------\n",
            "  episode      |  55527\n",
            "  reward       |  1.581\n",
            "----------------------------------------\n",
            "Episode 12000, Reward: 1.581\n",
            "INFO - Step 25740, sl-loss: 0.5424699783325195\n",
            "----------------------------------------\n",
            "  episode      |  56005\n",
            "  reward       |  1.884\n",
            "----------------------------------------\n",
            "Episode 12100, Reward: 1.884\n",
            "INFO - Step 26000, rl-loss: 4.741765975952148\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 26005, sl-loss: 0.47031569480895996\n",
            "----------------------------------------\n",
            "  episode      |  56578\n",
            "  reward       |  1.876\n",
            "----------------------------------------\n",
            "Episode 12200, Reward: 1.876\n",
            "INFO - Step 26221, sl-loss: 0.49364402890205383\n",
            "----------------------------------------\n",
            "  episode      |  57063\n",
            "  reward       |  1.8395\n",
            "----------------------------------------\n",
            "Episode 12300, Reward: 1.8395\n",
            "INFO - Step 26455, sl-loss: 0.46426716446876526\n",
            "----------------------------------------\n",
            "  episode      |  57574\n",
            "  reward       |  1.803\n",
            "----------------------------------------\n",
            "Episode 12400, Reward: 1.803\n",
            "INFO - Step 26675, sl-loss: 0.4220118820667267\n",
            "----------------------------------------\n",
            "  episode      |  58057\n",
            "  reward       |  2.0535\n",
            "----------------------------------------\n",
            "Episode 12500, Reward: 2.0535\n",
            "INFO - Step 26889, sl-loss: 0.41824615001678467\n",
            "----------------------------------------\n",
            "  episode      |  58529\n",
            "  reward       |  1.7155\n",
            "----------------------------------------\n",
            "Episode 12600, Reward: 1.7155\n",
            "INFO - Step 27000, rl-loss: 3.247720956802368\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 27135, sl-loss: 0.4152120053768158\n",
            "----------------------------------------\n",
            "  episode      |  59061\n",
            "  reward       |  1.7755\n",
            "----------------------------------------\n",
            "Episode 12700, Reward: 1.7755\n",
            "INFO - Step 27343, sl-loss: 0.5389202833175659\n",
            "----------------------------------------\n",
            "  episode      |  59532\n",
            "  reward       |  2.166\n",
            "----------------------------------------\n",
            "Episode 12800, Reward: 2.166\n",
            "INFO - Step 27537, sl-loss: 0.47239041328430176\n",
            "----------------------------------------\n",
            "  episode      |  59974\n",
            "  reward       |  1.7895\n",
            "----------------------------------------\n",
            "Episode 12900, Reward: 1.7895\n",
            "INFO - Step 27775, sl-loss: 0.5548115372657776\n",
            "----------------------------------------\n",
            "  episode      |  60498\n",
            "  reward       |  1.776\n",
            "----------------------------------------\n",
            "Episode 13000, Reward: 1.776\n",
            "INFO - Step 27988, sl-loss: 0.39237189292907715\n",
            "----------------------------------------\n",
            "  episode      |  60970\n",
            "  reward       |  2.1805\n",
            "----------------------------------------\n",
            "Episode 13100, Reward: 2.1805\n",
            "INFO - Step 28000, rl-loss: 3.7121689319610596\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 28257, sl-loss: 0.4890565574169159\n",
            "----------------------------------------\n",
            "  episode      |  61548\n",
            "  reward       |  1.74\n",
            "----------------------------------------\n",
            "Episode 13200, Reward: 1.74\n",
            "INFO - Step 28506, sl-loss: 0.5320753455162048\n",
            "----------------------------------------\n",
            "  episode      |  62092\n",
            "  reward       |  1.885\n",
            "----------------------------------------\n",
            "Episode 13300, Reward: 1.885\n",
            "INFO - Step 28729, sl-loss: 0.43584001064300537\n",
            "----------------------------------------\n",
            "  episode      |  62579\n",
            "  reward       |  1.906\n",
            "----------------------------------------\n",
            "Episode 13400, Reward: 1.906\n",
            "INFO - Step 28959, sl-loss: 0.4500526189804077\n",
            "----------------------------------------\n",
            "  episode      |  63081\n",
            "  reward       |  1.775\n",
            "----------------------------------------\n",
            "Episode 13500, Reward: 1.775\n",
            "INFO - Step 29000, rl-loss: 3.9193389415740967\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 29160, sl-loss: 0.4329347610473633\n",
            "----------------------------------------\n",
            "  episode      |  63538\n",
            "  reward       |  1.778\n",
            "----------------------------------------\n",
            "Episode 13600, Reward: 1.778\n",
            "INFO - Step 29389, sl-loss: 0.6337732076644897\n",
            "----------------------------------------\n",
            "  episode      |  64043\n",
            "  reward       |  1.8305\n",
            "----------------------------------------\n",
            "Episode 13700, Reward: 1.8305\n",
            "INFO - Step 29636, sl-loss: 0.5220630168914795\n",
            "----------------------------------------\n",
            "  episode      |  64581\n",
            "  reward       |  1.7465\n",
            "----------------------------------------\n",
            "Episode 13800, Reward: 1.7465\n",
            "INFO - Step 29866, sl-loss: 0.37861862778663635\n",
            "----------------------------------------\n",
            "  episode      |  65085\n",
            "  reward       |  1.9745\n",
            "----------------------------------------\n",
            "Episode 13900, Reward: 1.9745\n",
            "INFO - Step 30000, rl-loss: 4.337994575500488\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 30064, sl-loss: 0.5407472848892212\n",
            "----------------------------------------\n",
            "  episode      |  65534\n",
            "  reward       |  1.9185\n",
            "----------------------------------------\n",
            "Episode 14000, Reward: 1.9185\n",
            "INFO - Step 30279, sl-loss: 0.452519953250885\n",
            "----------------------------------------\n",
            "  episode      |  66006\n",
            "  reward       |  2.105\n",
            "----------------------------------------\n",
            "Episode 14100, Reward: 2.105\n",
            "INFO - Step 30472, sl-loss: 0.4627813398838043\n",
            "----------------------------------------\n",
            "  episode      |  66440\n",
            "  reward       |  1.8365\n",
            "----------------------------------------\n",
            "Episode 14200, Reward: 1.8365\n",
            "INFO - Step 30676, sl-loss: 0.4823804497718811\n",
            "----------------------------------------\n",
            "  episode      |  66890\n",
            "  reward       |  1.807\n",
            "----------------------------------------\n",
            "Episode 14300, Reward: 1.807\n",
            "INFO - Step 30893, sl-loss: 0.6063672304153442\n",
            "----------------------------------------\n",
            "  episode      |  67373\n",
            "  reward       |  1.8465\n",
            "----------------------------------------\n",
            "Episode 14400, Reward: 1.8465\n",
            "INFO - Step 31000, rl-loss: 3.5341637134552\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 31121, sl-loss: 0.49391618371009827\n",
            "----------------------------------------\n",
            "  episode      |  67876\n",
            "  reward       |  1.7825\n",
            "----------------------------------------\n",
            "Episode 14500, Reward: 1.7825\n",
            "INFO - Step 31349, sl-loss: 0.4485628306865692\n",
            "----------------------------------------\n",
            "  episode      |  68380\n",
            "  reward       |  1.838\n",
            "----------------------------------------\n",
            "Episode 14600, Reward: 1.838\n",
            "INFO - Step 31557, sl-loss: 0.42163166403770447\n",
            "----------------------------------------\n",
            "  episode      |  68842\n",
            "  reward       |  1.9325\n",
            "----------------------------------------\n",
            "Episode 14700, Reward: 1.9325\n",
            "INFO - Step 31787, sl-loss: 0.5992178320884705\n",
            "----------------------------------------\n",
            "  episode      |  69342\n",
            "  reward       |  2.0955\n",
            "----------------------------------------\n",
            "Episode 14800, Reward: 2.0955\n",
            "INFO - Step 32000, rl-loss: 4.461246967315674\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 32007, sl-loss: 0.3957166373729706\n",
            "----------------------------------------\n",
            "  episode      |  69835\n",
            "  reward       |  1.7655\n",
            "----------------------------------------\n",
            "Episode 14900, Reward: 1.7655\n",
            "INFO - Step 32209, sl-loss: 0.3595424294471741\n",
            "Logs saved in experiments/limit_holdem_nfsp_result/\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Initialize the Logger and train with the best parameters found\n",
        "bestNFSPagent = NFSPAgent(\n",
        "    num_actions=env.num_actions,\n",
        "    state_shape=env.state_shape[0],\n",
        "    hidden_layers_sizes=best_params['hidden_layers_sizes'],\n",
        "    q_mlp_layers=best_params['hidden_layers_sizes'],\n",
        "    reservoir_buffer_capacity=best_params['reservoir_buffer_capacity'],\n",
        "    anticipatory_param=0.1,\n",
        "    batch_size=256,\n",
        "    train_every=1,\n",
        "    rl_learning_rate=best_params['rl_learning_rate'],\n",
        "    sl_learning_rate=best_params['sl_learning_rate'],\n",
        "    min_buffer_size_to_learn=1000,\n",
        "    q_replay_memory_size=best_params['q_replay_memory_size'],\n",
        "    q_replay_memory_init_size=1000,\n",
        "    q_update_target_estimator_every=1000,\n",
        "    q_discount_factor=best_params['q_discount_factor'],\n",
        "    q_epsilon_start=best_params['q_epsilon_start'],\n",
        "    q_epsilon_end=best_params['q_epsilon_end'],\n",
        "    q_epsilon_decay_steps=10000,\n",
        "    q_batch_size=256,\n",
        "    q_train_every=1,\n",
        "    evaluate_with='average_policy'\n",
        ")\n",
        "\n",
        "env.set_agents([bestNFSPagent, RandomAgent(num_actions=env.num_actions)])\n",
        "eval_env.set_agents([bestNFSPagent, RandomAgent(num_actions=env.num_actions)])\n",
        "\n",
        "with Logger(\"experiments/limit_holdem_nfsp_result/\") as logger:\n",
        "    for episode in range(15000):  # Increase the number of episodes\n",
        "        trajectories, payoffs = env.run(is_training=True)\n",
        "        trajectories = reorganize(trajectories, payoffs)\n",
        "\n",
        "        for ts in trajectories[0]:  # Only use trajectories of the learning agent\n",
        "            bestNFSPagent.feed(ts)\n",
        "\n",
        "        if episode % 100 == 0:\n",
        "            reward = tournament(eval_env, 1000)[0]\n",
        "            logger.log_performance(env.timestep, reward)\n",
        "            print(f'Episode {episode}, Reward: {reward}')\n",
        "\n",
        "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
        "\n",
        "plot_curve(csv_path, fig_path, 'NFSP Search on Limit Texas Hold\\'em')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y9kYeIqoqd_u",
      "metadata": {
        "id": "y9kYeIqoqd_u"
      },
      "source": [
        " ### 3.6.4 Conclusion\n",
        "As the plot illustrates, this approach successfully identifies a parameter combination that achieves stable performance, with rewards approaching 2. Conducting a more extensive grid search with additional episodes and a larger value range could further enhance the model's performance. Given the paper's results, with an optimal setup, we would expect this agent to outperform the others.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9c4fc74",
      "metadata": {
        "id": "b9c4fc74"
      },
      "source": [
        "## 3.7 Demonstration of Manual Play against Methods trained on a Random Agent <a class=\"anchor\" id=\"3.7\"></a>\n",
        "\n",
        "To experience the skill level of the trained models, we played a demonstration of 5 games per agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4add4780",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4add4780",
        "outputId": "bc0b2d87-b633-4220-9dc6-977c876d6e60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent Name:  Double Deep Q-Network\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│4        │   │J        │   │K        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♥    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        4│   │        J│   │        K│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│4        │   │J        │   │K        │   │8        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♥    │   │    ♥    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        4│   │        J│   │        K│   │        8│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│4        │   │J        │   │K        │   │8        │   │9        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♥    │   │    ♥    │   │    ♥    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        4│   │        J│   │        K│   │        8│   │        9│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++\n",
            "++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│4        │   │J        │   │K        │   │8        │   │9        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♥    │   │    ♥    │   │    ♥    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        4│   │        J│   │        K│   │        8│   │        9│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++\n",
            "++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses fold\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│Q        │   │5        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        Q│   │        5│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 8.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            ">> Player 1 chooses fold\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│8        │   │6        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        8│   │        6│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 0.5 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│3        │   │4        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        3│   │        4│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│3        │   │4        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        3│   │        4│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 2\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses fold\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You lose 1.0 chips!\n",
            "\n",
            "Press any key to continue...1\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│2        │   │Q        │   │K        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♠    │   │    ♠    │   │    ♣    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        2│   │        Q│   │        K│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 2\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses check\n",
            ">> Player 1 chooses check\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│2        │   │Q        │   │K        │   │4        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♠    │   │    ♠    │   │    ♣    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        2│   │        Q│   │        K│   │        4│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses check\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│2        │   │Q        │   │K        │   │4        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♠    │   │    ♠    │   │    ♣    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        2│   │        Q│   │        K│   │        4│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses check\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│2        │   │Q        │   │K        │   │4        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♠    │   │    ♠    │   │    ♣    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        2│   │        Q│   │        K│   │        4│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++\n",
            "++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses check\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│2        │   │Q        │   │K        │   │4        │   │5        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♠    │   │    ♠    │   │    ♣    │   │    ♣    │   │    ♠    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        2│   │        Q│   │        K│   │        4│   │        5│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 2\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses check\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses check\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │5        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        5│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You lose 9.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │9        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        9│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 2\n",
            ">> Player 0 chooses fold\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │5        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        5│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You lose 0.5 chips!\n",
            "\n",
            "Press any key to continue...\n",
            "Agent Name:  Deep Fitted Q-Iteration\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│2        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        2│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│2        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        2│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│5        │   │9        │   │7        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♥    │   │    ♦    │   │    ♠    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        5│   │        9│   │        7│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│2        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        2│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│5        │   │9        │   │7        │   │10       │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♦    │   │    ♠    │   │    ♠    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        5│   │        9│   │        7│   │       01│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│2        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        2│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│5        │   │9        │   │7        │   │10       │   │2        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♦    │   │    ♠    │   │    ♠    │   │    ♥    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        5│   │        9│   │        7│   │       01│   │        2│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│2        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        2│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│8        │   │J        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        8│   │        J│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You lose 7.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │Q        │   │7        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♠    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        8│   │        Q│   │        7│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │Q        │   │7        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♠    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        8│   │        Q│   │        7│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++\n",
            "++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │Q        │   │7        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♠    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        8│   │        Q│   │        7│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │Q        │   │7        │   │4        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♠    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        8│   │        Q│   │        7│   │        4│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │Q        │   │7        │   │4        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♠    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        8│   │        Q│   │        7│   │        4│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │Q        │   │7        │   │4        │   │4        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♠    │   │    ♣    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        8│   │        Q│   │        7│   │        4│   │        4│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++++++++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │Q        │   │7        │   │4        │   │4        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♠    │   │    ♣    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        8│   │        Q│   │        7│   │        4│   │        4│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++++++++++++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │9        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        9│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 23.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│5        │   │9        │   │3        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♣    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        5│   │        9│   │        3│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│5        │   │9        │   │3        │   │7        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♣    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        5│   │        9│   │        3│   │        7│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 2\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses check\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│5        │   │9        │   │3        │   │7        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♣    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        5│   │        9│   │        3│   │        7│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses check\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│5        │   │9        │   │3        │   │7        │   │Q        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♣    │   │    ♦    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        5│   │        9│   │        3│   │        7│   │        Q│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses check\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │9        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        9│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You lose 7.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│J        │   │3        │   │6        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♦    │   │    ♦    │   │    ♠    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        J│   │        3│   │        6│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│J        │   │3        │   │6        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♦    │   │    ♦    │   │    ♠    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        J│   │        3│   │        6│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++\n",
            "++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│J        │   │3        │   │6        │   │2        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♦    │   │    ♠    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        J│   │        3│   │        6│   │        2│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++\n",
            "++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│J        │   │3        │   │6        │   │2        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♦    │   │    ♠    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        J│   │        3│   │        6│   │        2│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│J        │   │3        │   │6        │   │2        │   │K        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♦    │   │    ♠    │   │    ♦    │   │    ♠    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        J│   │        3│   │        6│   │        2│   │        K│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│J        │   │3        │   │6        │   │2        │   │K        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♦    │   │    ♠    │   │    ♦    │   │    ♠    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        J│   │        3│   │        6│   │        2│   │        K│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│6        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        6│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 1\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │J        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        J│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 18.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│K        │   │7        │   │A        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♥    │   │    ♣    │   │    ♦    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        K│   │        7│   │        A│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│K        │   │7        │   │A        │   │10       │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♣    │   │    ♦    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        K│   │        7│   │        A│   │       01│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│K        │   │7        │   │A        │   │10       │   │9        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♣    │   │    ♦    │   │    ♣    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        K│   │        7│   │        A│   │       01│   │        9│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│7        │   │3        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        7│   │        3│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│10       │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│       01│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You lose 7.0 chips!\n",
            "\n",
            "Press any key to continue...\n"
          ]
        }
      ],
      "source": [
        "trained_agent_list = {'Double Deep Q-Network':TwoDQNagent,\n",
        "                      'Deep Fitted Q-Iteration': FittedDQagent}\n",
        "\n",
        "for agent in trained_agent_list:\n",
        "    print(\"Agent Name: \", agent)\n",
        "    manual_play(opponent_agent = trained_agent_list[agent], num_games = 5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ShhnZ9wzfjv",
      "metadata": {
        "id": "4ShhnZ9wzfjv"
      },
      "source": [
        "Above is a log demonstrating manual play against the two models trained on a random agent. The best performing models, Double DQN and Deep Fitted Q-Iteration, were selected to play five games each. The agents exhibited aggressive play, rarely folding in the early stages. Both agents adopted a similar style, playing passively with calls when they had no pairs during the pre-flop, but initiating strong raises when a pair was made after the turn or river. Interestingly, both agents shifted their strategy from passive to aggressive when encountering a gutshot straight draw (one card missing from a straight). This observation highlights their strategic adaptability and their ability to identify high-potential hands."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n5LBI2vCiZ_O",
      "metadata": {
        "id": "n5LBI2vCiZ_O"
      },
      "source": [
        "## 4. Applying Methods to Rule-Based Agents <a class=\"anchor\" id=\"chap4\"></a>\n",
        "In this section, we extend our investigation by training the successful reinforcement learning models identified previously against a rule-based agent, as opposed to a random agent. This approach facilitates a more rigorous evaluation of the models' performance against opponents with established strategies. By comparing the reward outcomes of these sessions with those obtained against random agents, we aim to assess the adaptability and effectiveness of the models in dynamic gameplay scenarios. This analysis offers insights into the robustness and generalization capabilities of the trained agents, highlighting their potential applicability in real-world poker environments. The RLCard library provides only a single rule-based agent for the Limit Texas Hold'em environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "UtI35MgQiehu",
      "metadata": {
        "id": "UtI35MgQiehu"
      },
      "outputs": [],
      "source": [
        "pre_trained_agent = models.load('limit-holdem-rule-v1').agents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6kdp2oK3ihac",
      "metadata": {
        "id": "6kdp2oK3ihac"
      },
      "source": [
        "We now select the two best-performing agents from Section 3 (Double DQN and Deep Fitted Q-Iteration) and train them using the rule-based agent as the opponent."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rBbX-7ILive5",
      "metadata": {
        "id": "rBbX-7ILive5"
      },
      "source": [
        "## 4.1 Double-DQN-Agent vs. Rule-Based <a class=\"anchor\" id=\"4.1\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "PoAEQHnvi32J",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PoAEQHnvi32J",
        "outputId": "b2434da7-d336-4f94-947b-6e43db8e9deb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1\n",
            "  reward       |  0.442\n",
            "----------------------------------------\n",
            "Episode 100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  189\n",
            "  reward       |  0.258\n",
            "----------------------------------------\n",
            "INFO - Step 100, rl-loss: 2.0203466415405273\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 169, rl-loss: 3.4689834117889404Episode 200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  395\n",
            "  reward       |  0.1185\n",
            "----------------------------------------\n",
            "INFO - Step 260, rl-loss: 2.6188557147979736Episode 300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  584\n",
            "  reward       |  0.2095\n",
            "----------------------------------------\n",
            "INFO - Step 365, rl-loss: 2.885847568511963Episode 400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  812\n",
            "  reward       |  0.242\n",
            "----------------------------------------\n",
            "INFO - Step 451, rl-loss: 22.092973709106445Episode 500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1006\n",
            "  reward       |  0.2525\n",
            "----------------------------------------\n",
            "INFO - Step 530, rl-loss: 1.1826730966567993Episode 600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1183\n",
            "  reward       |  0.0745\n",
            "----------------------------------------\n",
            "INFO - Step 634, rl-loss: 1.2880504131317139Episode 700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1395\n",
            "  reward       |  0.3045\n",
            "----------------------------------------\n",
            "INFO - Step 732, rl-loss: 1.1331359148025513Episode 800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1598\n",
            "  reward       |  0.292\n",
            "----------------------------------------\n",
            "INFO - Step 830, rl-loss: 0.5436383485794067Episode 900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1805\n",
            "  reward       |  0.1735\n",
            "----------------------------------------\n",
            "INFO - Step 931, rl-loss: 1.8967375755310059Episode 1000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2021\n",
            "  reward       |  0.4535\n",
            "----------------------------------------\n",
            "INFO - Step 1027, rl-loss: 2.546901226043701Episode 1100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2234\n",
            "  reward       |  0.28\n",
            "----------------------------------------\n",
            "INFO - Step 1100, rl-loss: 8.587539672851562\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 1121, rl-loss: 1.6509686708450317Episode 1200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2445\n",
            "  reward       |  0.274\n",
            "----------------------------------------\n",
            "INFO - Step 1201, rl-loss: 1.7622896432876587Episode 1300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2626\n",
            "  reward       |  0.2665\n",
            "----------------------------------------\n",
            "INFO - Step 1298, rl-loss: 14.210719108581543Episode 1400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2845\n",
            "  reward       |  0.2095\n",
            "----------------------------------------\n",
            "INFO - Step 1378, rl-loss: 0.4382423162460327Episode 1500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3025\n",
            "  reward       |  0.3795\n",
            "----------------------------------------\n",
            "INFO - Step 1476, rl-loss: 1.0966228246688843Episode 1600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3222\n",
            "  reward       |  0.3855\n",
            "----------------------------------------\n",
            "INFO - Step 1570, rl-loss: 0.23767602443695068Episode 1700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3421\n",
            "  reward       |  0.414\n",
            "----------------------------------------\n",
            "INFO - Step 1662, rl-loss: 1.3713890314102173Episode 1800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3627\n",
            "  reward       |  0.3755\n",
            "----------------------------------------\n",
            "INFO - Step 1758, rl-loss: 3.637122392654419Episode 1900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3845\n",
            "  reward       |  0.3365\n",
            "----------------------------------------\n",
            "INFO - Step 1858, rl-loss: 0.532135009765625Episode 2000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4074\n",
            "  reward       |  0.1535\n",
            "----------------------------------------\n",
            "INFO - Step 1954, rl-loss: 0.37687745690345764Episode 2100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4280\n",
            "  reward       |  0.408\n",
            "----------------------------------------\n",
            "INFO - Step 2047, rl-loss: 0.4421847462654114Episode 2200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4497\n",
            "  reward       |  0.251\n",
            "----------------------------------------\n",
            "INFO - Step 2100, rl-loss: 1.2810289859771729\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 2149, rl-loss: 0.7333616018295288Episode 2300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4718\n",
            "  reward       |  0.1985\n",
            "----------------------------------------\n",
            "INFO - Step 2221, rl-loss: 0.8845251798629761Episode 2400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4900\n",
            "  reward       |  0.3705\n",
            "----------------------------------------\n",
            "INFO - Step 2298, rl-loss: 1.0051765441894531Episode 2500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5083\n",
            "  reward       |  0.3845\n",
            "----------------------------------------\n",
            "INFO - Step 2383, rl-loss: 4.160715103149414Episode 2600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5274\n",
            "  reward       |  0.3135\n",
            "----------------------------------------\n",
            "INFO - Step 2468, rl-loss: 0.5855693817138672Episode 2700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5459\n",
            "  reward       |  0.454\n",
            "----------------------------------------\n",
            "INFO - Step 2563, rl-loss: 2.163627862930298Episode 2800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5662\n",
            "  reward       |  0.485\n",
            "----------------------------------------\n",
            "INFO - Step 2639, rl-loss: 0.4146694839000702Episode 2900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5850\n",
            "  reward       |  0.4325\n",
            "----------------------------------------\n",
            "INFO - Step 2737, rl-loss: 5.643040657043457Episode 3000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6055\n",
            "  reward       |  0.399\n",
            "----------------------------------------\n",
            "INFO - Step 2829, rl-loss: 1.0302187204360962Episode 3100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6263\n",
            "  reward       |  0.3675\n",
            "----------------------------------------\n",
            "INFO - Step 2920, rl-loss: 4.796554088592529Episode 3200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6470\n",
            "  reward       |  0.63\n",
            "----------------------------------------\n",
            "INFO - Step 3016, rl-loss: 3.750027894973755Episode 3300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6680\n",
            "  reward       |  0.4285\n",
            "----------------------------------------\n",
            "INFO - Step 3100, rl-loss: 11.887007713317871\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 3112, rl-loss: 1.9439464807510376Episode 3400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6895\n",
            "  reward       |  0.472\n",
            "----------------------------------------\n",
            "INFO - Step 3203, rl-loss: 1.159315824508667Episode 3500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7096\n",
            "  reward       |  0.3785\n",
            "----------------------------------------\n",
            "INFO - Step 3304, rl-loss: 1.195949912071228Episode 3600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7326\n",
            "  reward       |  0.7335\n",
            "----------------------------------------\n",
            "INFO - Step 3406, rl-loss: 0.716895580291748Episode 3700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7546\n",
            "  reward       |  0.436\n",
            "----------------------------------------\n",
            "INFO - Step 3522, rl-loss: 0.44394025206565857Episode 3800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7794\n",
            "  reward       |  0.413\n",
            "----------------------------------------\n",
            "INFO - Step 3594, rl-loss: 0.5808643102645874Episode 3900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7974\n",
            "  reward       |  0.566\n",
            "----------------------------------------\n",
            "INFO - Step 3678, rl-loss: 7.661632537841797Episode 4000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8168\n",
            "  reward       |  0.6015\n",
            "----------------------------------------\n",
            "INFO - Step 3785, rl-loss: 5.997929096221924Episode 4100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8408\n",
            "  reward       |  0.268\n",
            "----------------------------------------\n",
            "INFO - Step 3899, rl-loss: 1.3357632160186768Episode 4200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8646\n",
            "  reward       |  0.1775\n",
            "----------------------------------------\n",
            "INFO - Step 4002, rl-loss: 0.5170907974243164Episode 4300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8870\n",
            "  reward       |  0.445\n",
            "----------------------------------------\n",
            "INFO - Step 4093, rl-loss: 4.164207458496094Episode 4400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9063\n",
            "  reward       |  0.2175\n",
            "----------------------------------------\n",
            "INFO - Step 4100, rl-loss: 14.469112396240234\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 4197, rl-loss: 6.0713396072387695Episode 4500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9289\n",
            "  reward       |  0.5075\n",
            "----------------------------------------\n",
            "INFO - Step 4299, rl-loss: 5.915186405181885Episode 4600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9510\n",
            "  reward       |  0.314\n",
            "----------------------------------------\n",
            "INFO - Step 4402, rl-loss: 6.447710990905762Episode 4700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9731\n",
            "  reward       |  0.402\n",
            "----------------------------------------\n",
            "INFO - Step 4479, rl-loss: 0.2252526879310608Episode 4800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9919\n",
            "  reward       |  0.3175\n",
            "----------------------------------------\n",
            "INFO - Step 4582, rl-loss: 0.7057754993438721Episode 4900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10142\n",
            "  reward       |  0.4265\n",
            "----------------------------------------\n",
            "INFO - Step 4707, rl-loss: 0.8386534452438354\n",
            "Logs saved in experiments/limit_holdem_dqn_pre_trained_result/\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make the environment with Limit Texas Hold'em\n",
        "env = rlcard.make('limit-holdem')\n",
        "eval_env = rlcard.make('limit-holdem')\n",
        "\n",
        "# Initialize a DQN agent\n",
        "DQN_pretrained_agent = DQNAgent(\n",
        "    num_actions=env.num_actions,\n",
        "    state_shape=env.state_shape[0],\n",
        "    mlp_layers=[64, 64],\n",
        ")\n",
        "\n",
        "# Set the agents in the environment\n",
        "env.set_agents([DQN_pretrained_agent, pre_trained_agent])\n",
        "eval_env.set_agents([DQN_pretrained_agent, pre_trained_agent])\n",
        "\n",
        "# Initialize the Logger\n",
        "with Logger(\"experiments/limit_holdem_dqn_pre_trained_result/\") as logger:\n",
        "    for episode in range(5000):  # Change the number of episodes based on your computational budget\n",
        "        # Generate data from the environment\n",
        "        trajectories, payoffs = env.run(is_training=True)\n",
        "\n",
        "        # Reorganize the data to be state, action, reward, next_state, done\n",
        "        trajectories = reorganize(trajectories, payoffs)\n",
        "\n",
        "        # Feed transitions into agent memory, and train the agent\n",
        "        for ts in trajectories[0]:  # Only use trajectories of the learning agent\n",
        "            DQN_pretrained_agent.feed(ts)\n",
        "\n",
        "        # Evaluate the performance every 100 episodes\n",
        "        if episode % 100 == 0:\n",
        "            print(f'Episode {episode}')\n",
        "            logger.log_performance(\n",
        "                env.timestep,\n",
        "                tournament(\n",
        "                    eval_env,\n",
        "                    1000  # Reduce the number for quicker evaluations\n",
        "                )[0]\n",
        "            )\n",
        "\n",
        "    # Get the paths for the learning curve\n",
        "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_curve(csv_path, fig_path, 'DQN on Limit Texas Hold\\'em')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gbdzSwgWi-X4",
      "metadata": {
        "id": "gbdzSwgWi-X4"
      },
      "source": [
        "The application of the Double DQN algorithm to train against a rule-based agent in poker has produced contrasting reward outcomes compared to training against a randomly playing agent. Training against a random agent resulted in a rapid increase in rewards, stabilizing at a relatively high mean level. In contrast, training against a pre-trained rule-based agent led to significantly lower and more volatile reward outcomes, oscillating around a mean of 0.35BB. The Double DQN algorithm encounters greater difficulty in adapting and learning effective strategies against such opponents, leading to diminished and more erratic reward performance. This highlights the algorithm's sensitivity to opponent dynamics and underscores the need for further research and refinement to enhance its adaptability and effectiveness in competitive poker environments."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VeQxNv4DjBew",
      "metadata": {
        "id": "VeQxNv4DjBew"
      },
      "source": [
        "## 4.2 Deep Fitted Q-Iteration vs. Rule-Based <a class=\"anchor\" id=\"4.2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "V4Zi1xnEjWO1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V4Zi1xnEjWO1",
        "outputId": "048bf0ef-9e1b-4a46-b1b4-8a20ae173cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1\n",
            "  reward       |  0.2915\n",
            "----------------------------------------\n",
            "Episode 100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  189\n",
            "  reward       |  0.4435\n",
            "----------------------------------------\n",
            "INFO - Step 100, rl-loss: 6.8489909172058105\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 175, rl-loss: 4.814320087432861Episode 200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  386\n",
            "  reward       |  0.367\n",
            "----------------------------------------\n",
            "INFO - Step 260, rl-loss: 2.382575035095215Episode 300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  566\n",
            "  reward       |  0.3495\n",
            "----------------------------------------\n",
            "INFO - Step 363, rl-loss: 1.780142903327942Episode 400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  785\n",
            "  reward       |  0.303\n",
            "----------------------------------------\n",
            "INFO - Step 456, rl-loss: 3.6857657432556152Episode 500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  995\n",
            "  reward       |  0.054\n",
            "----------------------------------------\n",
            "INFO - Step 539, rl-loss: 6.101635456085205Episode 600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1188\n",
            "  reward       |  0.1505\n",
            "----------------------------------------\n",
            "INFO - Step 626, rl-loss: 3.8709490299224854Episode 700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1389\n",
            "  reward       |  0.237\n",
            "----------------------------------------\n",
            "INFO - Step 702, rl-loss: 1.1019186973571777Episode 800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1565\n",
            "  reward       |  0.0845\n",
            "----------------------------------------\n",
            "INFO - Step 778, rl-loss: 2.012624979019165Episode 900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1740\n",
            "  reward       |  0.2565\n",
            "----------------------------------------\n",
            "INFO - Step 865, rl-loss: 2.946138858795166Episode 1000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1926\n",
            "  reward       |  0.268\n",
            "----------------------------------------\n",
            "INFO - Step 969, rl-loss: 1.6853810548782349Episode 1100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2150\n",
            "  reward       |  0.333\n",
            "----------------------------------------\n",
            "INFO - Step 1046, rl-loss: 1.0547597408294678Episode 1200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2319\n",
            "  reward       |  0.232\n",
            "----------------------------------------\n",
            "INFO - Step 1100, rl-loss: 1.1348384618759155\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 1131, rl-loss: 1.8271498680114746Episode 1300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2518\n",
            "  reward       |  0.258\n",
            "----------------------------------------\n",
            "INFO - Step 1210, rl-loss: 1.055208444595337Episode 1400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2706\n",
            "  reward       |  0.3865\n",
            "----------------------------------------\n",
            "INFO - Step 1274, rl-loss: 1.7387866973876953Episode 1500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2863\n",
            "  reward       |  0.481\n",
            "----------------------------------------\n",
            "INFO - Step 1387, rl-loss: 1.0120843648910522Episode 1600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3101\n",
            "  reward       |  0.2465\n",
            "----------------------------------------\n",
            "INFO - Step 1464, rl-loss: 1.4776616096496582Episode 1700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3292\n",
            "  reward       |  0.3045\n",
            "----------------------------------------\n",
            "INFO - Step 1555, rl-loss: 2.4727344512939453Episode 1800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3494\n",
            "  reward       |  0.3265\n",
            "----------------------------------------\n",
            "INFO - Step 1654, rl-loss: 3.831305980682373Episode 1900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3712\n",
            "  reward       |  0.4215\n",
            "----------------------------------------\n",
            "INFO - Step 1729, rl-loss: 2.0132508277893066Episode 2000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3889\n",
            "  reward       |  0.207\n",
            "----------------------------------------\n",
            "INFO - Step 1814, rl-loss: 2.4002034664154053Episode 2100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4083\n",
            "  reward       |  0.501\n",
            "----------------------------------------\n",
            "INFO - Step 1915, rl-loss: 0.32774919271469116Episode 2200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4312\n",
            "  reward       |  0.349\n",
            "----------------------------------------\n",
            "INFO - Step 1994, rl-loss: 5.8554911613464355Episode 2300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4487\n",
            "  reward       |  0.4385\n",
            "----------------------------------------\n",
            "INFO - Step 2082, rl-loss: 0.6917121410369873Episode 2400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4688\n",
            "  reward       |  0.238\n",
            "----------------------------------------\n",
            "INFO - Step 2100, rl-loss: 0.7171797752380371\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 2156, rl-loss: 1.4745386838912964Episode 2500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4864\n",
            "  reward       |  0.452\n",
            "----------------------------------------\n",
            "INFO - Step 2232, rl-loss: 0.8297949433326721Episode 2600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5042\n",
            "  reward       |  0.6245\n",
            "----------------------------------------\n",
            "INFO - Step 2340, rl-loss: 2.695716381072998Episode 2700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5290\n",
            "  reward       |  0.4775\n",
            "----------------------------------------\n",
            "INFO - Step 2429, rl-loss: 3.8518948554992676Episode 2800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5486\n",
            "  reward       |  0.4715\n",
            "----------------------------------------\n",
            "INFO - Step 2519, rl-loss: 2.3497018814086914Episode 2900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5689\n",
            "  reward       |  0.43\n",
            "----------------------------------------\n",
            "INFO - Step 2605, rl-loss: 0.35472941398620605Episode 3000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5888\n",
            "  reward       |  0.419\n",
            "----------------------------------------\n",
            "INFO - Step 2700, rl-loss: 0.22308404743671417Episode 3100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6105\n",
            "  reward       |  0.2825\n",
            "----------------------------------------\n",
            "INFO - Step 2777, rl-loss: 7.867251396179199Episode 3200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6289\n",
            "  reward       |  0.3515\n",
            "----------------------------------------\n",
            "INFO - Step 2852, rl-loss: 5.601107597351074Episode 3300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6471\n",
            "  reward       |  0.3785\n",
            "----------------------------------------\n",
            "INFO - Step 2936, rl-loss: 1.0125393867492676Episode 3400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6659\n",
            "  reward       |  0.3825\n",
            "----------------------------------------\n",
            "INFO - Step 3018, rl-loss: 5.246738910675049Episode 3500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6851\n",
            "  reward       |  0.3875\n",
            "----------------------------------------\n",
            "INFO - Step 3100, rl-loss: 0.33697062730789185\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 3101, rl-loss: 8.40494155883789Episode 3600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7044\n",
            "  reward       |  0.4145\n",
            "----------------------------------------\n",
            "INFO - Step 3196, rl-loss: 0.8935425281524658Episode 3700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7256\n",
            "  reward       |  0.4665\n",
            "----------------------------------------\n",
            "INFO - Step 3289, rl-loss: 1.9793087244033813Episode 3800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7462\n",
            "  reward       |  0.4395\n",
            "----------------------------------------\n",
            "INFO - Step 3396, rl-loss: 3.3926615715026855Episode 3900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7682\n",
            "  reward       |  0.498\n",
            "----------------------------------------\n",
            "INFO - Step 3495, rl-loss: 0.47793668508529663Episode 4000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7905\n",
            "  reward       |  0.387\n",
            "----------------------------------------\n",
            "INFO - Step 3592, rl-loss: 6.156888961791992Episode 4100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8127\n",
            "  reward       |  0.3405\n",
            "----------------------------------------\n",
            "INFO - Step 3660, rl-loss: 1.3966861963272095Episode 4200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8297\n",
            "  reward       |  0.4455\n",
            "----------------------------------------\n",
            "INFO - Step 3753, rl-loss: 0.7767127156257629Episode 4300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8516\n",
            "  reward       |  0.478\n",
            "----------------------------------------\n",
            "INFO - Step 3849, rl-loss: 3.8640520572662354Episode 4400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8713\n",
            "  reward       |  0.4\n",
            "----------------------------------------\n",
            "INFO - Step 3954, rl-loss: 0.678519606590271Episode 4500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8944\n",
            "  reward       |  0.4005\n",
            "----------------------------------------\n",
            "INFO - Step 4041, rl-loss: 1.5029959678649902Episode 4600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9138\n",
            "  reward       |  0.2325\n",
            "----------------------------------------\n",
            "INFO - Step 4100, rl-loss: 0.7595565915107727\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 4128, rl-loss: 5.70773983001709Episode 4700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9334\n",
            "  reward       |  0.2375\n",
            "----------------------------------------\n",
            "INFO - Step 4228, rl-loss: 1.6272263526916504Episode 4800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9551\n",
            "  reward       |  0.4075\n",
            "----------------------------------------\n",
            "INFO - Step 4319, rl-loss: 0.6027911901473999Episode 4900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9760\n",
            "  reward       |  -0.1285\n",
            "----------------------------------------\n",
            "INFO - Step 4402, rl-loss: 0.5742939114570618\n",
            "Logs saved in experiments/limit_holdem_dqn_with_fittedq_pretrained_result/\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make the environment with Limit Texas Hold'em\n",
        "env = rlcard.make('limit-holdem')\n",
        "eval_env = rlcard.make('limit-holdem')\n",
        "\n",
        "# Initialize the Double DQN + Fitted Q Iteration agent\n",
        "DQN_fitted_pretrained_agent = DQNAgentWithFittedQ(\n",
        "    num_actions=env.num_actions,\n",
        "    state_shape=env.state_shape[0],\n",
        "    mlp_layers=[64, 64],\n",
        ")\n",
        "\n",
        "# Set the agents in the environment\n",
        "env.set_agents([DQN_fitted_pretrained_agent, pre_trained_agent])\n",
        "eval_env.set_agents([DQN_fitted_pretrained_agent, pre_trained_agent])\n",
        "\n",
        "# Initialize the Logger\n",
        "with Logger(\"experiments/limit_holdem_dqn_with_fittedq_pretrained_result/\") as logger:\n",
        "    for episode in range(5000):  # Change the number of episodes based on your computational budget\n",
        "        # Generate data from the environment\n",
        "        trajectories, payoffs = env.run(is_training=True)\n",
        "\n",
        "        # Reorganize the data to be state, action, reward, next_state, done\n",
        "        trajectories = reorganize(trajectories, payoffs)\n",
        "\n",
        "        # Feed transitions into agent memory, and train the agent\n",
        "        for ts in trajectories[0]:  # Only use trajectories of the learning agent\n",
        "            DQN_fitted_pretrained_agent.feed(ts)\n",
        "\n",
        "        # Evaluate the performance every 100 episodes\n",
        "        if episode % 100 == 0:\n",
        "            print(f'Episode {episode}')\n",
        "            logger.log_performance(\n",
        "                env.timestep,\n",
        "                tournament(\n",
        "                    eval_env,\n",
        "                    1000  \n",
        "                )[0]\n",
        "            )\n",
        "\n",
        "    # Get the paths for the learning curve\n",
        "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_curve(csv_path, fig_path, 'Double DQN with Fitted Q Iteration on Limit Texas Hold\\'em')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LdtsQ2KTjgSS",
      "metadata": {
        "id": "LdtsQ2KTjgSS"
      },
      "source": [
        "The application of the Deep Fitted Q-Iteration algorithm to a rule-based agent has produced reward outcomes slightly lower than those achieved with the Double DQN approach, though with less variability. The agent manages to score positive rewards almost exclusively. As discussed in Section 3, when trained against a random agent, both algorithms demonstrated increasing rewards across episodes, eventually stabilizing at a high mean reward level. However, when faced with a rule-based agent, the reward-to-episode graph for both algorithms shows oscillations around a mean of approximately 0.3BB, suggesting limited learning behavior. Nonetheless, the agents consistently achieve positive rewards even against the rule-based agent."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RlPYIZrh2emg",
      "metadata": {
        "id": "RlPYIZrh2emg"
      },
      "source": [
        "## 4.3 Deep Fitted Q-Iteration vs. Double Deep Q-Network  <a class=\"anchor\" id=\"4.3\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "qo7bB43U2zHT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qo7bB43U2zHT",
        "outputId": "c045bbe9-f544-487c-ac06-0c080a242ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1\n",
            "  reward       |  0.204\n",
            "----------------------------------------\n",
            "INFO - Step 100, rl-loss: 2.7974672317504883\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 134, rl-loss: 2.986624240875244Episode 100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  270\n",
            "  reward       |  -0.5145\n",
            "----------------------------------------\n",
            "INFO - Step 286, rl-loss: 0.9160386919975281Episode 200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  551\n",
            "  reward       |  -0.574\n",
            "----------------------------------------\n",
            "INFO - Step 435, rl-loss: 2.998976707458496Episode 300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  852\n",
            "  reward       |  -0.791\n",
            "----------------------------------------\n",
            "INFO - Step 579, rl-loss: 2.757950782775879Episode 400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1142\n",
            "  reward       |  -0.7525\n",
            "----------------------------------------\n",
            "INFO - Step 719, rl-loss: 1.4886521100997925Episode 500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1415\n",
            "  reward       |  -0.559\n",
            "----------------------------------------\n",
            "INFO - Step 875, rl-loss: 0.6479065418243408Episode 600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  1723\n",
            "  reward       |  -0.7255\n",
            "----------------------------------------\n",
            "INFO - Step 1018, rl-loss: 2.7657952308654785Episode 700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2013\n",
            "  reward       |  -0.927\n",
            "----------------------------------------\n",
            "INFO - Step 1100, rl-loss: 1.4607151746749878\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 1192, rl-loss: 6.0712409019470215Episode 800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2347\n",
            "  reward       |  -0.9605\n",
            "----------------------------------------\n",
            "INFO - Step 1348, rl-loss: 0.47851094603538513Episode 900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2669\n",
            "  reward       |  -0.956\n",
            "----------------------------------------\n",
            "INFO - Step 1500, rl-loss: 1.7528586387634277Episode 1000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  2968\n",
            "  reward       |  -1.532\n",
            "----------------------------------------\n",
            "INFO - Step 1657, rl-loss: 1.4186359643936157Episode 1100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3288\n",
            "  reward       |  -0.6195\n",
            "----------------------------------------\n",
            "INFO - Step 1816, rl-loss: 11.207703590393066Episode 1200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3605\n",
            "  reward       |  -0.3325\n",
            "----------------------------------------\n",
            "INFO - Step 1970, rl-loss: 1.2990422248840332Episode 1300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  3916\n",
            "  reward       |  -2.12\n",
            "----------------------------------------\n",
            "INFO - Step 2100, rl-loss: 0.570660412311554\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 2126, rl-loss: 2.5253946781158447Episode 1400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4227\n",
            "  reward       |  -1.7995\n",
            "----------------------------------------\n",
            "INFO - Step 2266, rl-loss: 0.656721293926239Episode 1500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4510\n",
            "  reward       |  -1.8435\n",
            "----------------------------------------\n",
            "INFO - Step 2406, rl-loss: 0.798175036907196Episode 1600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  4799\n",
            "  reward       |  0.069\n",
            "----------------------------------------\n",
            "INFO - Step 2570, rl-loss: 0.813481330871582Episode 1700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5134\n",
            "  reward       |  0.471\n",
            "----------------------------------------\n",
            "INFO - Step 2716, rl-loss: 2.4911723136901855Episode 1800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5427\n",
            "  reward       |  0.6675\n",
            "----------------------------------------\n",
            "INFO - Step 2859, rl-loss: 0.8612902760505676Episode 1900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  5711\n",
            "  reward       |  0.4645\n",
            "----------------------------------------\n",
            "INFO - Step 3017, rl-loss: 0.8667111992835999Episode 2000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6030\n",
            "  reward       |  -0.124\n",
            "----------------------------------------\n",
            "INFO - Step 3100, rl-loss: 2.9844698905944824\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 3188, rl-loss: 0.3811019957065582Episode 2100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6374\n",
            "  reward       |  1.6225\n",
            "----------------------------------------\n",
            "INFO - Step 3340, rl-loss: 2.733103036880493Episode 2200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  6673\n",
            "  reward       |  0.5455\n",
            "----------------------------------------\n",
            "INFO - Step 3506, rl-loss: 0.3319125473499298Episode 2300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7009\n",
            "  reward       |  -1.7965\n",
            "----------------------------------------\n",
            "INFO - Step 3696, rl-loss: 0.9747368693351746Episode 2400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7388\n",
            "  reward       |  -1.4295\n",
            "----------------------------------------\n",
            "INFO - Step 3851, rl-loss: 0.18287166953086853Episode 2500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  7697\n",
            "  reward       |  -0.0565\n",
            "----------------------------------------\n",
            "INFO - Step 3998, rl-loss: 0.8075539469718933Episode 2600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8001\n",
            "  reward       |  -2.1945\n",
            "----------------------------------------\n",
            "INFO - Step 4100, rl-loss: 1.1299779415130615\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 4161, rl-loss: 0.8098491430282593Episode 2700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8333\n",
            "  reward       |  1.2495\n",
            "----------------------------------------\n",
            "INFO - Step 4339, rl-loss: 0.886646032333374Episode 2800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  8698\n",
            "  reward       |  0.5555\n",
            "----------------------------------------\n",
            "INFO - Step 4496, rl-loss: 0.4133410155773163Episode 2900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9026\n",
            "  reward       |  -1.816\n",
            "----------------------------------------\n",
            "INFO - Step 4657, rl-loss: 2.152280807495117Episode 3000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9353\n",
            "  reward       |  1.749\n",
            "----------------------------------------\n",
            "INFO - Step 4836, rl-loss: 0.5067368745803833Episode 3100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  9719\n",
            "  reward       |  1.67\n",
            "----------------------------------------\n",
            "INFO - Step 4990, rl-loss: 0.5862173438072205Episode 3200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10038\n",
            "  reward       |  1.7595\n",
            "----------------------------------------\n",
            "INFO - Step 5100, rl-loss: 1.3847466707229614\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 5129, rl-loss: 1.994893193244934Episode 3300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10329\n",
            "  reward       |  0.7595\n",
            "----------------------------------------\n",
            "INFO - Step 5278, rl-loss: 2.926100254058838Episode 3400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10626\n",
            "  reward       |  1.0505\n",
            "----------------------------------------\n",
            "INFO - Step 5421, rl-loss: 1.5721522569656372Episode 3500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  10931\n",
            "  reward       |  1.76\n",
            "----------------------------------------\n",
            "INFO - Step 5583, rl-loss: 1.3206875324249268Episode 3600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11273\n",
            "  reward       |  1.486\n",
            "----------------------------------------\n",
            "INFO - Step 5717, rl-loss: 1.8259608745574951Episode 3700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11552\n",
            "  reward       |  1.4925\n",
            "----------------------------------------\n",
            "INFO - Step 5872, rl-loss: 1.3602548837661743Episode 3800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  11882\n",
            "  reward       |  1.6435\n",
            "----------------------------------------\n",
            "INFO - Step 6030, rl-loss: 0.7881079912185669Episode 3900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12204\n",
            "  reward       |  1.0485\n",
            "----------------------------------------\n",
            "INFO - Step 6100, rl-loss: 2.699115514755249\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 6194, rl-loss: 0.5408800840377808Episode 4000\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12545\n",
            "  reward       |  1.528\n",
            "----------------------------------------\n",
            "INFO - Step 6365, rl-loss: 4.072969436645508Episode 4100\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  12900\n",
            "  reward       |  1.78\n",
            "----------------------------------------\n",
            "INFO - Step 6545, rl-loss: 0.4159480035305023Episode 4200\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13262\n",
            "  reward       |  2.1855\n",
            "----------------------------------------\n",
            "INFO - Step 6690, rl-loss: 0.6781562566757202Episode 4300\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13562\n",
            "  reward       |  1.7645\n",
            "----------------------------------------\n",
            "INFO - Step 6850, rl-loss: 0.41387444734573364Episode 4400\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  13883\n",
            "  reward       |  1.5875\n",
            "----------------------------------------\n",
            "INFO - Step 7015, rl-loss: 3.063464641571045Episode 4500\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14235\n",
            "  reward       |  2.075\n",
            "----------------------------------------\n",
            "INFO - Step 7100, rl-loss: 1.8300672769546509\n",
            "INFO - Copied model parameters to target network.\n",
            "INFO - Step 7185, rl-loss: 0.7649812698364258Episode 4600\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14584\n",
            "  reward       |  2.1775\n",
            "----------------------------------------\n",
            "INFO - Step 7352, rl-loss: 0.8568450212478638Episode 4700\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  14913\n",
            "  reward       |  2.2935\n",
            "----------------------------------------\n",
            "INFO - Step 7547, rl-loss: 0.4998089373111725Episode 4800\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15315\n",
            "  reward       |  1.354\n",
            "----------------------------------------\n",
            "INFO - Step 7713, rl-loss: 0.994114100933075Episode 4900\n",
            "\n",
            "----------------------------------------\n",
            "  episode      |  15660\n",
            "  reward       |  1.536\n",
            "----------------------------------------\n",
            "INFO - Step 7892, rl-loss: 0.907200276851654\n",
            "Logs saved in experiments/limit_holdem_dqnFittedQ_vs_dqn/\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Make the environment with Limit Texas Hold'em\n",
        "env = rlcard.make('limit-holdem')\n",
        "eval_env = rlcard.make('limit-holdem')\n",
        "\n",
        "# Initialize the Double DQN + Fitted Q Iteration agent\n",
        "DQN_FittedQ = DQNAgentWithFittedQ(\n",
        "    num_actions=env.num_actions,\n",
        "    state_shape=env.state_shape[0],\n",
        "    mlp_layers=[64, 64],\n",
        ")\n",
        "\n",
        "# Initialize a DQN agent\n",
        "DQN = DQNAgent(\n",
        "    num_actions=env.num_actions,\n",
        "    state_shape=env.state_shape[0],\n",
        "    mlp_layers=[64, 64],\n",
        ")\n",
        "\n",
        "# Set the agents in the environment\n",
        "env.set_agents([DQN_FittedQ, DQN])\n",
        "eval_env.set_agents([DQN_FittedQ, DQN])\n",
        "\n",
        "# Initialize the Logger\n",
        "with Logger(\"experiments/limit_holdem_dqnFittedQ_vs_dqn/\") as logger:\n",
        "    for episode in range(5000):  # Change the number of episodes based on your computational budget\n",
        "        # Generate data from the environment\n",
        "        trajectories, payoffs = env.run(is_training=True)\n",
        "\n",
        "        # Reorganize the data to be state, action, reward, next_state, done\n",
        "        trajectories = reorganize(trajectories, payoffs)\n",
        "\n",
        "        # Feed transitions into agent memory, and train the agent\n",
        "        for ts in trajectories[0]:  # Only use trajectories of the learning agent\n",
        "            DQN_FittedQ.feed(ts)\n",
        "\n",
        "        # Evaluate the performance every 100 episodes\n",
        "        if episode % 100 == 0:\n",
        "            print(f'Episode {episode}')\n",
        "            logger.log_performance(\n",
        "                env.timestep,\n",
        "                tournament(\n",
        "                    eval_env,\n",
        "                    1000  \n",
        "                )[0]\n",
        "            )\n",
        "\n",
        "    # Get the paths for the learning curve\n",
        "    csv_path, fig_path = logger.csv_path, logger.fig_path\n",
        "\n",
        "# Plot the learning curve\n",
        "plot_curve(csv_path, fig_path, 'Double DQN with Fitted Q Iteration on Limit Texas Hold\\'em')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EcgocF1p6eZC",
      "metadata": {
        "id": "EcgocF1p6eZC"
      },
      "source": [
        "In all previous tests, Deep Fitted Q-Iteration and Double Deep Q-Network (DQN) have performed similarly, prompting a direct comparison between the methods. The outcome is particularly interesting: While DQN initially has the upper hand, rewards then undergo a volatile period with no clear winner. Eventually, Deep Fitted Q-Iteration begins to consistently achieve high positive rewards, which continue to increase towards the final episodes. It remains to be seen whether this upward trend would persist or if the rewards might drop into the negative again with longer training. Currently, Deep Fitted Q-Iteration appears to outperform DQN, potentially due to its ensemble-based construction that combines the capabilities of both Fitted Q-Iteration and deep Q-learning, giving it an edge. Another interesting observation is that Deep Fitted Q-Iteration performs well against the sophisticated DQN agent but struggles against the rule-based agent encountered earlier. This discrepancy may be due to the rule-based agent's predictable yet strategically robust behavior, which exposes weaknesses in the adaptability and flexibility of the Fitted Q-Iteration approach. Further investigation is needed to understand and address these dynamics, which could involve refining the training procedures or enhancing the algorithm's ability to generalize across different types of opponents."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9ELHbv7kAdY",
      "metadata": {
        "id": "d9ELHbv7kAdY"
      },
      "source": [
        "## 4.4 Demonstration of Manual Play Against Implemented Agents  <a class=\"anchor\" id=\"4.3\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "VMsfsxMlkBL_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMsfsxMlkBL_",
        "outputId": "50ba090a-3072-4853-ebc0-b09da815b6e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent Name:  DQN_pretrained\n",
            ">> Start a new game\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│A        │   │9        │   │2        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♣    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        A│   │        9│   │        2│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│A        │   │9        │   │2        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♣    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        A│   │        9│   │        2│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++\n",
            "++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│A        │   │9        │   │2        │   │10       │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♣    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        A│   │        9│   │        2│   │       01│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│A        │   │9        │   │2        │   │10       │   │6        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♣    │   │    ♣    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        A│   │        9│   │        2│   │       01│   │        6│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++\n",
            "++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│A        │   │9        │   │2        │   │10       │   │6        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♣    │   │    ♣    │   │    ♣    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        A│   │        9│   │        2│   │       01│   │        6│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++++++\n",
            "++++++++++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│9        │   │K        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        9│   │        K│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You lose 11.0 chips!\n",
            "\n",
            "Press any key to continue...0\n",
            ">> Start a new game\n",
            ">> Player 1 chooses fold\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│A        │   │10       │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        A│   │       01│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 0.5 chips!\n",
            "\n",
            "Press any key to continue...0\n",
            ">> Start a new game\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│2        │   │6        │   │5        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♠    │   │    ♦    │   │    ♥    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        2│   │        6│   │        5│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│2        │   │6        │   │5        │   │2        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♠    │   │    ♦    │   │    ♥    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        2│   │        6│   │        5│   │        2│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│2        │   │6        │   │5        │   │2        │   │3        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♠    │   │    ♦    │   │    ♥    │   │    ♦    │   │    ♠    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        2│   │        6│   │        5│   │        2│   │        3│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│2        │   │6        │   │5        │   │2        │   │3        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♠    │   │    ♦    │   │    ♥    │   │    ♦    │   │    ♠    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        2│   │        6│   │        5│   │        2│   │        3│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│K        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        K│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++\n",
            "++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses call\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │7        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        7│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 9.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            "Agent Name:  DQN_fitted_pretrained\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│6        │   │5        │   │2        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♦    │   │    ♠    │   │    ♣    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        6│   │        5│   │        2│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│6        │   │5        │   │2        │   │8        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♠    │   │    ♣    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        6│   │        5│   │        2│   │        8│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│6        │   │5        │   │2        │   │8        │   │J        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♦    │   │    ♠    │   │    ♣    │   │    ♦    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        6│   │        5│   │        2│   │        8│   │        J│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│J        │   │A        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♥    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        J│   │        A│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │2        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♠    │   │    ♠    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        2│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You win 7.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │7        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        7│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │7        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        7│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│6        │   │8        │   │2        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♥    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        6│   │        8│   │        2│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │7        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        7│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│6        │   │8        │   │2        │   │K        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♥    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        6│   │        8│   │        2│   │        K│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │7        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        7│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│6        │   │8        │   │2        │   │K        │   │6        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♥    │   │    ♣    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        6│   │        8│   │        2│   │        K│   │        6│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │7        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        7│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: raise, 1: fold, 2: check\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│6        │   │8        │   │2        │   │K        │   │6        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♠    │   │    ♥    │   │    ♣    │   │    ♦    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        6│   │        8│   │        2│   │        K│   │        6│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │7        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        7│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++++++\n",
            "++++++++++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses check\n",
            ">> Player 0 chooses raise\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │6        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♣    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        6│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You lose 9.0 chips!\n",
            "\n",
            "Press any key to continue...\n",
            ">> Start a new game\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   +\n",
            "+++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++\n",
            "++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │J        │   │5        │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│    ♥    │   │    ♣    │   │    ♣    │\n",
            "│         │   │         │   │         │\n",
            "│         │   │         │   │         │\n",
            "│        8│   │        J│   │        5│\n",
            "└─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++\n",
            "++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │J        │   │5        │   │2        │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♣    │   │    ♣    │   │    ♣    │\n",
            "│         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │\n",
            "│        8│   │        J│   │        5│   │        2│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++\n",
            "++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            "\n",
            "=============== Community Card ===============\n",
            "┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
            "│8        │   │J        │   │5        │   │2        │   │J        │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│    ♥    │   │    ♣    │   │    ♣    │   │    ♣    │   │    ♥    │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│         │   │         │   │         │   │         │   │         │\n",
            "│        8│   │        J│   │        5│   │        2│   │        J│\n",
            "└─────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
            "===============   Your Hand    ===============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │Q        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♦    │   │    ♦    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        Q│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Chips      ===============\n",
            "Yours:   ++++++++++\n",
            "++++++++++++++++++++++++\n",
            "=========== Actions You Can Choose ===========\n",
            "0: call, 1: raise, 2: fold\n",
            "\n",
            ">> You choose action (integer): 0\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            ">> Player 1 chooses raise\n",
            ">> Player 0 chooses call\n",
            "=============     Random Agent    ============\n",
            "┌─────────┐   ┌─────────┐\n",
            "│4        │   │4        │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│    ♥    │   │    ♣    │\n",
            "│         │   │         │\n",
            "│         │   │         │\n",
            "│        4│   │        4│\n",
            "└─────────┘   └─────────┘\n",
            "===============     Result     ===============\n",
            "You lose 7.0 chips!\n",
            "\n",
            "Press any key to continue...\n"
          ]
        }
      ],
      "source": [
        "trained_agent_list = {'DQN_pretrained':DQN_pretrained_agent,\n",
        "                      'DQN_fitted_pretrained':DQN_fitted_pretrained_agent}\n",
        "\n",
        "for agent in trained_agent_list:\n",
        "    print(\"Agent Name: \", agent)\n",
        "    manual_play(opponent_agent = trained_agent_list[agent], num_games = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_WDWrtNR2M2F",
      "metadata": {
        "id": "_WDWrtNR2M2F"
      },
      "source": [
        "The log above demonstrates manual play against the two models trained on a pre-trained agent. The agents trained with DQN exhibited more aggressive play compared to their performance against agents trained on a random agent. Both agents adopted a similar style, making strong betting moves from the pre-flop stage and only folding when necessary. This indicates that the pre-trained agent training influenced their strategic approach, leading to more assertive and calculated gameplay."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad1e9e9",
      "metadata": {
        "id": "3ad1e9e9"
      },
      "source": [
        "## 5. Conclusion <a class=\"anchor\" id=\"cahp5\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zWgS1OLD3eYK",
      "metadata": {
        "id": "zWgS1OLD3eYK"
      },
      "source": [
        "This study aimed to evaluate and compare the performance of various reinforcement learning (RL) agents in the context of Limit Texas Hold'em poker, with a particular focus on novel methods developed as part of this research. The agents tested include Counterfactual Regret Minimization (CFR), Double Q-Learning, Double Deep Q-Network (Double DQN), Deep Fitted Q-Iteration, Advantage Actor-Critic (A2C) with Fitted Q Iteration, and Neural Fictitious Self-Play (NFSP). Each agent was initially trained against a random agent and subsequently against a rule-based agent to assess its adaptability and effectiveness in different scenarios.\n",
        "\n",
        "**Counterfactual Regret Minimization (CFR):**\n",
        "Despite its theoretical effectiveness, CFR faced challenges in achieving improved rewards over successive episodes. The stagnation in rewards suggests limitations in the current implementation or parameterization of CFR, highlighting the complexity of the poker domain and the need for further refinement.\n",
        "\n",
        "**Double Q-Learning:**\n",
        "Double Q-Learning struggled with the complexities of poker, including partial observability and high variance in rewards. The algorithm encountered difficulties in accurately assessing and learning effective strategies, leading to instability and poor convergence. However, it did achieve positive rewards around 1.15, outperforming the random agent.\n",
        "\n",
        "**Double Deep Q-Network (Double DQN):**\n",
        "By leveraging neural networks, Double DQN handled complex state spaces more effectively than tabular methods. Training against a random agent resulted in a rapid increase in rewards, stabilizing at a high level. However, training against a rule-based agent led to lower and more volatile rewards, highlighting the algorithm's sensitivity to opponent dynamics. Despite these challenges, Double DQN demonstrated significant improvements over Double Q-Learning.\n",
        "\n",
        "**Deep Fitted Q-Iteration:**\n",
        "This novel method combines neural network-based function approximation with the stability of batch learning from FQI. It performed well against the random agent, reaching reward levels up to 2.50. When trained against a rule-based agent, it produced reward outcomes comparable to Double DQN, with limited learning behavior but consistent positive rewards. In a direct comparison with DQN, Deep Fitted Q-Iteration initially lags but eventually manages to outperform DQN, consistently achieving high positive rewards toward the final episodes. It is important to note however, that Deep Fitted Q-Iteration is slower than DQN and requires longer training times. This performance is likely due to its ensemble-based construction, which combines the strengths of both Fitted Q-Iteration and deep Q-learning. An interesting observation is that while Deep Fitted Q-Iteration excels against the sophisticated DQN agent, it performs poorly against the rule-based agent, possibly due to the rule-based agent's predictable yet strategically robust behavior.\n",
        "\n",
        "**Advantage Actor-Critic (A2C) with Fitted Q Iteration:**\n",
        "The A2C agent exhibited some learning behavior but performed worse than other methods such as Double DQN. The high variance in reward signals and unstable updates likely contributed to its lower performance. Despite this, the A2C agent outperformed the random agent, reaching reward levels up to 1.4.\n",
        "\n",
        "**Neural Fictitious Self-Play (NFSP):**\n",
        "Our implementation of NFSP through the RLCard API struggled to reproduce the performance reported in the literature. A grid search to find suitable parameters for our specific setting identified a combination that achieved stable performance, with rewards approaching 2. However, further extensive grid searches and additional episodes might be needed to fully realize the potential of NFSP.\n",
        "\n",
        "### Summary and Evaluation\n",
        "\n",
        "The study's findings indicate that while established methods like Double DQN and Deep Fitted Q-Iteration performed well, the novel methods developed, particularly Deep Fitted Q-Iteration, showed promising results. Deep Fitted Q-Iteration's ability to achieve high reward levels against random agents and maintain positive rewards against rule-based agents suggests it is a robust and effective approach for poker.\n",
        "\n",
        "However, methods like CFR and Double Q-Learning demonstrated the challenges of applying traditional RL algorithms to the complex and dynamic environment of poker. The novel A2C with Fitted Q Iteration also highlighted the difficulties inherent in combining policy gradients with value function estimation in such settings.\n",
        "\n",
        "Overall, this study underscores the importance of tailored RL approaches for complex strategic games like poker. The insights gained from the performance of various agents will inform future research and refinement of RL algorithms, aiming to develop more robust and proficient poker-playing agents. The promising results from novel methods like Deep Fitted Q-Iteration pave the way for further exploration and optimization in this exciting field."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LwIHSw0UpIaX",
      "metadata": {
        "id": "LwIHSw0UpIaX"
      },
      "source": [
        "## Contributions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qFRVTxQupQ1H",
      "metadata": {
        "id": "qFRVTxQupQ1H"
      },
      "source": [
        "26990: 47.5%\n",
        "\n",
        "23685: 47.5%\n",
        "\n",
        "Third group member: 5%\n",
        "Student ID: 201919998 (we do not know their candidate number)\n",
        "Unfortunately, this group member did not participate in the project after the initial meetings and has not shared any files or made any other contributions."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
